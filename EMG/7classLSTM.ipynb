{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-27T03:10:46.122602Z",
     "iopub.status.busy": "2022-04-27T03:10:46.121912Z",
     "iopub.status.idle": "2022-04-27T03:10:52.624336Z",
     "shell.execute_reply": "2022-04-27T03:10:52.623687Z",
     "shell.execute_reply.started": "2022-04-27T03:10:46.122519Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.7.0'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.layers import Dense, Input, LSTM, GRU, Embedding, Dropout, Activation\n",
    "from keras.layers import Bidirectional, GlobalMaxPool1D\n",
    "from keras.models import Model\n",
    "tf.__version__\n",
    "keras.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2022-04-27T03:10:52.626270Z",
     "iopub.status.busy": "2022-04-27T03:10:52.625704Z",
     "iopub.status.idle": "2022-04-27T03:10:57.882086Z",
     "shell.execute_reply": "2022-04-27T03:10:57.881567Z",
     "shell.execute_reply.started": "2022-04-27T03:10:52.626243Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(48, 53056)\n",
      "(7, 53056)\n",
      "       14.995         15     15.005      15.01     15.015      15.02  \\\n",
      "0    0.070938   0.072422   0.077188   0.078828   0.081250   0.080234   \n",
      "1    0.071406   0.073672   0.077578   0.078750   0.081719   0.080156   \n",
      "2    0.072656   0.078594   0.078359   0.080547   0.081953   0.078750   \n",
      "3    0.071797   0.079141   0.077969   0.083281   0.082187   0.078359   \n",
      "4    0.071875   0.078672   0.077031   0.083047   0.082187   0.078750   \n",
      "5    0.071563   0.078281   0.076953   0.082500   0.080859   0.077891   \n",
      "6    0.071016   0.078203   0.077031   0.081641   0.080469   0.073984   \n",
      "7    0.071953   0.077500   0.078359   0.080937   0.079766   0.072500   \n",
      "8    0.515625   0.515625   0.515625   0.515625   0.515625   0.515625   \n",
      "9    0.515625   0.515625   0.515625   0.515625   0.515625   0.515625   \n",
      "10   0.515625   0.515625   0.515625   0.515625   0.515625   0.515625   \n",
      "11   0.515625   0.515625   0.515625   0.515625   0.515625   0.515625   \n",
      "12   0.515625   0.515625   0.515625   0.515625   0.515625   0.515625   \n",
      "13   0.515625   0.515625   0.515625   0.515625   0.515625   0.515625   \n",
      "14   0.515625   0.515625   0.515625   0.515625   0.515625   0.492188   \n",
      "15   0.515625   0.515625   0.515625   0.515625   0.515625   0.492188   \n",
      "16   0.006739   0.007031   0.008767   0.008792   0.009547   0.009532   \n",
      "17   0.006716   0.007063   0.008746   0.008803   0.009507   0.009541   \n",
      "18   0.006791   0.008753   0.008759   0.009011   0.009533   0.009389   \n",
      "19   0.006842   0.008808   0.008768   0.009400   0.009537   0.009319   \n",
      "20   0.006833   0.008817   0.008796   0.009434   0.009537   0.009272   \n",
      "21   0.006859   0.008851   0.008806   0.009486   0.009515   0.009306   \n",
      "22   0.006864   0.008845   0.008804   0.009513   0.009526   0.007378   \n",
      "23   0.007055   0.008728   0.008836   0.009579   0.009579   0.007211   \n",
      "24   0.082094   0.083849   0.093633   0.093764   0.097711   0.097634   \n",
      "25   0.081953   0.084042   0.093521   0.093827   0.097505   0.097677   \n",
      "26   0.082407   0.093558   0.093588   0.094924   0.097638   0.096898   \n",
      "27   0.082715   0.093853   0.093638   0.096952   0.097657   0.096533   \n",
      "28   0.082665   0.093896   0.093790   0.097126   0.097657   0.096291   \n",
      "29   0.082819   0.094078   0.093838   0.097397   0.097543   0.096469   \n",
      "30   0.082852   0.094049   0.093829   0.097536   0.097600   0.085894   \n",
      "31   0.083991   0.093425   0.094003   0.097872   0.097870   0.084917   \n",
      "32   0.108185   0.110477   0.120985   0.122138   0.126702   0.125995   \n",
      "33   0.108388   0.111445   0.121149   0.122135   0.126847   0.125978   \n",
      "34   0.109553   0.121830   0.121702   0.124130   0.127099   0.124486   \n",
      "35   0.109216   0.122407   0.121489   0.127442   0.127265   0.123958   \n",
      "36   0.109230   0.122138   0.121006   0.127420   0.127265   0.124020   \n",
      "37   0.109140   0.122025   0.120993   0.127269   0.126324   0.123613   \n",
      "38   0.108807   0.121953   0.121036   0.126820   0.126118   0.113039   \n",
      "39   0.110278   0.121026   0.122018   0.126625   0.125878   0.111333   \n",
      "40  30.000000  29.000000  30.000000  30.000000  30.000000  30.000000   \n",
      "41  28.000000  28.000000  29.000000  30.000000  30.000000  30.000000   \n",
      "42  31.000000  30.000000  31.000000  30.000000  30.000000  29.000000   \n",
      "43  32.000000  32.000000  33.000000  32.000000  32.000000  32.000000   \n",
      "44  28.000000  28.000000  29.000000  29.000000  29.000000  29.000000   \n",
      "45  27.000000  27.000000  27.000000  27.000000  27.000000  27.000000   \n",
      "46  33.000000  34.000000  34.000000  35.000000  35.000000  34.000000   \n",
      "47  31.000000  31.000000  31.000000  32.000000  31.000000  31.000000   \n",
      "\n",
      "       15.025      15.03     15.035      15.04  ...     15.185      15.19  \\\n",
      "0    0.073750   0.072188   0.070078   0.067578  ...   0.080000   0.080156   \n",
      "1    0.073672   0.071953   0.070703   0.068125  ...   0.080156   0.079766   \n",
      "2    0.071094   0.070469   0.070859   0.068203  ...   0.082734   0.081484   \n",
      "3    0.070547   0.070234   0.067656   0.066406  ...   0.081875   0.081250   \n",
      "4    0.069844   0.070391   0.067656   0.065781  ...   0.081953   0.079531   \n",
      "5    0.069687   0.070234   0.067656   0.065391  ...   0.081797   0.077969   \n",
      "6    0.070859   0.069531   0.067734   0.065000  ...   0.078750   0.074609   \n",
      "7    0.072500   0.069375   0.067656   0.064766  ...   0.079141   0.072891   \n",
      "8    0.492188   0.492188   0.492188   0.492188  ...   0.398438   0.390625   \n",
      "9    0.492188   0.492188   0.492188   0.492188  ...   0.398438   0.390625   \n",
      "10   0.492188   0.492188   0.492188   0.492188  ...   0.398438   0.390625   \n",
      "11   0.492188   0.492188   0.492188   0.492188  ...   0.398438   0.390625   \n",
      "12   0.492188   0.492188   0.492188   0.492188  ...   0.398438   0.390625   \n",
      "13   0.492188   0.492188   0.492188   0.492188  ...   0.398438   0.390625   \n",
      "14   0.492188   0.492188   0.492188   0.492188  ...   0.390625   0.390625   \n",
      "15   0.492188   0.492188   0.492188   0.492188  ...   0.390625   0.390625   \n",
      "16   0.007184   0.007348   0.007121   0.006296  ...   0.007995   0.007588   \n",
      "17   0.007188   0.007365   0.007092   0.006260  ...   0.007977   0.007623   \n",
      "18   0.006771   0.007169   0.007077   0.006264  ...   0.008428   0.007723   \n",
      "19   0.006716   0.007197   0.006286   0.005756  ...   0.008401   0.007745   \n",
      "20   0.006732   0.007179   0.006286   0.005800  ...   0.008390   0.007536   \n",
      "21   0.006739   0.007199   0.006286   0.005824  ...   0.008409   0.007414   \n",
      "22   0.007174   0.007160   0.006281   0.005848  ...   0.007388   0.006686   \n",
      "23   0.007312   0.007137   0.006288   0.005866  ...   0.007471   0.006454   \n",
      "24   0.084759   0.085719   0.084388   0.079349  ...   0.089416   0.087107   \n",
      "25   0.084780   0.085821   0.084212   0.079121  ...   0.089315   0.087310   \n",
      "26   0.082287   0.084669   0.084123   0.079143  ...   0.091804   0.087879   \n",
      "27   0.081949   0.084833   0.079286   0.075871  ...   0.091658   0.088004   \n",
      "28   0.082050   0.084731   0.079286   0.076160  ...   0.091598   0.086807   \n",
      "29   0.082094   0.084847   0.079286   0.076318  ...   0.091699   0.086106   \n",
      "30   0.084700   0.084614   0.079254   0.076473  ...   0.085953   0.081768   \n",
      "31   0.085510   0.084482   0.079294   0.076589  ...   0.086432   0.080335   \n",
      "32   0.112032   0.111738   0.109367   0.103924  ...   0.119646   0.118054   \n",
      "33   0.111997   0.111664   0.109634   0.104109  ...   0.119677   0.117938   \n",
      "34   0.108433   0.109832   0.109668   0.104176  ...   0.123242   0.119521   \n",
      "35   0.107821   0.109807   0.103927   0.100542  ...   0.122559   0.119452   \n",
      "36   0.107438   0.109829   0.103927   0.100347  ...   0.122567   0.117411   \n",
      "37   0.107370   0.109818   0.103927   0.100210  ...   0.122537   0.115841   \n",
      "38   0.110106   0.109191   0.103953   0.100073  ...   0.116257   0.110389   \n",
      "39   0.111782   0.108989   0.103933   0.100009  ...   0.116872   0.108177   \n",
      "40  30.000000  31.000000  31.000000  32.000000  ...  30.000000  30.000000   \n",
      "41  29.000000  30.000000  30.000000  29.000000  ...  29.000000  29.000000   \n",
      "42  29.000000  29.000000  29.000000  29.000000  ...  31.000000  30.000000   \n",
      "43  33.000000  34.000000  34.000000  35.000000  ...  31.000000  31.000000   \n",
      "44  30.000000  29.000000  29.000000  30.000000  ...  26.000000  27.000000   \n",
      "45  28.000000  29.000000  29.000000  28.000000  ...  28.000000  28.000000   \n",
      "46  35.000000  35.000000  36.000000  35.000000  ...  34.000000  33.000000   \n",
      "47  31.000000  31.000000  32.000000  31.000000  ...  31.000000  30.000000   \n",
      "\n",
      "       15.195       15.2     15.205      15.21     15.215      15.22  \\\n",
      "0    0.073047   0.069141   0.070469   0.078594   0.077422   0.077656   \n",
      "1    0.072422   0.070156   0.072734   0.078516   0.077734   0.077734   \n",
      "2    0.071875   0.073359   0.075078   0.081719   0.078359   0.080547   \n",
      "3    0.071641   0.070000   0.075469   0.080781   0.077891   0.081328   \n",
      "4    0.071016   0.069844   0.075938   0.079922   0.077813   0.081719   \n",
      "5    0.068984   0.069531   0.075859   0.078984   0.077969   0.082734   \n",
      "6    0.068828   0.069531   0.076328   0.077656   0.077422   0.083984   \n",
      "7    0.068828   0.069687   0.078437   0.077578   0.077188   0.083437   \n",
      "8    0.390625   0.390625   0.390625   0.390625   0.390625   0.390625   \n",
      "9    0.390625   0.390625   0.390625   0.390625   0.390625   0.390625   \n",
      "10   0.390625   0.390625   0.390625   0.390625   0.390625   0.390625   \n",
      "11   0.390625   0.390625   0.390625   0.390625   0.390625   0.390625   \n",
      "12   0.390625   0.390625   0.390625   0.390625   0.390625   0.390625   \n",
      "13   0.390625   0.390625   0.390625   0.390625   0.390625   0.390625   \n",
      "14   0.390625   0.390625   0.390625   0.390625   0.390625   0.390625   \n",
      "15   0.390625   0.390625   0.390625   0.390625   0.390625   0.390625   \n",
      "16   0.006458   0.006384   0.006507   0.007775   0.008466   0.008346   \n",
      "17   0.006441   0.006441   0.006733   0.007787   0.008432   0.008336   \n",
      "18   0.006439   0.007317   0.007012   0.008406   0.008422   0.008730   \n",
      "19   0.006453   0.006504   0.006968   0.008382   0.008437   0.008824   \n",
      "20   0.006503   0.006519   0.006919   0.008434   0.008447   0.008799   \n",
      "21   0.006374   0.006538   0.006921   0.008481   0.008430   0.008783   \n",
      "22   0.006388   0.006538   0.007012   0.008450   0.008374   0.008770   \n",
      "23   0.006388   0.006531   0.007798   0.008444   0.008383   0.008815   \n",
      "24   0.080361   0.079899   0.080664   0.088178   0.092012   0.091357   \n",
      "25   0.080257   0.080258   0.082056   0.088244   0.091826   0.091300   \n",
      "26   0.080243   0.085538   0.083738   0.091685   0.091772   0.093432   \n",
      "27   0.080328   0.080648   0.083475   0.091556   0.091853   0.093935   \n",
      "28   0.080642   0.080739   0.083178   0.091836   0.091910   0.093805   \n",
      "29   0.079835   0.080859   0.083195   0.092091   0.091816   0.093718   \n",
      "30   0.079925   0.080859   0.083738   0.091923   0.091508   0.093647   \n",
      "31   0.079925   0.080815   0.088304   0.091892   0.091556   0.093887   \n",
      "32   0.108301   0.105359   0.106806   0.117790   0.119898   0.119554   \n",
      "33   0.107804   0.106296   0.109344   0.117788   0.119959   0.119562   \n",
      "34   0.107427   0.112362   0.112155   0.122474   0.120325   0.123004   \n",
      "35   0.107333   0.106485   0.112223   0.121755   0.120081   0.123894   \n",
      "36   0.107151   0.106451   0.112321   0.121396   0.120074   0.124054   \n",
      "37   0.105208   0.106336   0.112280   0.120973   0.120104   0.124660   \n",
      "38   0.105173   0.106336   0.112995   0.119982   0.119516   0.125441   \n",
      "39   0.105173   0.106405   0.117780   0.119909   0.119401   0.125254   \n",
      "40  29.000000  30.000000  30.000000  31.000000  31.000000  31.000000   \n",
      "41  29.000000  29.000000  29.000000  30.000000  30.000000  29.000000   \n",
      "42  31.000000  31.000000  30.000000  31.000000  31.000000  30.000000   \n",
      "43  30.000000  30.000000  30.000000  30.000000  30.000000  29.000000   \n",
      "44  28.000000  27.000000  27.000000  28.000000  28.000000  28.000000   \n",
      "45  28.000000  27.000000  27.000000  28.000000  27.000000  26.000000   \n",
      "46  34.000000  33.000000  33.000000  33.000000  33.000000  32.000000   \n",
      "47  31.000000  31.000000  31.000000  32.000000  32.000000  31.000000   \n",
      "\n",
      "       15.225      15.23  \n",
      "0    0.083437   0.081172  \n",
      "1    0.084375   0.080859  \n",
      "2    0.084453   0.081016  \n",
      "3    0.084844   0.080625  \n",
      "4    0.084453   0.081172  \n",
      "5    0.084609   0.080078  \n",
      "6    0.082187   0.081094  \n",
      "7    0.081406   0.082344  \n",
      "8    0.390625   0.390625  \n",
      "9    0.390625   0.390625  \n",
      "10   0.390625   0.390625  \n",
      "11   0.390625   0.390625  \n",
      "12   0.390625   0.390625  \n",
      "13   0.390625   0.390625  \n",
      "14   0.390625   0.390625  \n",
      "15   0.390625   0.390625  \n",
      "16   0.008815   0.008388  \n",
      "17   0.008774   0.008429  \n",
      "18   0.008780   0.008429  \n",
      "19   0.008741   0.008384  \n",
      "20   0.008774   0.008351  \n",
      "21   0.008755   0.008305  \n",
      "22   0.008341   0.008468  \n",
      "23   0.008359   0.008617  \n",
      "24   0.093887   0.091587  \n",
      "25   0.093671   0.091812  \n",
      "26   0.093702   0.091807  \n",
      "27   0.093493   0.091567  \n",
      "28   0.093669   0.091385  \n",
      "29   0.093566   0.091131  \n",
      "30   0.091328   0.092023  \n",
      "31   0.091427   0.092828  \n",
      "32   0.125254   0.122038  \n",
      "33   0.125721   0.121998  \n",
      "34   0.125796   0.122098  \n",
      "35   0.125905   0.121659  \n",
      "36   0.125772   0.121888  \n",
      "37   0.125801   0.120973  \n",
      "38   0.122524   0.122310  \n",
      "39   0.122075   0.123739  \n",
      "40  32.000000  32.000000  \n",
      "41  30.000000  31.000000  \n",
      "42  31.000000  31.000000  \n",
      "43  30.000000  30.000000  \n",
      "44  28.000000  28.000000  \n",
      "45  27.000000  27.000000  \n",
      "46  33.000000  33.000000  \n",
      "47  32.000000  31.000000  \n",
      "\n",
      "[48 rows x 48 columns]\n",
      "[[1 1 1 1 1 1 1 1 1]\n",
      " [0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "from scipy.io import loadmat\n",
    "\n",
    "data = pd.read_csv('trainData7ClassTest1No1.csv')\n",
    "annots = loadmat('trainLabels7ClassTest1No1OneHotnew.mat')\n",
    "target = annots['trainLabels']\n",
    "\n",
    "print(data.shape)\n",
    "print(target.shape)\n",
    "print(data.iloc[0:48,0:48])\n",
    "print(target[:,1:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-27T03:10:57.883332Z",
     "iopub.status.busy": "2022-04-27T03:10:57.883177Z",
     "iopub.status.idle": "2022-04-27T03:10:57.890599Z",
     "shell.execute_reply": "2022-04-27T03:10:57.890164Z",
     "shell.execute_reply.started": "2022-04-27T03:10:57.883313Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(53056, 48)\n",
      "(48, 48)\n"
     ]
    }
   ],
   "source": [
    "dataT = np.transpose(data)\n",
    "print(dataT.shape)\n",
    "newData = data.iloc[:,0:48]\n",
    "print(newData.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-27T03:10:57.891889Z",
     "iopub.status.busy": "2022-04-27T03:10:57.891745Z",
     "iopub.status.idle": "2022-04-27T03:11:00.333066Z",
     "shell.execute_reply": "2022-04-27T03:11:00.332304Z",
     "shell.execute_reply.started": "2022-04-27T03:10:57.891872Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(53009, 48, 48)\n",
      "(7, 53009)\n",
      "[[ 0.0709375   0.07140625  0.07265625 ... 27.         33.\n",
      "  31.        ]\n",
      " [ 0.07242187  0.07367187  0.07859375 ... 27.         34.\n",
      "  31.        ]\n",
      " [ 0.0771875   0.07757812  0.07835937 ... 27.         34.\n",
      "  31.        ]\n",
      " ...\n",
      " [ 0.07765625  0.07773437  0.08054688 ... 26.         32.\n",
      "  31.        ]\n",
      " [ 0.0834375   0.084375    0.08445313 ... 27.         33.\n",
      "  32.        ]\n",
      " [ 0.08117188  0.08085937  0.08101562 ... 27.         33.\n",
      "  31.        ]]\n"
     ]
    }
   ],
   "source": [
    "windows = []\n",
    "\n",
    "for i in range(dataT.shape[0]-47):\n",
    "    window = dataT[i:i+48]\n",
    "    windows.append(np.expand_dims(window, 0))\n",
    "\n",
    "dataRoll = np.vstack(windows)\n",
    "\n",
    "targetRoll = target[:,:-47]\n",
    "\n",
    "print(dataRoll.shape)\n",
    "print(targetRoll.shape)\n",
    "print(dataRoll[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-27T03:11:00.334261Z",
     "iopub.status.busy": "2022-04-27T03:11:00.334092Z",
     "iopub.status.idle": "2022-04-27T03:11:00.339082Z",
     "shell.execute_reply": "2022-04-27T03:11:00.338489Z",
     "shell.execute_reply.started": "2022-04-27T03:11:00.334241Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(53009, 7)\n",
      "(53009, 48, 48)\n",
      "[[ 0.0709375   0.07242187  0.0771875  ...  0.07765625  0.0834375\n",
      "   0.08117188]\n",
      " [ 0.07140625  0.07367187  0.07757812 ...  0.07773437  0.084375\n",
      "   0.08085937]\n",
      " [ 0.07265625  0.07859375  0.07835937 ...  0.08054688  0.08445313\n",
      "   0.08101562]\n",
      " ...\n",
      " [27.         27.         27.         ... 26.         27.\n",
      "  27.        ]\n",
      " [33.         34.         34.         ... 32.         33.\n",
      "  33.        ]\n",
      " [31.         31.         31.         ... 31.         32.\n",
      "  31.        ]]\n"
     ]
    }
   ],
   "source": [
    "newDataT = np.swapaxes(dataRoll,1,2)\n",
    "newTargetT = np.transpose(targetRoll)\n",
    "print(newTargetT.shape)\n",
    "print(newDataT.shape)\n",
    "print(newDataT[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-27T03:11:00.340003Z",
     "iopub.status.busy": "2022-04-27T03:11:00.339860Z",
     "iopub.status.idle": "2022-04-27T03:11:01.005139Z",
     "shell.execute_reply": "2022-04-27T03:11:01.004398Z",
     "shell.execute_reply.started": "2022-04-27T03:11:00.339987Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(42407, 48, 48)\n",
      "(10602, 48, 48)\n",
      "(42407, 7)\n",
      "(10602, 7)\n",
      "[[ 0.11773438  0.1128125   0.10953125 ...  0.120625    0.12585937\n",
      "   0.12859375]\n",
      " [ 0.11835938  0.11859375  0.1103125  ...  0.12328125  0.12835937\n",
      "   0.13140625]\n",
      " [ 0.11742187  0.11757813  0.1090625  ...  0.1234375   0.12851562\n",
      "   0.13140625]\n",
      " ...\n",
      " [28.         29.         29.         ... 32.         32.\n",
      "  31.        ]\n",
      " [32.         32.         32.         ... 32.         32.\n",
      "  33.        ]\n",
      " [32.         33.         33.         ... 33.         33.\n",
      "  33.        ]]\n",
      "[0 0 0 ... 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "trainData, testData, trainTarget, testTarget = train_test_split(newDataT, newTargetT, test_size=.2, random_state=0) #np.transpose()\n",
    "\n",
    "print(trainData.shape)\n",
    "print(testData.shape)\n",
    "print(trainTarget.shape)\n",
    "print(testTarget.shape)\n",
    "\n",
    "print(trainData[0])\n",
    "print(testTarget[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-27T03:11:01.006622Z",
     "iopub.status.busy": "2022-04-27T03:11:01.006164Z",
     "iopub.status.idle": "2022-04-27T07:31:49.649173Z",
     "shell.execute_reply": "2022-04-27T07:31:49.648651Z",
     "shell.execute_reply.started": "2022-04-27T03:11:01.006601Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-27 03:11:01.077567: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1052] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-27 03:11:01.384797: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1052] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-27 03:11:01.385141: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1052] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-27 03:11:01.386887: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1052] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-27 03:11:01.387170: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1052] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-27 03:11:01.387381: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1052] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-27 03:11:04.217725: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1052] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-27 03:11:04.218052: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1052] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-27 03:11:04.218299: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1052] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-27 03:11:04.218541: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 14803 MB memory:  -> device: 0, name: Quadro RTX 5000, pci bus id: 0000:00:05.0, compute capability: 7.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 48, 48)]     0           []                               \n",
      "                                                                                                  \n",
      " bidirectional (Bidirectional)  (None, 1600)         5433600     ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " flatten (Flatten)              (None, 1600)         0           ['bidirectional[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization (BatchNorm  (None, 1600)        6400        ['flatten[0][0]']                \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 400)          640400      ['batch_normalization[0][0]']    \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 400)          0           ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 100)          40100       ['dropout[0][0]']                \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 1700)         0           ['flatten[0][0]',                \n",
      "                                                                  'dense_1[0][0]']                \n",
      "                                                                                                  \n",
      " dense_2 (Dense)                (None, 7)            11907       ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 6,132,407\n",
      "Trainable params: 6,129,207\n",
      "Non-trainable params: 3,200\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-27 03:11:12.586272: I tensorflow/stream_executor/cuda/cuda_dnn.cc:377] Loaded cuDNN version 8302\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "332/332 [==============================] - 23s 50ms/step - loss: 0.7787 - accuracy: 0.6866 - val_loss: 4.1284 - val_accuracy: 0.3120\n",
      "Epoch 2/1000\n",
      "332/332 [==============================] - 15s 46ms/step - loss: 0.6032 - accuracy: 0.7567 - val_loss: 4.9605 - val_accuracy: 0.2344\n",
      "Epoch 3/1000\n",
      "332/332 [==============================] - 15s 46ms/step - loss: 0.4576 - accuracy: 0.8238 - val_loss: 4.8670 - val_accuracy: 0.2027\n",
      "Epoch 4/1000\n",
      "332/332 [==============================] - 15s 46ms/step - loss: 0.2328 - accuracy: 0.9132 - val_loss: 3.4251 - val_accuracy: 0.3526\n",
      "Epoch 5/1000\n",
      "332/332 [==============================] - 15s 46ms/step - loss: 0.1902 - accuracy: 0.9274 - val_loss: 0.9101 - val_accuracy: 0.7391\n",
      "Epoch 6/1000\n",
      "332/332 [==============================] - 15s 46ms/step - loss: 0.1335 - accuracy: 0.9518 - val_loss: 3.8175 - val_accuracy: 0.3251\n",
      "Epoch 7/1000\n",
      "332/332 [==============================] - 16s 50ms/step - loss: 0.0975 - accuracy: 0.9647 - val_loss: 0.5864 - val_accuracy: 0.7966\n",
      "Epoch 8/1000\n",
      "332/332 [==============================] - 15s 46ms/step - loss: 0.1123 - accuracy: 0.9580 - val_loss: 4.4512 - val_accuracy: 0.3054\n",
      "Epoch 9/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 0.0965 - accuracy: 0.9644 - val_loss: 2.5706 - val_accuracy: 0.4466\n",
      "Epoch 10/1000\n",
      "332/332 [==============================] - 17s 50ms/step - loss: 0.0861 - accuracy: 0.9686 - val_loss: 1.8159 - val_accuracy: 0.6370\n",
      "Epoch 11/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 0.0844 - accuracy: 0.9689 - val_loss: 1.3628 - val_accuracy: 0.6933\n",
      "Epoch 12/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 0.0671 - accuracy: 0.9745 - val_loss: 2.5368 - val_accuracy: 0.5664\n",
      "Epoch 13/1000\n",
      "332/332 [==============================] - 16s 47ms/step - loss: 0.0697 - accuracy: 0.9742 - val_loss: 7.0882 - val_accuracy: 0.1820\n",
      "Epoch 14/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 0.0907 - accuracy: 0.9670 - val_loss: 0.3011 - val_accuracy: 0.9029\n",
      "Epoch 15/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 0.0628 - accuracy: 0.9765 - val_loss: 0.8250 - val_accuracy: 0.8076\n",
      "Epoch 16/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 0.0603 - accuracy: 0.9770 - val_loss: 1.4214 - val_accuracy: 0.6572\n",
      "Epoch 17/1000\n",
      "332/332 [==============================] - 16s 47ms/step - loss: 0.0680 - accuracy: 0.9755 - val_loss: 0.3171 - val_accuracy: 0.9035\n",
      "Epoch 18/1000\n",
      "332/332 [==============================] - 16s 47ms/step - loss: 0.0583 - accuracy: 0.9785 - val_loss: 2.0446 - val_accuracy: 0.6455\n",
      "Epoch 19/1000\n",
      "332/332 [==============================] - 16s 47ms/step - loss: 0.0511 - accuracy: 0.9808 - val_loss: 0.9939 - val_accuracy: 0.7171\n",
      "Epoch 20/1000\n",
      "332/332 [==============================] - 17s 50ms/step - loss: 0.0464 - accuracy: 0.9829 - val_loss: 3.9026 - val_accuracy: 0.5732\n",
      "Epoch 21/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 0.0403 - accuracy: 0.9851 - val_loss: 0.7946 - val_accuracy: 0.8157\n",
      "Epoch 22/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 0.0423 - accuracy: 0.9846 - val_loss: 0.5160 - val_accuracy: 0.8664\n",
      "Epoch 23/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 0.0328 - accuracy: 0.9882 - val_loss: 3.0616 - val_accuracy: 0.6227\n",
      "Epoch 24/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 0.0384 - accuracy: 0.9863 - val_loss: 0.6569 - val_accuracy: 0.8673\n",
      "Epoch 25/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 0.0316 - accuracy: 0.9881 - val_loss: 2.0822 - val_accuracy: 0.6555\n",
      "Epoch 26/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 0.0271 - accuracy: 0.9905 - val_loss: 1.3677 - val_accuracy: 0.7317\n",
      "Epoch 27/1000\n",
      "332/332 [==============================] - 16s 47ms/step - loss: 0.0282 - accuracy: 0.9903 - val_loss: 2.0675 - val_accuracy: 0.7280\n",
      "Epoch 28/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 0.0327 - accuracy: 0.9883 - val_loss: 1.4556 - val_accuracy: 0.7273\n",
      "Epoch 29/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 0.0280 - accuracy: 0.9900 - val_loss: 1.0030 - val_accuracy: 0.7982\n",
      "Epoch 30/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 0.0280 - accuracy: 0.9899 - val_loss: 2.9192 - val_accuracy: 0.7590\n",
      "Epoch 31/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 0.0171 - accuracy: 0.9944 - val_loss: 0.3973 - val_accuracy: 0.8995\n",
      "Epoch 32/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 0.0233 - accuracy: 0.9921 - val_loss: 1.0598 - val_accuracy: 0.8281\n",
      "Epoch 33/1000\n",
      "332/332 [==============================] - 16s 50ms/step - loss: 0.0229 - accuracy: 0.9919 - val_loss: 0.9159 - val_accuracy: 0.8637\n",
      "Epoch 34/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 0.0145 - accuracy: 0.9951 - val_loss: 0.3272 - val_accuracy: 0.9163\n",
      "Epoch 35/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 0.0172 - accuracy: 0.9942 - val_loss: 0.4728 - val_accuracy: 0.8913\n",
      "Epoch 36/1000\n",
      "332/332 [==============================] - 15s 46ms/step - loss: 0.0320 - accuracy: 0.9895 - val_loss: 1.3185 - val_accuracy: 0.7777\n",
      "Epoch 37/1000\n",
      "332/332 [==============================] - 16s 47ms/step - loss: 0.0183 - accuracy: 0.9937 - val_loss: 0.3164 - val_accuracy: 0.9173\n",
      "Epoch 38/1000\n",
      "332/332 [==============================] - 16s 47ms/step - loss: 0.0117 - accuracy: 0.9957 - val_loss: 0.2849 - val_accuracy: 0.9352\n",
      "Epoch 39/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 0.0080 - accuracy: 0.9973 - val_loss: 0.5625 - val_accuracy: 0.8617\n",
      "Epoch 40/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 0.0107 - accuracy: 0.9961 - val_loss: 0.9646 - val_accuracy: 0.8147\n",
      "Epoch 41/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 0.0234 - accuracy: 0.9925 - val_loss: 1.2963 - val_accuracy: 0.7914\n",
      "Epoch 42/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 0.0120 - accuracy: 0.9959 - val_loss: 0.0235 - val_accuracy: 0.9924\n",
      "Epoch 43/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 0.0149 - accuracy: 0.9952 - val_loss: 3.0269 - val_accuracy: 0.5685\n",
      "Epoch 44/1000\n",
      "332/332 [==============================] - 17s 50ms/step - loss: 0.0133 - accuracy: 0.9955 - val_loss: 0.8995 - val_accuracy: 0.8393\n",
      "Epoch 45/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 0.0225 - accuracy: 0.9924 - val_loss: 1.1409 - val_accuracy: 0.7385\n",
      "Epoch 46/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 0.0087 - accuracy: 0.9970 - val_loss: 0.4151 - val_accuracy: 0.9122\n",
      "Epoch 47/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 0.0125 - accuracy: 0.9956 - val_loss: 0.7177 - val_accuracy: 0.8535\n",
      "Epoch 48/1000\n",
      "332/332 [==============================] - 17s 50ms/step - loss: 0.0121 - accuracy: 0.9960 - val_loss: 0.6306 - val_accuracy: 0.8894\n",
      "Epoch 49/1000\n",
      "332/332 [==============================] - 16s 50ms/step - loss: 0.0175 - accuracy: 0.9940 - val_loss: 0.0910 - val_accuracy: 0.9726\n",
      "Epoch 50/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 0.0157 - accuracy: 0.9950 - val_loss: 4.7049 - val_accuracy: 0.4416\n",
      "Epoch 51/1000\n",
      "332/332 [==============================] - 15s 46ms/step - loss: 0.0159 - accuracy: 0.9949 - val_loss: 4.1651 - val_accuracy: 0.6640\n",
      "Epoch 52/1000\n",
      "332/332 [==============================] - 16s 50ms/step - loss: 0.0063 - accuracy: 0.9979 - val_loss: 0.1115 - val_accuracy: 0.9699\n",
      "Epoch 53/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 0.0121 - accuracy: 0.9961 - val_loss: 0.3332 - val_accuracy: 0.9240\n",
      "Epoch 54/1000\n",
      "332/332 [==============================] - 16s 47ms/step - loss: 0.0077 - accuracy: 0.9975 - val_loss: 0.9035 - val_accuracy: 0.8382\n",
      "Epoch 55/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 0.0133 - accuracy: 0.9959 - val_loss: 0.3468 - val_accuracy: 0.9264\n",
      "Epoch 56/1000\n",
      "332/332 [==============================] - 16s 47ms/step - loss: 0.0065 - accuracy: 0.9976 - val_loss: 0.5299 - val_accuracy: 0.9029\n",
      "Epoch 57/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 0.0145 - accuracy: 0.9954 - val_loss: 3.7634 - val_accuracy: 0.5800\n",
      "Epoch 58/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 0.0094 - accuracy: 0.9967 - val_loss: 0.2097 - val_accuracy: 0.9421\n",
      "Epoch 59/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 0.0066 - accuracy: 0.9978 - val_loss: 0.5231 - val_accuracy: 0.8929\n",
      "Epoch 60/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 0.0159 - accuracy: 0.9948 - val_loss: 0.4992 - val_accuracy: 0.8924\n",
      "Epoch 61/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 0.0043 - accuracy: 0.9984 - val_loss: 0.3040 - val_accuracy: 0.9397\n",
      "Epoch 62/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 0.0125 - accuracy: 0.9963 - val_loss: 0.1715 - val_accuracy: 0.9556\n",
      "Epoch 63/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 0.0068 - accuracy: 0.9975 - val_loss: 0.1032 - val_accuracy: 0.9748\n",
      "Epoch 64/1000\n",
      "332/332 [==============================] - 16s 47ms/step - loss: 0.0086 - accuracy: 0.9972 - val_loss: 0.1828 - val_accuracy: 0.9583\n",
      "Epoch 65/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 0.0098 - accuracy: 0.9970 - val_loss: 1.0524 - val_accuracy: 0.8377\n",
      "Epoch 66/1000\n",
      "332/332 [==============================] - 17s 50ms/step - loss: 0.0105 - accuracy: 0.9961 - val_loss: 1.0342 - val_accuracy: 0.8207\n",
      "Epoch 67/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 0.0146 - accuracy: 0.9957 - val_loss: 0.3157 - val_accuracy: 0.9322\n",
      "Epoch 68/1000\n",
      "332/332 [==============================] - 16s 47ms/step - loss: 0.0143 - accuracy: 0.9950 - val_loss: 0.6691 - val_accuracy: 0.8696\n",
      "Epoch 69/1000\n",
      "332/332 [==============================] - 16s 50ms/step - loss: 0.0068 - accuracy: 0.9977 - val_loss: 0.0420 - val_accuracy: 0.9854\n",
      "Epoch 70/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 0.0045 - accuracy: 0.9983 - val_loss: 0.1599 - val_accuracy: 0.9644\n",
      "Epoch 71/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 0.0067 - accuracy: 0.9981 - val_loss: 0.1613 - val_accuracy: 0.9584\n",
      "Epoch 72/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 0.0073 - accuracy: 0.9975 - val_loss: 0.0631 - val_accuracy: 0.9821\n",
      "Epoch 73/1000\n",
      "332/332 [==============================] - 17s 50ms/step - loss: 0.0305 - accuracy: 0.9914 - val_loss: 1.0412 - val_accuracy: 0.8482\n",
      "Epoch 74/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 0.0052 - accuracy: 0.9981 - val_loss: 0.3386 - val_accuracy: 0.9265\n",
      "Epoch 75/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 0.0019 - accuracy: 0.9995 - val_loss: 5.3686e-04 - val_accuracy: 0.9998\n",
      "Epoch 76/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 0.0022 - accuracy: 0.9992 - val_loss: 0.2144 - val_accuracy: 0.9576\n",
      "Epoch 77/1000\n",
      "332/332 [==============================] - 17s 50ms/step - loss: 0.0039 - accuracy: 0.9987 - val_loss: 0.8794 - val_accuracy: 0.8717\n",
      "Epoch 78/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 0.0186 - accuracy: 0.9949 - val_loss: 0.1372 - val_accuracy: 0.9678\n",
      "Epoch 79/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 0.0040 - accuracy: 0.9987 - val_loss: 0.0655 - val_accuracy: 0.9775\n",
      "Epoch 80/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 0.0054 - accuracy: 0.9983 - val_loss: 1.2251 - val_accuracy: 0.8264\n",
      "Epoch 81/1000\n",
      "332/332 [==============================] - 15s 46ms/step - loss: 0.0076 - accuracy: 0.9974 - val_loss: 0.0386 - val_accuracy: 0.9884\n",
      "Epoch 82/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 0.0131 - accuracy: 0.9960 - val_loss: 1.3249 - val_accuracy: 0.7882\n",
      "Epoch 83/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 0.0080 - accuracy: 0.9974 - val_loss: 0.2485 - val_accuracy: 0.9467\n",
      "Epoch 84/1000\n",
      "332/332 [==============================] - 16s 47ms/step - loss: 0.0150 - accuracy: 0.9954 - val_loss: 0.0691 - val_accuracy: 0.9812\n",
      "Epoch 85/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 0.0084 - accuracy: 0.9972 - val_loss: 1.9002 - val_accuracy: 0.7488\n",
      "Epoch 86/1000\n",
      "332/332 [==============================] - 16s 47ms/step - loss: 0.0022 - accuracy: 0.9992 - val_loss: 0.0876 - val_accuracy: 0.9768\n",
      "Epoch 87/1000\n",
      "332/332 [==============================] - 17s 50ms/step - loss: 0.0082 - accuracy: 0.9976 - val_loss: 1.0217 - val_accuracy: 0.8212\n",
      "Epoch 88/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 0.0076 - accuracy: 0.9974 - val_loss: 7.0129 - val_accuracy: 0.3470\n",
      "Epoch 89/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 0.0032 - accuracy: 0.9989 - val_loss: 0.2591 - val_accuracy: 0.9439\n",
      "Epoch 90/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 0.0315 - accuracy: 0.9906 - val_loss: 0.2400 - val_accuracy: 0.9366\n",
      "Epoch 91/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 0.0145 - accuracy: 0.9954 - val_loss: 0.1661 - val_accuracy: 0.9583\n",
      "Epoch 92/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 0.0106 - accuracy: 0.9966 - val_loss: 0.1388 - val_accuracy: 0.9623\n",
      "Epoch 93/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 0.0078 - accuracy: 0.9970 - val_loss: 0.6206 - val_accuracy: 0.8891\n",
      "Epoch 94/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 0.0112 - accuracy: 0.9965 - val_loss: 0.0772 - val_accuracy: 0.9773\n",
      "Epoch 95/1000\n",
      "332/332 [==============================] - 16s 47ms/step - loss: 0.0043 - accuracy: 0.9986 - val_loss: 0.0354 - val_accuracy: 0.9902\n",
      "Epoch 96/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 0.0132 - accuracy: 0.9961 - val_loss: 0.1796 - val_accuracy: 0.9642\n",
      "Epoch 97/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 0.0085 - accuracy: 0.9974 - val_loss: 0.0978 - val_accuracy: 0.9739\n",
      "Epoch 98/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 0.0042 - accuracy: 0.9988 - val_loss: 0.0793 - val_accuracy: 0.9809\n",
      "Epoch 99/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 0.0055 - accuracy: 0.9980 - val_loss: 0.0244 - val_accuracy: 0.9938\n",
      "Epoch 100/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 0.0068 - accuracy: 0.9975 - val_loss: 0.0239 - val_accuracy: 0.9914\n",
      "Epoch 101/1000\n",
      "332/332 [==============================] - 17s 50ms/step - loss: 0.0126 - accuracy: 0.9958 - val_loss: 0.4969 - val_accuracy: 0.9050\n",
      "Epoch 102/1000\n",
      "332/332 [==============================] - 16s 50ms/step - loss: 0.0078 - accuracy: 0.9976 - val_loss: 0.2978 - val_accuracy: 0.9428\n",
      "Epoch 103/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 0.0072 - accuracy: 0.9978 - val_loss: 0.9553 - val_accuracy: 0.8358\n",
      "Epoch 104/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 0.0041 - accuracy: 0.9989 - val_loss: 0.2154 - val_accuracy: 0.9596\n",
      "Epoch 105/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 0.0112 - accuracy: 0.9962 - val_loss: 0.2407 - val_accuracy: 0.9273\n",
      "Epoch 106/1000\n",
      "332/332 [==============================] - 17s 50ms/step - loss: 0.0053 - accuracy: 0.9982 - val_loss: 0.0188 - val_accuracy: 0.9933\n",
      "Epoch 107/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 0.0026 - accuracy: 0.9991 - val_loss: 0.3754 - val_accuracy: 0.9227\n",
      "Epoch 108/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 0.0119 - accuracy: 0.9961 - val_loss: 0.0759 - val_accuracy: 0.9802\n",
      "Epoch 109/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 0.0066 - accuracy: 0.9980 - val_loss: 0.0121 - val_accuracy: 0.9966\n",
      "Epoch 110/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 0.0051 - accuracy: 0.9981 - val_loss: 0.0534 - val_accuracy: 0.9854\n",
      "Epoch 111/1000\n",
      "332/332 [==============================] - 17s 50ms/step - loss: 0.0069 - accuracy: 0.9978 - val_loss: 0.3228 - val_accuracy: 0.9240\n",
      "Epoch 112/1000\n",
      "332/332 [==============================] - 16s 50ms/step - loss: 0.0070 - accuracy: 0.9980 - val_loss: 0.0116 - val_accuracy: 0.9966\n",
      "Epoch 113/1000\n",
      "332/332 [==============================] - 16s 50ms/step - loss: 0.0027 - accuracy: 0.9991 - val_loss: 0.1750 - val_accuracy: 0.9651\n",
      "Epoch 114/1000\n",
      "332/332 [==============================] - 15s 46ms/step - loss: 0.0112 - accuracy: 0.9967 - val_loss: 0.5654 - val_accuracy: 0.9129\n",
      "Epoch 115/1000\n",
      "332/332 [==============================] - 15s 46ms/step - loss: 0.0056 - accuracy: 0.9982 - val_loss: 0.0050 - val_accuracy: 0.9984\n",
      "Epoch 116/1000\n",
      "332/332 [==============================] - 16s 50ms/step - loss: 0.0029 - accuracy: 0.9989 - val_loss: 0.0722 - val_accuracy: 0.9826\n",
      "Epoch 117/1000\n",
      "332/332 [==============================] - 16s 47ms/step - loss: 0.0034 - accuracy: 0.9989 - val_loss: 0.0242 - val_accuracy: 0.9912\n",
      "Epoch 118/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 0.0129 - accuracy: 0.9961 - val_loss: 0.2972 - val_accuracy: 0.9507\n",
      "Epoch 119/1000\n",
      "332/332 [==============================] - 15s 46ms/step - loss: 0.0063 - accuracy: 0.9976 - val_loss: 0.7413 - val_accuracy: 0.8521\n",
      "Epoch 120/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 0.0072 - accuracy: 0.9973 - val_loss: 5.7254 - val_accuracy: 0.4101\n",
      "Epoch 121/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 0.0076 - accuracy: 0.9973 - val_loss: 0.0948 - val_accuracy: 0.9709\n",
      "Epoch 122/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 0.0067 - accuracy: 0.9981 - val_loss: 0.1447 - val_accuracy: 0.9682\n",
      "Epoch 123/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 0.0094 - accuracy: 0.9973 - val_loss: 0.1442 - val_accuracy: 0.9685\n",
      "Epoch 124/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 0.0018 - accuracy: 0.9993 - val_loss: 0.0017 - val_accuracy: 0.9992\n",
      "Epoch 125/1000\n",
      "332/332 [==============================] - 16s 47ms/step - loss: 0.0088 - accuracy: 0.9973 - val_loss: 0.1921 - val_accuracy: 0.9523\n",
      "Epoch 126/1000\n",
      "332/332 [==============================] - 16s 47ms/step - loss: 0.0053 - accuracy: 0.9984 - val_loss: 0.2064 - val_accuracy: 0.9595\n",
      "Epoch 127/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 0.0035 - accuracy: 0.9987 - val_loss: 0.7487 - val_accuracy: 0.8978\n",
      "Epoch 128/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 0.0059 - accuracy: 0.9977 - val_loss: 0.4843 - val_accuracy: 0.9074\n",
      "Epoch 129/1000\n",
      "332/332 [==============================] - 15s 46ms/step - loss: 0.0112 - accuracy: 0.9968 - val_loss: 0.1268 - val_accuracy: 0.9733\n",
      "Epoch 130/1000\n",
      "332/332 [==============================] - 17s 50ms/step - loss: 0.0041 - accuracy: 0.9987 - val_loss: 0.0088 - val_accuracy: 0.9966\n",
      "Epoch 131/1000\n",
      "332/332 [==============================] - 16s 50ms/step - loss: 0.0024 - accuracy: 0.9992 - val_loss: 0.0105 - val_accuracy: 0.9959\n",
      "Epoch 132/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 0.0068 - accuracy: 0.9980 - val_loss: 0.0140 - val_accuracy: 0.9958\n",
      "Epoch 133/1000\n",
      "332/332 [==============================] - 16s 47ms/step - loss: 0.0052 - accuracy: 0.9985 - val_loss: 0.0336 - val_accuracy: 0.9902\n",
      "Epoch 134/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 0.0023 - accuracy: 0.9992 - val_loss: 0.0125 - val_accuracy: 0.9964\n",
      "Epoch 135/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 0.0083 - accuracy: 0.9972 - val_loss: 0.1581 - val_accuracy: 0.9689\n",
      "Epoch 136/1000\n",
      "332/332 [==============================] - 15s 46ms/step - loss: 0.0104 - accuracy: 0.9967 - val_loss: 0.1040 - val_accuracy: 0.9765\n",
      "Epoch 137/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 0.0027 - accuracy: 0.9992 - val_loss: 0.0018 - val_accuracy: 0.9993\n",
      "Epoch 138/1000\n",
      "332/332 [==============================] - 16s 47ms/step - loss: 0.0055 - accuracy: 0.9980 - val_loss: 0.0352 - val_accuracy: 0.9889\n",
      "Epoch 139/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 0.0033 - accuracy: 0.9990 - val_loss: 0.0287 - val_accuracy: 0.9905\n",
      "Epoch 140/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 0.0060 - accuracy: 0.9980 - val_loss: 0.2300 - val_accuracy: 0.9458\n",
      "Epoch 141/1000\n",
      "332/332 [==============================] - 16s 50ms/step - loss: 0.0080 - accuracy: 0.9979 - val_loss: 0.0210 - val_accuracy: 0.9928\n",
      "Epoch 142/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 0.0040 - accuracy: 0.9988 - val_loss: 0.0199 - val_accuracy: 0.9944\n",
      "Epoch 143/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 0.0022 - accuracy: 0.9993 - val_loss: 0.0140 - val_accuracy: 0.9961\n",
      "Epoch 144/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 0.0042 - accuracy: 0.9986 - val_loss: 0.0563 - val_accuracy: 0.9828\n",
      "Epoch 145/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 0.0025 - accuracy: 0.9993 - val_loss: 0.0133 - val_accuracy: 0.9961\n",
      "Epoch 146/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 0.0034 - accuracy: 0.9987 - val_loss: 0.0521 - val_accuracy: 0.9858\n",
      "Epoch 147/1000\n",
      "332/332 [==============================] - 15s 46ms/step - loss: 0.0070 - accuracy: 0.9980 - val_loss: 0.0488 - val_accuracy: 0.9870\n",
      "Epoch 148/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 0.0108 - accuracy: 0.9966 - val_loss: 0.1351 - val_accuracy: 0.9717\n",
      "Epoch 149/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 0.0034 - accuracy: 0.9989 - val_loss: 0.2980 - val_accuracy: 0.9425\n",
      "Epoch 150/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 0.0021 - accuracy: 0.9993 - val_loss: 7.3284e-04 - val_accuracy: 0.9999\n",
      "Epoch 151/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 0.0070 - accuracy: 0.9977 - val_loss: 0.0283 - val_accuracy: 0.9914\n",
      "Epoch 152/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 0.0051 - accuracy: 0.9985 - val_loss: 0.2209 - val_accuracy: 0.9591\n",
      "Epoch 153/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 0.0090 - accuracy: 0.9971 - val_loss: 0.2781 - val_accuracy: 0.9486\n",
      "Epoch 154/1000\n",
      "332/332 [==============================] - 15s 46ms/step - loss: 0.0050 - accuracy: 0.9985 - val_loss: 0.0010 - val_accuracy: 0.9998\n",
      "Epoch 155/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 0.0013 - accuracy: 0.9996 - val_loss: 0.0027 - val_accuracy: 0.9989\n",
      "Epoch 156/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 0.0066 - accuracy: 0.9981 - val_loss: 0.0834 - val_accuracy: 0.9769\n",
      "Epoch 157/1000\n",
      "332/332 [==============================] - 17s 50ms/step - loss: 0.0064 - accuracy: 0.9982 - val_loss: 0.8141 - val_accuracy: 0.8824\n",
      "Epoch 158/1000\n",
      "332/332 [==============================] - 15s 46ms/step - loss: 0.0051 - accuracy: 0.9984 - val_loss: 0.2129 - val_accuracy: 0.9586\n",
      "Epoch 159/1000\n",
      "332/332 [==============================] - 16s 50ms/step - loss: 0.0042 - accuracy: 0.9986 - val_loss: 2.1207e-04 - val_accuracy: 0.9999\n",
      "Epoch 160/1000\n",
      "332/332 [==============================] - 15s 46ms/step - loss: 0.0014 - accuracy: 0.9995 - val_loss: 0.1076 - val_accuracy: 0.9742\n",
      "Epoch 161/1000\n",
      "332/332 [==============================] - 16s 50ms/step - loss: 0.0057 - accuracy: 0.9982 - val_loss: 0.0648 - val_accuracy: 0.9815\n",
      "Epoch 162/1000\n",
      "332/332 [==============================] - 15s 46ms/step - loss: 0.0042 - accuracy: 0.9983 - val_loss: 0.0295 - val_accuracy: 0.9932\n",
      "Epoch 163/1000\n",
      "332/332 [==============================] - 16s 50ms/step - loss: 0.0068 - accuracy: 0.9978 - val_loss: 0.1046 - val_accuracy: 0.9744\n",
      "Epoch 164/1000\n",
      "332/332 [==============================] - 15s 46ms/step - loss: 0.0043 - accuracy: 0.9986 - val_loss: 0.5065 - val_accuracy: 0.9268\n",
      "Epoch 165/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 0.0067 - accuracy: 0.9980 - val_loss: 0.0369 - val_accuracy: 0.9883\n",
      "Epoch 166/1000\n",
      "332/332 [==============================] - 15s 46ms/step - loss: 0.0039 - accuracy: 0.9989 - val_loss: 0.0335 - val_accuracy: 0.9915\n",
      "Epoch 167/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 0.0027 - accuracy: 0.9991 - val_loss: 0.2883 - val_accuracy: 0.9564\n",
      "Epoch 168/1000\n",
      "332/332 [==============================] - 15s 46ms/step - loss: 0.0078 - accuracy: 0.9978 - val_loss: 0.0374 - val_accuracy: 0.9874\n",
      "Epoch 169/1000\n",
      "332/332 [==============================] - 15s 46ms/step - loss: 0.0038 - accuracy: 0.9989 - val_loss: 0.0259 - val_accuracy: 0.9939\n",
      "Epoch 170/1000\n",
      "332/332 [==============================] - 15s 46ms/step - loss: 0.0053 - accuracy: 0.9983 - val_loss: 0.0035 - val_accuracy: 0.9990\n",
      "Epoch 171/1000\n",
      "332/332 [==============================] - 15s 46ms/step - loss: 0.0030 - accuracy: 0.9991 - val_loss: 0.0290 - val_accuracy: 0.9922\n",
      "Epoch 172/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 0.0024 - accuracy: 0.9993 - val_loss: 0.0162 - val_accuracy: 0.9949\n",
      "Epoch 173/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 0.0035 - accuracy: 0.9988 - val_loss: 0.0596 - val_accuracy: 0.9860\n",
      "Epoch 174/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 0.0048 - accuracy: 0.9984 - val_loss: 0.1245 - val_accuracy: 0.9764\n",
      "Epoch 175/1000\n",
      "332/332 [==============================] - 15s 46ms/step - loss: 0.0064 - accuracy: 0.9979 - val_loss: 0.2015 - val_accuracy: 0.9592\n",
      "Epoch 176/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 0.0077 - accuracy: 0.9977 - val_loss: 0.1502 - val_accuracy: 0.9664\n",
      "Epoch 177/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 0.0014 - accuracy: 0.9997 - val_loss: 0.0131 - val_accuracy: 0.9951\n",
      "Epoch 178/1000\n",
      "332/332 [==============================] - 15s 46ms/step - loss: 0.0028 - accuracy: 0.9992 - val_loss: 0.1578 - val_accuracy: 0.9650\n",
      "Epoch 179/1000\n",
      "332/332 [==============================] - 15s 46ms/step - loss: 0.0058 - accuracy: 0.9983 - val_loss: 0.5496 - val_accuracy: 0.9299\n",
      "Epoch 180/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 0.0062 - accuracy: 0.9979 - val_loss: 0.0198 - val_accuracy: 0.9950\n",
      "Epoch 181/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 0.0054 - accuracy: 0.9983 - val_loss: 0.0051 - val_accuracy: 0.9981\n",
      "Epoch 182/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 0.0019 - accuracy: 0.9994 - val_loss: 1.5513e-04 - val_accuracy: 1.0000\n",
      "Epoch 183/1000\n",
      "332/332 [==============================] - 16s 50ms/step - loss: 7.8140e-04 - accuracy: 0.9997 - val_loss: 0.0554 - val_accuracy: 0.9879\n",
      "Epoch 184/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 0.0037 - accuracy: 0.9990 - val_loss: 0.3538 - val_accuracy: 0.9384\n",
      "Epoch 185/1000\n",
      "332/332 [==============================] - 15s 46ms/step - loss: 0.0094 - accuracy: 0.9974 - val_loss: 0.0442 - val_accuracy: 0.9879\n",
      "Epoch 186/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 0.0048 - accuracy: 0.9988 - val_loss: 7.5968e-05 - val_accuracy: 1.0000\n",
      "Epoch 187/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 0.0033 - accuracy: 0.9989 - val_loss: 0.1554 - val_accuracy: 0.9671\n",
      "Epoch 188/1000\n",
      "332/332 [==============================] - 15s 46ms/step - loss: 0.0029 - accuracy: 0.9989 - val_loss: 0.0023 - val_accuracy: 0.9992\n",
      "Epoch 189/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 0.0048 - accuracy: 0.9985 - val_loss: 0.0233 - val_accuracy: 0.9934\n",
      "Epoch 190/1000\n",
      "332/332 [==============================] - 15s 46ms/step - loss: 0.0019 - accuracy: 0.9993 - val_loss: 0.0096 - val_accuracy: 0.9967\n",
      "Epoch 191/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 0.0050 - accuracy: 0.9986 - val_loss: 0.0139 - val_accuracy: 0.9965\n",
      "Epoch 192/1000\n",
      "332/332 [==============================] - 16s 50ms/step - loss: 0.0024 - accuracy: 0.9992 - val_loss: 0.0254 - val_accuracy: 0.9925\n",
      "Epoch 193/1000\n",
      "332/332 [==============================] - 16s 50ms/step - loss: 0.0073 - accuracy: 0.9979 - val_loss: 0.0201 - val_accuracy: 0.9948\n",
      "Epoch 194/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 0.0020 - accuracy: 0.9995 - val_loss: 8.3252e-04 - val_accuracy: 0.9997\n",
      "Epoch 195/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 0.0013 - accuracy: 0.9995 - val_loss: 0.1394 - val_accuracy: 0.9743\n",
      "Epoch 196/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 0.0071 - accuracy: 0.9981 - val_loss: 0.0201 - val_accuracy: 0.9946\n",
      "Epoch 197/1000\n",
      "332/332 [==============================] - 15s 46ms/step - loss: 0.0026 - accuracy: 0.9991 - val_loss: 0.0296 - val_accuracy: 0.9925\n",
      "Epoch 198/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 0.0066 - accuracy: 0.9979 - val_loss: 0.4462 - val_accuracy: 0.9245\n",
      "Epoch 199/1000\n",
      "332/332 [==============================] - 15s 46ms/step - loss: 0.0033 - accuracy: 0.9988 - val_loss: 0.0156 - val_accuracy: 0.9953\n",
      "Epoch 200/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 0.0068 - accuracy: 0.9983 - val_loss: 0.3138 - val_accuracy: 0.9530\n",
      "Epoch 201/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 0.0014 - accuracy: 0.9994 - val_loss: 0.0354 - val_accuracy: 0.9911\n",
      "Epoch 202/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 4.4532e-04 - accuracy: 0.9999 - val_loss: 1.0905e-05 - val_accuracy: 1.0000\n",
      "Epoch 203/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 0.0083 - accuracy: 0.9977 - val_loss: 0.0179 - val_accuracy: 0.9955\n",
      "Epoch 204/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 0.0032 - accuracy: 0.9991 - val_loss: 0.4304 - val_accuracy: 0.9330\n",
      "Epoch 205/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 0.0042 - accuracy: 0.9987 - val_loss: 0.0629 - val_accuracy: 0.9898\n",
      "Epoch 206/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 0.0042 - accuracy: 0.9988 - val_loss: 0.1349 - val_accuracy: 0.9730\n",
      "Epoch 207/1000\n",
      "332/332 [==============================] - 15s 46ms/step - loss: 0.0023 - accuracy: 0.9993 - val_loss: 0.4788 - val_accuracy: 0.9332\n",
      "Epoch 208/1000\n",
      "332/332 [==============================] - 15s 46ms/step - loss: 0.0023 - accuracy: 0.9992 - val_loss: 0.0033 - val_accuracy: 0.9989\n",
      "Epoch 209/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 0.0027 - accuracy: 0.9994 - val_loss: 0.0821 - val_accuracy: 0.9807\n",
      "Epoch 210/1000\n",
      "332/332 [==============================] - 15s 46ms/step - loss: 0.0051 - accuracy: 0.9985 - val_loss: 4.8133 - val_accuracy: 0.6534\n",
      "Epoch 211/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 0.0038 - accuracy: 0.9989 - val_loss: 0.0057 - val_accuracy: 0.9982\n",
      "Epoch 212/1000\n",
      "332/332 [==============================] - 16s 47ms/step - loss: 0.0034 - accuracy: 0.9990 - val_loss: 0.0366 - val_accuracy: 0.9904\n",
      "Epoch 213/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 0.0018 - accuracy: 0.9994 - val_loss: 0.0086 - val_accuracy: 0.9973\n",
      "Epoch 214/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 0.0062 - accuracy: 0.9983 - val_loss: 0.0064 - val_accuracy: 0.9976\n",
      "Epoch 215/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 0.0011 - accuracy: 0.9995 - val_loss: 0.0099 - val_accuracy: 0.9968\n",
      "Epoch 216/1000\n",
      "332/332 [==============================] - 15s 46ms/step - loss: 0.0062 - accuracy: 0.9980 - val_loss: 0.0066 - val_accuracy: 0.9982\n",
      "Epoch 217/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 0.0042 - accuracy: 0.9988 - val_loss: 0.0069 - val_accuracy: 0.9981\n",
      "Epoch 218/1000\n",
      "332/332 [==============================] - 16s 47ms/step - loss: 0.0031 - accuracy: 0.9991 - val_loss: 9.7033e-04 - val_accuracy: 0.9997\n",
      "Epoch 219/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 0.0016 - accuracy: 0.9995 - val_loss: 0.0801 - val_accuracy: 0.9832\n",
      "Epoch 220/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 3.5160e-04 - accuracy: 0.9999 - val_loss: 6.1633e-06 - val_accuracy: 1.0000\n",
      "Epoch 221/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 0.0066 - accuracy: 0.9980 - val_loss: 0.1643 - val_accuracy: 0.9719\n",
      "Epoch 222/1000\n",
      "332/332 [==============================] - 15s 46ms/step - loss: 0.0052 - accuracy: 0.9985 - val_loss: 0.0529 - val_accuracy: 0.9846\n",
      "Epoch 223/1000\n",
      "332/332 [==============================] - 15s 46ms/step - loss: 9.0516e-04 - accuracy: 0.9997 - val_loss: 0.0712 - val_accuracy: 0.9834\n",
      "Epoch 224/1000\n",
      "332/332 [==============================] - 15s 46ms/step - loss: 0.0041 - accuracy: 0.9988 - val_loss: 0.0285 - val_accuracy: 0.9912\n",
      "Epoch 225/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 0.0071 - accuracy: 0.9982 - val_loss: 0.0543 - val_accuracy: 0.9865\n",
      "Epoch 226/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 0.0031 - accuracy: 0.9992 - val_loss: 0.0210 - val_accuracy: 0.9954\n",
      "Epoch 227/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 0.0026 - accuracy: 0.9991 - val_loss: 0.2200 - val_accuracy: 0.9631\n",
      "Epoch 228/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 0.0046 - accuracy: 0.9988 - val_loss: 0.3261 - val_accuracy: 0.9459\n",
      "Epoch 229/1000\n",
      "332/332 [==============================] - 16s 47ms/step - loss: 0.0021 - accuracy: 0.9993 - val_loss: 1.0447e-04 - val_accuracy: 1.0000\n",
      "Epoch 230/1000\n",
      "332/332 [==============================] - 16s 47ms/step - loss: 0.0012 - accuracy: 0.9996 - val_loss: 0.0940 - val_accuracy: 0.9843\n",
      "Epoch 231/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 0.0061 - accuracy: 0.9984 - val_loss: 0.1671 - val_accuracy: 0.9677\n",
      "Epoch 232/1000\n",
      "332/332 [==============================] - 15s 46ms/step - loss: 0.0044 - accuracy: 0.9985 - val_loss: 0.0160 - val_accuracy: 0.9953\n",
      "Epoch 233/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 0.0048 - accuracy: 0.9986 - val_loss: 0.0448 - val_accuracy: 0.9884\n",
      "Epoch 234/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 0.0029 - accuracy: 0.9990 - val_loss: 0.0088 - val_accuracy: 0.9970\n",
      "Epoch 235/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 0.0129 - accuracy: 0.9970 - val_loss: 0.2766 - val_accuracy: 0.9549\n",
      "Epoch 236/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 0.0041 - accuracy: 0.9990 - val_loss: 6.7846e-04 - val_accuracy: 0.9996\n",
      "Epoch 237/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 8.6903e-04 - accuracy: 0.9997 - val_loss: 0.0030 - val_accuracy: 0.9986\n",
      "Epoch 238/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 7.9440e-04 - accuracy: 0.9997 - val_loss: 7.2499e-04 - val_accuracy: 0.9998\n",
      "Epoch 239/1000\n",
      "332/332 [==============================] - 15s 46ms/step - loss: 8.8864e-04 - accuracy: 0.9998 - val_loss: 0.3112 - val_accuracy: 0.9553\n",
      "Epoch 240/1000\n",
      "332/332 [==============================] - 15s 46ms/step - loss: 7.2887e-04 - accuracy: 0.9998 - val_loss: 0.0211 - val_accuracy: 0.9933\n",
      "Epoch 241/1000\n",
      "332/332 [==============================] - 16s 50ms/step - loss: 0.0053 - accuracy: 0.9983 - val_loss: 0.6132 - val_accuracy: 0.9200\n",
      "Epoch 242/1000\n",
      "332/332 [==============================] - 15s 46ms/step - loss: 0.0049 - accuracy: 0.9984 - val_loss: 0.3944 - val_accuracy: 0.9344\n",
      "Epoch 243/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 0.0023 - accuracy: 0.9993 - val_loss: 0.0050 - val_accuracy: 0.9989\n",
      "Epoch 244/1000\n",
      "332/332 [==============================] - 16s 50ms/step - loss: 0.0013 - accuracy: 0.9995 - val_loss: 0.0967 - val_accuracy: 0.9790\n",
      "Epoch 245/1000\n",
      "332/332 [==============================] - 15s 46ms/step - loss: 0.0051 - accuracy: 0.9985 - val_loss: 0.1792 - val_accuracy: 0.9668\n",
      "Epoch 246/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 0.0025 - accuracy: 0.9993 - val_loss: 0.0751 - val_accuracy: 0.9844\n",
      "Epoch 247/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 0.0017 - accuracy: 0.9996 - val_loss: 0.1024 - val_accuracy: 0.9786\n",
      "Epoch 248/1000\n",
      "332/332 [==============================] - 15s 46ms/step - loss: 0.0089 - accuracy: 0.9977 - val_loss: 0.1555 - val_accuracy: 0.9722\n",
      "Epoch 249/1000\n",
      "332/332 [==============================] - 16s 50ms/step - loss: 0.0026 - accuracy: 0.9993 - val_loss: 8.4162e-04 - val_accuracy: 0.9999\n",
      "Epoch 250/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 0.0021 - accuracy: 0.9994 - val_loss: 0.2438 - val_accuracy: 0.9600\n",
      "Epoch 251/1000\n",
      "332/332 [==============================] - 15s 46ms/step - loss: 0.0033 - accuracy: 0.9990 - val_loss: 0.0527 - val_accuracy: 0.9895\n",
      "Epoch 252/1000\n",
      "332/332 [==============================] - 16s 50ms/step - loss: 8.4916e-04 - accuracy: 0.9997 - val_loss: 1.9741e-04 - val_accuracy: 0.9999\n",
      "Epoch 253/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 0.0012 - accuracy: 0.9996 - val_loss: 0.0559 - val_accuracy: 0.9870\n",
      "Epoch 254/1000\n",
      "332/332 [==============================] - 15s 46ms/step - loss: 0.0083 - accuracy: 0.9979 - val_loss: 0.2530 - val_accuracy: 0.9550\n",
      "Epoch 255/1000\n",
      "332/332 [==============================] - 16s 50ms/step - loss: 0.0025 - accuracy: 0.9990 - val_loss: 0.0456 - val_accuracy: 0.9889\n",
      "Epoch 256/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 0.0026 - accuracy: 0.9993 - val_loss: 0.4573 - val_accuracy: 0.9320\n",
      "Epoch 257/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 0.0027 - accuracy: 0.9992 - val_loss: 0.0020 - val_accuracy: 0.9992\n",
      "Epoch 258/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 0.0013 - accuracy: 0.9995 - val_loss: 0.0315 - val_accuracy: 0.9940\n",
      "Epoch 259/1000\n",
      "332/332 [==============================] - 16s 47ms/step - loss: 2.3570e-04 - accuracy: 0.9999 - val_loss: 5.8340e-04 - val_accuracy: 0.9998\n",
      "Epoch 260/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 0.0067 - accuracy: 0.9980 - val_loss: 0.1334 - val_accuracy: 0.9747\n",
      "Epoch 261/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 0.0055 - accuracy: 0.9984 - val_loss: 0.0181 - val_accuracy: 0.9947\n",
      "Epoch 262/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 0.0017 - accuracy: 0.9995 - val_loss: 0.0088 - val_accuracy: 0.9972\n",
      "Epoch 263/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 3.2944e-04 - accuracy: 0.9999 - val_loss: 8.5561e-05 - val_accuracy: 1.0000\n",
      "Epoch 264/1000\n",
      "332/332 [==============================] - 17s 50ms/step - loss: 2.5359e-04 - accuracy: 0.9999 - val_loss: 0.0136 - val_accuracy: 0.9959\n",
      "Epoch 265/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 0.0026 - accuracy: 0.9992 - val_loss: 0.3721 - val_accuracy: 0.9456\n",
      "Epoch 266/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 0.0051 - accuracy: 0.9986 - val_loss: 0.0052 - val_accuracy: 0.9986\n",
      "Epoch 267/1000\n",
      "332/332 [==============================] - 16s 50ms/step - loss: 0.0013 - accuracy: 0.9995 - val_loss: 0.0350 - val_accuracy: 0.9918\n",
      "Epoch 268/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 0.0027 - accuracy: 0.9992 - val_loss: 0.0025 - val_accuracy: 0.9990\n",
      "Epoch 269/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 0.0062 - accuracy: 0.9982 - val_loss: 0.0699 - val_accuracy: 0.9861\n",
      "Epoch 270/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 0.0046 - accuracy: 0.9987 - val_loss: 0.0241 - val_accuracy: 0.9931\n",
      "Epoch 271/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 0.0022 - accuracy: 0.9993 - val_loss: 0.0080 - val_accuracy: 0.9981\n",
      "Epoch 272/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 0.0027 - accuracy: 0.9993 - val_loss: 0.0649 - val_accuracy: 0.9868\n",
      "Epoch 273/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 2.3714e-04 - accuracy: 1.0000 - val_loss: 2.0432e-04 - val_accuracy: 1.0000\n",
      "Epoch 274/1000\n",
      "332/332 [==============================] - 15s 46ms/step - loss: 0.0022 - accuracy: 0.9995 - val_loss: 0.0612 - val_accuracy: 0.9890\n",
      "Epoch 275/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 0.0051 - accuracy: 0.9986 - val_loss: 0.0667 - val_accuracy: 0.9888\n",
      "Epoch 276/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 0.0069 - accuracy: 0.9981 - val_loss: 0.0165 - val_accuracy: 0.9952\n",
      "Epoch 277/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 0.0046 - accuracy: 0.9988 - val_loss: 0.0017 - val_accuracy: 0.9992\n",
      "Epoch 278/1000\n",
      "332/332 [==============================] - 15s 46ms/step - loss: 9.4045e-04 - accuracy: 0.9997 - val_loss: 5.6359e-05 - val_accuracy: 1.0000\n",
      "Epoch 279/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 5.7052e-04 - accuracy: 0.9998 - val_loss: 0.0013 - val_accuracy: 0.9994\n",
      "Epoch 280/1000\n",
      "332/332 [==============================] - 15s 46ms/step - loss: 0.0038 - accuracy: 0.9991 - val_loss: 0.0158 - val_accuracy: 0.9957\n",
      "Epoch 281/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 0.0020 - accuracy: 0.9993 - val_loss: 0.0271 - val_accuracy: 0.9932\n",
      "Epoch 282/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 0.0051 - accuracy: 0.9988 - val_loss: 0.3057 - val_accuracy: 0.9497\n",
      "Epoch 283/1000\n",
      "332/332 [==============================] - 17s 50ms/step - loss: 0.0049 - accuracy: 0.9984 - val_loss: 0.1531 - val_accuracy: 0.9708\n",
      "Epoch 284/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 0.0019 - accuracy: 0.9995 - val_loss: 0.0235 - val_accuracy: 0.9931\n",
      "Epoch 285/1000\n",
      "332/332 [==============================] - 17s 50ms/step - loss: 0.0035 - accuracy: 0.9990 - val_loss: 0.0316 - val_accuracy: 0.9921\n",
      "Epoch 286/1000\n",
      "332/332 [==============================] - 15s 46ms/step - loss: 0.0014 - accuracy: 0.9995 - val_loss: 0.0110 - val_accuracy: 0.9969\n",
      "Epoch 287/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 0.0032 - accuracy: 0.9992 - val_loss: 0.0534 - val_accuracy: 0.9878\n",
      "Epoch 288/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 0.0057 - accuracy: 0.9987 - val_loss: 0.0220 - val_accuracy: 0.9937\n",
      "Epoch 289/1000\n",
      "332/332 [==============================] - 15s 46ms/step - loss: 0.0023 - accuracy: 0.9993 - val_loss: 0.0011 - val_accuracy: 0.9995\n",
      "Epoch 290/1000\n",
      "332/332 [==============================] - 15s 46ms/step - loss: 0.0014 - accuracy: 0.9995 - val_loss: 0.0059 - val_accuracy: 0.9981\n",
      "Epoch 291/1000\n",
      "332/332 [==============================] - 17s 50ms/step - loss: 0.0016 - accuracy: 0.9995 - val_loss: 0.0532 - val_accuracy: 0.9887\n",
      "Epoch 292/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 0.0044 - accuracy: 0.9988 - val_loss: 0.0028 - val_accuracy: 0.9987\n",
      "Epoch 293/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 0.0051 - accuracy: 0.9983 - val_loss: 0.0040 - val_accuracy: 0.9986\n",
      "Epoch 294/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 0.0032 - accuracy: 0.9990 - val_loss: 0.0031 - val_accuracy: 0.9995\n",
      "Epoch 295/1000\n",
      "332/332 [==============================] - 17s 50ms/step - loss: 0.0019 - accuracy: 0.9993 - val_loss: 0.0031 - val_accuracy: 0.9997\n",
      "Epoch 296/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 0.0026 - accuracy: 0.9993 - val_loss: 0.0086 - val_accuracy: 0.9983\n",
      "Epoch 297/1000\n",
      "332/332 [==============================] - 16s 50ms/step - loss: 0.0083 - accuracy: 0.9979 - val_loss: 0.0262 - val_accuracy: 0.9929\n",
      "Epoch 298/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 7.1692e-04 - accuracy: 0.9997 - val_loss: 0.0314 - val_accuracy: 0.9922\n",
      "Epoch 299/1000\n",
      "332/332 [==============================] - 16s 50ms/step - loss: 0.0034 - accuracy: 0.9990 - val_loss: 0.0216 - val_accuracy: 0.9942\n",
      "Epoch 300/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 0.0013 - accuracy: 0.9996 - val_loss: 0.0525 - val_accuracy: 0.9859\n",
      "Epoch 301/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 0.0010 - accuracy: 0.9996 - val_loss: 0.0085 - val_accuracy: 0.9970\n",
      "Epoch 302/1000\n",
      "332/332 [==============================] - 17s 50ms/step - loss: 0.0031 - accuracy: 0.9990 - val_loss: 0.1465 - val_accuracy: 0.9722\n",
      "Epoch 303/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 0.0078 - accuracy: 0.9981 - val_loss: 0.0036 - val_accuracy: 0.9989\n",
      "Epoch 304/1000\n",
      "332/332 [==============================] - 15s 46ms/step - loss: 9.7254e-04 - accuracy: 0.9997 - val_loss: 0.0015 - val_accuracy: 0.9996\n",
      "Epoch 305/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 0.0023 - accuracy: 0.9994 - val_loss: 0.0833 - val_accuracy: 0.9826\n",
      "Epoch 306/1000\n",
      "332/332 [==============================] - 15s 46ms/step - loss: 0.0051 - accuracy: 0.9983 - val_loss: 0.0688 - val_accuracy: 0.9859\n",
      "Epoch 307/1000\n",
      "332/332 [==============================] - 15s 46ms/step - loss: 0.0021 - accuracy: 0.9992 - val_loss: 0.0013 - val_accuracy: 0.9994\n",
      "Epoch 308/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 7.0565e-04 - accuracy: 0.9998 - val_loss: 8.3417e-04 - val_accuracy: 0.9998\n",
      "Epoch 309/1000\n",
      "332/332 [==============================] - 16s 50ms/step - loss: 0.0025 - accuracy: 0.9991 - val_loss: 0.0049 - val_accuracy: 0.9981\n",
      "Epoch 310/1000\n",
      "332/332 [==============================] - 17s 50ms/step - loss: 0.0060 - accuracy: 0.9983 - val_loss: 9.8257e-04 - val_accuracy: 0.9999\n",
      "Epoch 311/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 7.0870e-04 - accuracy: 0.9998 - val_loss: 1.2351e-04 - val_accuracy: 0.9999\n",
      "Epoch 312/1000\n",
      "332/332 [==============================] - 15s 46ms/step - loss: 6.5657e-04 - accuracy: 0.9997 - val_loss: 0.0027 - val_accuracy: 0.9992\n",
      "Epoch 313/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 0.0032 - accuracy: 0.9991 - val_loss: 0.6943 - val_accuracy: 0.9138\n",
      "Epoch 314/1000\n",
      "332/332 [==============================] - 17s 50ms/step - loss: 0.0064 - accuracy: 0.9981 - val_loss: 0.0060 - val_accuracy: 0.9976\n",
      "Epoch 315/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 0.0035 - accuracy: 0.9991 - val_loss: 0.0280 - val_accuracy: 0.9932\n",
      "Epoch 316/1000\n",
      "332/332 [==============================] - 15s 46ms/step - loss: 0.0032 - accuracy: 0.9989 - val_loss: 0.0081 - val_accuracy: 0.9965\n",
      "Epoch 317/1000\n",
      "332/332 [==============================] - 15s 46ms/step - loss: 0.0022 - accuracy: 0.9994 - val_loss: 0.0034 - val_accuracy: 0.9988\n",
      "Epoch 318/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 3.1971e-04 - accuracy: 0.9999 - val_loss: 2.0528e-06 - val_accuracy: 1.0000\n",
      "Epoch 319/1000\n",
      "332/332 [==============================] - 16s 50ms/step - loss: 0.0012 - accuracy: 0.9996 - val_loss: 0.1469 - val_accuracy: 0.9729\n",
      "Epoch 320/1000\n",
      "332/332 [==============================] - 15s 46ms/step - loss: 0.0107 - accuracy: 0.9974 - val_loss: 0.0145 - val_accuracy: 0.9957\n",
      "Epoch 321/1000\n",
      "332/332 [==============================] - 15s 46ms/step - loss: 0.0012 - accuracy: 0.9996 - val_loss: 0.0135 - val_accuracy: 0.9981\n",
      "Epoch 322/1000\n",
      "332/332 [==============================] - 15s 46ms/step - loss: 0.0013 - accuracy: 0.9995 - val_loss: 0.0049 - val_accuracy: 0.9981\n",
      "Epoch 323/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 0.0015 - accuracy: 0.9994 - val_loss: 0.0366 - val_accuracy: 0.9913\n",
      "Epoch 324/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 0.0016 - accuracy: 0.9996 - val_loss: 0.2033 - val_accuracy: 0.9688\n",
      "Epoch 325/1000\n",
      "332/332 [==============================] - 16s 47ms/step - loss: 0.0038 - accuracy: 0.9989 - val_loss: 0.0894 - val_accuracy: 0.9822\n",
      "Epoch 326/1000\n",
      "332/332 [==============================] - 16s 47ms/step - loss: 0.0021 - accuracy: 0.9994 - val_loss: 0.0096 - val_accuracy: 0.9970\n",
      "Epoch 327/1000\n",
      "332/332 [==============================] - 16s 50ms/step - loss: 0.0028 - accuracy: 0.9991 - val_loss: 0.0995 - val_accuracy: 0.9798\n",
      "Epoch 328/1000\n",
      "332/332 [==============================] - 15s 46ms/step - loss: 0.0041 - accuracy: 0.9987 - val_loss: 0.9195 - val_accuracy: 0.8892\n",
      "Epoch 329/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 0.0041 - accuracy: 0.9990 - val_loss: 0.0011 - val_accuracy: 0.9997\n",
      "Epoch 330/1000\n",
      "332/332 [==============================] - 15s 46ms/step - loss: 0.0046 - accuracy: 0.9986 - val_loss: 0.0069 - val_accuracy: 0.9972\n",
      "Epoch 331/1000\n",
      "332/332 [==============================] - 17s 50ms/step - loss: 0.0024 - accuracy: 0.9994 - val_loss: 0.0223 - val_accuracy: 0.9947\n",
      "Epoch 332/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 0.0013 - accuracy: 0.9995 - val_loss: 4.3701e-04 - val_accuracy: 0.9999\n",
      "Epoch 333/1000\n",
      "332/332 [==============================] - 15s 46ms/step - loss: 0.0013 - accuracy: 0.9997 - val_loss: 8.8771e-05 - val_accuracy: 1.0000\n",
      "Epoch 334/1000\n",
      "332/332 [==============================] - 15s 46ms/step - loss: 0.0010 - accuracy: 0.9996 - val_loss: 0.0731 - val_accuracy: 0.9849\n",
      "Epoch 335/1000\n",
      "332/332 [==============================] - 15s 46ms/step - loss: 0.0031 - accuracy: 0.9992 - val_loss: 0.0062 - val_accuracy: 0.9977\n",
      "Epoch 336/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 0.0039 - accuracy: 0.9989 - val_loss: 0.0112 - val_accuracy: 0.9972\n",
      "Epoch 337/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 0.0079 - accuracy: 0.9978 - val_loss: 0.3349 - val_accuracy: 0.9426\n",
      "Epoch 338/1000\n",
      "332/332 [==============================] - 15s 46ms/step - loss: 0.0037 - accuracy: 0.9988 - val_loss: 0.0035 - val_accuracy: 0.9988\n",
      "Epoch 339/1000\n",
      "332/332 [==============================] - 15s 46ms/step - loss: 0.0016 - accuracy: 0.9995 - val_loss: 0.0012 - val_accuracy: 0.9995\n",
      "Epoch 340/1000\n",
      "332/332 [==============================] - 15s 46ms/step - loss: 0.0012 - accuracy: 0.9998 - val_loss: 3.8659e-05 - val_accuracy: 1.0000\n",
      "Epoch 341/1000\n",
      "332/332 [==============================] - 16s 50ms/step - loss: 0.0047 - accuracy: 0.9988 - val_loss: 2.5240e-04 - val_accuracy: 0.9998\n",
      "Epoch 342/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 0.0012 - accuracy: 0.9996 - val_loss: 0.0043 - val_accuracy: 0.9986\n",
      "Epoch 343/1000\n",
      "332/332 [==============================] - 15s 46ms/step - loss: 0.0046 - accuracy: 0.9990 - val_loss: 0.0584 - val_accuracy: 0.9870\n",
      "Epoch 344/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 0.0018 - accuracy: 0.9994 - val_loss: 2.9732e-04 - val_accuracy: 0.9999\n",
      "Epoch 345/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 0.0026 - accuracy: 0.9992 - val_loss: 0.3893 - val_accuracy: 0.9427\n",
      "Epoch 346/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 0.0045 - accuracy: 0.9988 - val_loss: 0.0034 - val_accuracy: 0.9991\n",
      "Epoch 347/1000\n",
      "332/332 [==============================] - 16s 50ms/step - loss: 0.0014 - accuracy: 0.9996 - val_loss: 2.6897e-04 - val_accuracy: 0.9999\n",
      "Epoch 348/1000\n",
      "332/332 [==============================] - 16s 47ms/step - loss: 0.0041 - accuracy: 0.9989 - val_loss: 2.2398e-04 - val_accuracy: 0.9999\n",
      "Epoch 349/1000\n",
      "332/332 [==============================] - 17s 50ms/step - loss: 0.0026 - accuracy: 0.9991 - val_loss: 0.0417 - val_accuracy: 0.9917\n",
      "Epoch 350/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 0.0025 - accuracy: 0.9993 - val_loss: 0.0032 - val_accuracy: 0.9989\n",
      "Epoch 351/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 0.0023 - accuracy: 0.9993 - val_loss: 0.2981 - val_accuracy: 0.9506\n",
      "Epoch 352/1000\n",
      "332/332 [==============================] - 16s 47ms/step - loss: 0.0028 - accuracy: 0.9991 - val_loss: 0.0349 - val_accuracy: 0.9917\n",
      "Epoch 353/1000\n",
      "332/332 [==============================] - 16s 47ms/step - loss: 7.3321e-04 - accuracy: 0.9997 - val_loss: 4.2783e-05 - val_accuracy: 1.0000\n",
      "Epoch 354/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 0.0022 - accuracy: 0.9994 - val_loss: 0.3024 - val_accuracy: 0.9556\n",
      "Epoch 355/1000\n",
      "332/332 [==============================] - 17s 50ms/step - loss: 0.0090 - accuracy: 0.9982 - val_loss: 0.0047 - val_accuracy: 0.9991\n",
      "Epoch 356/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 0.0023 - accuracy: 0.9992 - val_loss: 0.0128 - val_accuracy: 0.9967\n",
      "Epoch 357/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 0.0022 - accuracy: 0.9994 - val_loss: 0.0013 - val_accuracy: 0.9999\n",
      "Epoch 358/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 0.0012 - accuracy: 0.9995 - val_loss: 0.0535 - val_accuracy: 0.9889\n",
      "Epoch 359/1000\n",
      "332/332 [==============================] - 16s 47ms/step - loss: 0.0032 - accuracy: 0.9991 - val_loss: 3.9104e-04 - val_accuracy: 0.9998\n",
      "Epoch 360/1000\n",
      "332/332 [==============================] - 15s 46ms/step - loss: 0.0019 - accuracy: 0.9996 - val_loss: 0.0292 - val_accuracy: 0.9933\n",
      "Epoch 361/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 0.0069 - accuracy: 0.9982 - val_loss: 0.2783 - val_accuracy: 0.9603\n",
      "Epoch 362/1000\n",
      "332/332 [==============================] - 16s 47ms/step - loss: 0.0029 - accuracy: 0.9994 - val_loss: 0.0232 - val_accuracy: 0.9953\n",
      "Epoch 363/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 0.0028 - accuracy: 0.9992 - val_loss: 1.0384e-05 - val_accuracy: 1.0000\n",
      "Epoch 364/1000\n",
      "332/332 [==============================] - 16s 47ms/step - loss: 4.9752e-04 - accuracy: 0.9998 - val_loss: 4.4736e-04 - val_accuracy: 0.9999\n",
      "Epoch 365/1000\n",
      "332/332 [==============================] - 17s 50ms/step - loss: 7.3116e-04 - accuracy: 0.9997 - val_loss: 0.0037 - val_accuracy: 0.9987\n",
      "Epoch 366/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 0.0028 - accuracy: 0.9991 - val_loss: 0.0799 - val_accuracy: 0.9845\n",
      "Epoch 367/1000\n",
      "332/332 [==============================] - 16s 47ms/step - loss: 0.0032 - accuracy: 0.9992 - val_loss: 0.0015 - val_accuracy: 0.9995\n",
      "Epoch 368/1000\n",
      "332/332 [==============================] - 17s 50ms/step - loss: 0.0023 - accuracy: 0.9993 - val_loss: 0.1991 - val_accuracy: 0.9673\n",
      "Epoch 369/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 0.0055 - accuracy: 0.9984 - val_loss: 0.0127 - val_accuracy: 0.9958\n",
      "Epoch 370/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 0.0024 - accuracy: 0.9993 - val_loss: 0.0393 - val_accuracy: 0.9910\n",
      "Epoch 371/1000\n",
      "332/332 [==============================] - 17s 50ms/step - loss: 0.0029 - accuracy: 0.9992 - val_loss: 1.0942e-04 - val_accuracy: 1.0000\n",
      "Epoch 372/1000\n",
      "332/332 [==============================] - 15s 46ms/step - loss: 0.0018 - accuracy: 0.9995 - val_loss: 6.6250e-04 - val_accuracy: 0.9995\n",
      "Epoch 373/1000\n",
      "332/332 [==============================] - 17s 50ms/step - loss: 3.0607e-04 - accuracy: 0.9999 - val_loss: 3.3691e-06 - val_accuracy: 1.0000\n",
      "Epoch 374/1000\n",
      "332/332 [==============================] - 16s 47ms/step - loss: 0.0012 - accuracy: 0.9996 - val_loss: 0.0368 - val_accuracy: 0.9918\n",
      "Epoch 375/1000\n",
      "332/332 [==============================] - 15s 46ms/step - loss: 0.0044 - accuracy: 0.9987 - val_loss: 0.0395 - val_accuracy: 0.9912\n",
      "Epoch 376/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 0.0019 - accuracy: 0.9994 - val_loss: 0.0016 - val_accuracy: 0.9993\n",
      "Epoch 377/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 0.0019 - accuracy: 0.9996 - val_loss: 1.6854e-04 - val_accuracy: 1.0000\n",
      "Epoch 378/1000\n",
      "332/332 [==============================] - 15s 46ms/step - loss: 0.0067 - accuracy: 0.9988 - val_loss: 0.0282 - val_accuracy: 0.9928\n",
      "Epoch 379/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 0.0020 - accuracy: 0.9995 - val_loss: 0.0021 - val_accuracy: 0.9994\n",
      "Epoch 380/1000\n",
      "332/332 [==============================] - 15s 46ms/step - loss: 0.0020 - accuracy: 0.9994 - val_loss: 5.6696e-04 - val_accuracy: 0.9998\n",
      "Epoch 381/1000\n",
      "332/332 [==============================] - 16s 47ms/step - loss: 4.1517e-04 - accuracy: 0.9999 - val_loss: 2.1758e-04 - val_accuracy: 0.9999\n",
      "Epoch 382/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 0.0023 - accuracy: 0.9993 - val_loss: 0.0919 - val_accuracy: 0.9802\n",
      "Epoch 383/1000\n",
      "332/332 [==============================] - 16s 47ms/step - loss: 0.0068 - accuracy: 0.9982 - val_loss: 0.0060 - val_accuracy: 0.9985\n",
      "Epoch 384/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 0.0012 - accuracy: 0.9996 - val_loss: 0.0048 - val_accuracy: 0.9992\n",
      "Epoch 385/1000\n",
      "332/332 [==============================] - 16s 47ms/step - loss: 7.0706e-04 - accuracy: 0.9997 - val_loss: 0.0238 - val_accuracy: 0.9949\n",
      "Epoch 386/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 0.0027 - accuracy: 0.9992 - val_loss: 3.0758e-04 - val_accuracy: 0.9998\n",
      "Epoch 387/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 0.0031 - accuracy: 0.9990 - val_loss: 0.0728 - val_accuracy: 0.9842\n",
      "Epoch 388/1000\n",
      "332/332 [==============================] - 16s 47ms/step - loss: 0.0013 - accuracy: 0.9996 - val_loss: 0.0021 - val_accuracy: 0.9994\n",
      "Epoch 389/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 3.1399e-04 - accuracy: 0.9999 - val_loss: 0.2907 - val_accuracy: 0.9631\n",
      "Epoch 390/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 0.0055 - accuracy: 0.9987 - val_loss: 0.0439 - val_accuracy: 0.9902\n",
      "Epoch 391/1000\n",
      "332/332 [==============================] - 17s 50ms/step - loss: 0.0024 - accuracy: 0.9992 - val_loss: 0.0048 - val_accuracy: 0.9984\n",
      "Epoch 392/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 0.0025 - accuracy: 0.9992 - val_loss: 0.1047 - val_accuracy: 0.9789\n",
      "Epoch 393/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 0.0040 - accuracy: 0.9989 - val_loss: 0.0089 - val_accuracy: 0.9977\n",
      "Epoch 394/1000\n",
      "332/332 [==============================] - 16s 47ms/step - loss: 0.0013 - accuracy: 0.9995 - val_loss: 0.0013 - val_accuracy: 0.9993\n",
      "Epoch 395/1000\n",
      "332/332 [==============================] - 15s 46ms/step - loss: 0.0020 - accuracy: 0.9992 - val_loss: 0.3593 - val_accuracy: 0.9488\n",
      "Epoch 396/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 0.0036 - accuracy: 0.9992 - val_loss: 0.1693 - val_accuracy: 0.9680\n",
      "Epoch 397/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 0.0028 - accuracy: 0.9994 - val_loss: 0.0339 - val_accuracy: 0.9914\n",
      "Epoch 398/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 0.0025 - accuracy: 0.9992 - val_loss: 0.0011 - val_accuracy: 0.9995\n",
      "Epoch 399/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 0.0018 - accuracy: 0.9994 - val_loss: 8.3846e-04 - val_accuracy: 0.9997\n",
      "Epoch 400/1000\n",
      "332/332 [==============================] - 16s 47ms/step - loss: 0.0029 - accuracy: 0.9991 - val_loss: 0.0069 - val_accuracy: 0.9978\n",
      "Epoch 401/1000\n",
      "332/332 [==============================] - 17s 50ms/step - loss: 0.0033 - accuracy: 0.9991 - val_loss: 0.1032 - val_accuracy: 0.9797\n",
      "Epoch 402/1000\n",
      "332/332 [==============================] - 17s 50ms/step - loss: 0.0026 - accuracy: 0.9993 - val_loss: 4.3657e-04 - val_accuracy: 0.9998\n",
      "Epoch 403/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 0.0011 - accuracy: 0.9996 - val_loss: 0.0013 - val_accuracy: 0.9997\n",
      "Epoch 404/1000\n",
      "332/332 [==============================] - 16s 47ms/step - loss: 0.0011 - accuracy: 0.9996 - val_loss: 0.2540 - val_accuracy: 0.9634\n",
      "Epoch 405/1000\n",
      "332/332 [==============================] - 16s 47ms/step - loss: 0.0034 - accuracy: 0.9991 - val_loss: 0.0989 - val_accuracy: 0.9838\n",
      "Epoch 406/1000\n",
      "332/332 [==============================] - 16s 47ms/step - loss: 0.0078 - accuracy: 0.9981 - val_loss: 0.2335 - val_accuracy: 0.9661\n",
      "Epoch 407/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 0.0023 - accuracy: 0.9994 - val_loss: 1.1176e-04 - val_accuracy: 1.0000\n",
      "Epoch 408/1000\n",
      "332/332 [==============================] - 15s 46ms/step - loss: 0.0020 - accuracy: 0.9993 - val_loss: 0.1450 - val_accuracy: 0.9738\n",
      "Epoch 409/1000\n",
      "332/332 [==============================] - 16s 47ms/step - loss: 0.0014 - accuracy: 0.9997 - val_loss: 2.0843e-05 - val_accuracy: 1.0000\n",
      "Epoch 410/1000\n",
      "332/332 [==============================] - 16s 47ms/step - loss: 0.0019 - accuracy: 0.9995 - val_loss: 0.0117 - val_accuracy: 0.9971\n",
      "Epoch 411/1000\n",
      "332/332 [==============================] - 15s 46ms/step - loss: 0.0017 - accuracy: 0.9996 - val_loss: 0.0425 - val_accuracy: 0.9954\n",
      "Epoch 412/1000\n",
      "332/332 [==============================] - 16s 47ms/step - loss: 0.0015 - accuracy: 0.9996 - val_loss: 6.4159e-04 - val_accuracy: 0.9997\n",
      "Epoch 413/1000\n",
      "332/332 [==============================] - 15s 46ms/step - loss: 9.1439e-04 - accuracy: 0.9997 - val_loss: 0.0010 - val_accuracy: 0.9997\n",
      "Epoch 414/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 0.0044 - accuracy: 0.9989 - val_loss: 0.0679 - val_accuracy: 0.9854\n",
      "Epoch 415/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 0.0062 - accuracy: 0.9984 - val_loss: 0.0660 - val_accuracy: 0.9863\n",
      "Epoch 416/1000\n",
      "332/332 [==============================] - 17s 50ms/step - loss: 0.0016 - accuracy: 0.9994 - val_loss: 9.8865e-04 - val_accuracy: 0.9998\n",
      "Epoch 417/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 9.6169e-04 - accuracy: 0.9996 - val_loss: 0.0108 - val_accuracy: 0.9975\n",
      "Epoch 418/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 9.1713e-04 - accuracy: 0.9996 - val_loss: 4.7480e-04 - val_accuracy: 0.9998\n",
      "Epoch 419/1000\n",
      "332/332 [==============================] - 16s 47ms/step - loss: 5.6092e-04 - accuracy: 0.9999 - val_loss: 0.0085 - val_accuracy: 0.9984\n",
      "Epoch 420/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 0.0042 - accuracy: 0.9989 - val_loss: 1.7965e-04 - val_accuracy: 1.0000\n",
      "Epoch 421/1000\n",
      "332/332 [==============================] - 16s 47ms/step - loss: 0.0051 - accuracy: 0.9987 - val_loss: 0.1699 - val_accuracy: 0.9676\n",
      "Epoch 422/1000\n",
      "332/332 [==============================] - 16s 47ms/step - loss: 0.0016 - accuracy: 0.9994 - val_loss: 6.2269e-04 - val_accuracy: 0.9996\n",
      "Epoch 423/1000\n",
      "332/332 [==============================] - 16s 47ms/step - loss: 0.0022 - accuracy: 0.9993 - val_loss: 0.0011 - val_accuracy: 0.9997\n",
      "Epoch 424/1000\n",
      "332/332 [==============================] - 16s 47ms/step - loss: 7.1962e-04 - accuracy: 0.9997 - val_loss: 0.0064 - val_accuracy: 0.9986\n",
      "Epoch 425/1000\n",
      "332/332 [==============================] - 17s 50ms/step - loss: 0.0027 - accuracy: 0.9991 - val_loss: 0.0341 - val_accuracy: 0.9936\n",
      "Epoch 426/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 0.0022 - accuracy: 0.9993 - val_loss: 0.0046 - val_accuracy: 0.9988\n",
      "Epoch 427/1000\n",
      "332/332 [==============================] - 16s 47ms/step - loss: 0.0032 - accuracy: 0.9992 - val_loss: 0.0057 - val_accuracy: 0.9983\n",
      "Epoch 428/1000\n",
      "332/332 [==============================] - 16s 47ms/step - loss: 0.0035 - accuracy: 0.9991 - val_loss: 0.0018 - val_accuracy: 0.9993\n",
      "Epoch 429/1000\n",
      "332/332 [==============================] - 16s 47ms/step - loss: 0.0038 - accuracy: 0.9992 - val_loss: 7.2463e-04 - val_accuracy: 0.9996\n",
      "Epoch 430/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 0.0012 - accuracy: 0.9996 - val_loss: 0.1030 - val_accuracy: 0.9791\n",
      "Epoch 431/1000\n",
      "332/332 [==============================] - 16s 47ms/step - loss: 0.0038 - accuracy: 0.9990 - val_loss: 0.0949 - val_accuracy: 0.9849\n",
      "Epoch 432/1000\n",
      "332/332 [==============================] - 16s 47ms/step - loss: 0.0027 - accuracy: 0.9994 - val_loss: 0.0174 - val_accuracy: 0.9952\n",
      "Epoch 433/1000\n",
      "332/332 [==============================] - 16s 47ms/step - loss: 0.0020 - accuracy: 0.9994 - val_loss: 0.0048 - val_accuracy: 0.9983\n",
      "Epoch 434/1000\n",
      "332/332 [==============================] - 17s 50ms/step - loss: 0.0013 - accuracy: 0.9996 - val_loss: 0.0163 - val_accuracy: 0.9949\n",
      "Epoch 435/1000\n",
      "332/332 [==============================] - 17s 50ms/step - loss: 6.4832e-04 - accuracy: 0.9997 - val_loss: 0.0137 - val_accuracy: 0.9969\n",
      "Epoch 436/1000\n",
      "332/332 [==============================] - 16s 47ms/step - loss: 8.6439e-04 - accuracy: 0.9998 - val_loss: 3.7012e-04 - val_accuracy: 0.9998\n",
      "Epoch 437/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 0.0045 - accuracy: 0.9989 - val_loss: 0.3554 - val_accuracy: 0.9515\n",
      "Epoch 438/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 0.0053 - accuracy: 0.9987 - val_loss: 0.0724 - val_accuracy: 0.9883\n",
      "Epoch 439/1000\n",
      "332/332 [==============================] - 16s 47ms/step - loss: 0.0018 - accuracy: 0.9995 - val_loss: 0.0079 - val_accuracy: 0.9973\n",
      "Epoch 440/1000\n",
      "332/332 [==============================] - 16s 47ms/step - loss: 0.0015 - accuracy: 0.9996 - val_loss: 0.0027 - val_accuracy: 0.9996\n",
      "Epoch 441/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 0.0014 - accuracy: 0.9997 - val_loss: 0.0031 - val_accuracy: 0.9996\n",
      "Epoch 442/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 0.0037 - accuracy: 0.9991 - val_loss: 0.2605 - val_accuracy: 0.9602\n",
      "Epoch 443/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 0.0047 - accuracy: 0.9987 - val_loss: 0.0531 - val_accuracy: 0.9895\n",
      "Epoch 444/1000\n",
      "332/332 [==============================] - 16s 47ms/step - loss: 0.0029 - accuracy: 0.9991 - val_loss: 0.0060 - val_accuracy: 0.9981\n",
      "Epoch 445/1000\n",
      "332/332 [==============================] - 15s 46ms/step - loss: 0.0030 - accuracy: 0.9992 - val_loss: 0.0356 - val_accuracy: 0.9918\n",
      "Epoch 446/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 9.5648e-04 - accuracy: 0.9997 - val_loss: 0.0081 - val_accuracy: 0.9977\n",
      "Epoch 447/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 2.4236e-04 - accuracy: 0.9999 - val_loss: 3.2879e-06 - val_accuracy: 1.0000\n",
      "Epoch 448/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 0.0065 - accuracy: 0.9987 - val_loss: 0.0669 - val_accuracy: 0.9846\n",
      "Epoch 449/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 0.0038 - accuracy: 0.9990 - val_loss: 0.0121 - val_accuracy: 0.9966\n",
      "Epoch 450/1000\n",
      "332/332 [==============================] - 17s 50ms/step - loss: 0.0010 - accuracy: 0.9996 - val_loss: 4.7285e-04 - val_accuracy: 0.9998\n",
      "Epoch 451/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 0.0038 - accuracy: 0.9991 - val_loss: 5.6332e-04 - val_accuracy: 0.9997\n",
      "Epoch 452/1000\n",
      "332/332 [==============================] - 16s 47ms/step - loss: 2.3826e-04 - accuracy: 1.0000 - val_loss: 1.0793e-06 - val_accuracy: 1.0000\n",
      "Epoch 453/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 2.8915e-04 - accuracy: 0.9999 - val_loss: 1.7802e-06 - val_accuracy: 1.0000\n",
      "Epoch 454/1000\n",
      "332/332 [==============================] - 16s 47ms/step - loss: 0.0029 - accuracy: 0.9992 - val_loss: 0.1302 - val_accuracy: 0.9732\n",
      "Epoch 455/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 0.0025 - accuracy: 0.9990 - val_loss: 0.0028 - val_accuracy: 0.9990\n",
      "Epoch 456/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 9.1002e-04 - accuracy: 0.9997 - val_loss: 0.3092 - val_accuracy: 0.9472\n",
      "Epoch 457/1000\n",
      "332/332 [==============================] - 16s 47ms/step - loss: 0.0077 - accuracy: 0.9983 - val_loss: 0.0172 - val_accuracy: 0.9962\n",
      "Epoch 458/1000\n",
      "332/332 [==============================] - 16s 47ms/step - loss: 7.3216e-04 - accuracy: 0.9998 - val_loss: 1.9708e-04 - val_accuracy: 0.9999\n",
      "Epoch 459/1000\n",
      "332/332 [==============================] - 16s 47ms/step - loss: 9.9162e-04 - accuracy: 0.9996 - val_loss: 2.2935e-05 - val_accuracy: 1.0000\n",
      "Epoch 460/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 5.0260e-04 - accuracy: 0.9998 - val_loss: 9.1688e-04 - val_accuracy: 0.9996\n",
      "Epoch 461/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 0.0028 - accuracy: 0.9995 - val_loss: 2.8405e-04 - val_accuracy: 0.9999\n",
      "Epoch 462/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 0.0017 - accuracy: 0.9995 - val_loss: 0.0455 - val_accuracy: 0.9899\n",
      "Epoch 463/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 0.0016 - accuracy: 0.9995 - val_loss: 0.0499 - val_accuracy: 0.9904\n",
      "Epoch 464/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 0.0076 - accuracy: 0.9983 - val_loss: 0.0237 - val_accuracy: 0.9932\n",
      "Epoch 465/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 0.0021 - accuracy: 0.9995 - val_loss: 0.0017 - val_accuracy: 0.9996\n",
      "Epoch 466/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 9.2074e-04 - accuracy: 0.9997 - val_loss: 4.8913e-04 - val_accuracy: 0.9998\n",
      "Epoch 467/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 5.9249e-04 - accuracy: 0.9998 - val_loss: 0.0032 - val_accuracy: 0.9994\n",
      "Epoch 468/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 2.1815e-04 - accuracy: 0.9999 - val_loss: 4.7059e-04 - val_accuracy: 0.9999\n",
      "Epoch 469/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 0.0033 - accuracy: 0.9991 - val_loss: 0.1376 - val_accuracy: 0.9776\n",
      "Epoch 470/1000\n",
      "332/332 [==============================] - 17s 50ms/step - loss: 0.0051 - accuracy: 0.9986 - val_loss: 0.0113 - val_accuracy: 0.9975\n",
      "Epoch 471/1000\n",
      "332/332 [==============================] - 16s 47ms/step - loss: 8.1255e-04 - accuracy: 0.9997 - val_loss: 5.1923e-04 - val_accuracy: 0.9997\n",
      "Epoch 472/1000\n",
      "332/332 [==============================] - 16s 47ms/step - loss: 0.0011 - accuracy: 0.9996 - val_loss: 0.0011 - val_accuracy: 0.9997\n",
      "Epoch 473/1000\n",
      "332/332 [==============================] - 16s 47ms/step - loss: 0.0015 - accuracy: 0.9996 - val_loss: 0.1101 - val_accuracy: 0.9807\n",
      "Epoch 474/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 0.0013 - accuracy: 0.9997 - val_loss: 1.0799e-05 - val_accuracy: 1.0000\n",
      "Epoch 475/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 0.0033 - accuracy: 0.9990 - val_loss: 0.4020 - val_accuracy: 0.9401\n",
      "Epoch 476/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 0.0025 - accuracy: 0.9993 - val_loss: 0.0263 - val_accuracy: 0.9948\n",
      "Epoch 477/1000\n",
      "332/332 [==============================] - 17s 50ms/step - loss: 4.9199e-04 - accuracy: 0.9997 - val_loss: 2.2233e-05 - val_accuracy: 1.0000\n",
      "Epoch 478/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 0.0049 - accuracy: 0.9991 - val_loss: 0.0800 - val_accuracy: 0.9825\n",
      "Epoch 479/1000\n",
      "332/332 [==============================] - 15s 46ms/step - loss: 0.0021 - accuracy: 0.9993 - val_loss: 0.0058 - val_accuracy: 0.9987\n",
      "Epoch 480/1000\n",
      "332/332 [==============================] - 16s 47ms/step - loss: 0.0043 - accuracy: 0.9992 - val_loss: 0.0890 - val_accuracy: 0.9829\n",
      "Epoch 481/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 0.0022 - accuracy: 0.9992 - val_loss: 1.1811e-04 - val_accuracy: 0.9999\n",
      "Epoch 482/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 0.0021 - accuracy: 0.9992 - val_loss: 0.0192 - val_accuracy: 0.9948\n",
      "Epoch 483/1000\n",
      "332/332 [==============================] - 16s 47ms/step - loss: 2.1031e-04 - accuracy: 0.9999 - val_loss: 0.0012 - val_accuracy: 0.9995\n",
      "Epoch 484/1000\n",
      "332/332 [==============================] - 16s 47ms/step - loss: 0.0017 - accuracy: 0.9996 - val_loss: 0.0269 - val_accuracy: 0.9939\n",
      "Epoch 485/1000\n",
      "332/332 [==============================] - 16s 47ms/step - loss: 0.0034 - accuracy: 0.9991 - val_loss: 0.0022 - val_accuracy: 0.9994\n",
      "Epoch 486/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 4.2299e-04 - accuracy: 0.9999 - val_loss: 0.0011 - val_accuracy: 0.9999\n",
      "Epoch 487/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 2.0081e-04 - accuracy: 0.9999 - val_loss: 1.1375e-04 - val_accuracy: 0.9999\n",
      "Epoch 488/1000\n",
      "332/332 [==============================] - 16s 47ms/step - loss: 4.0811e-04 - accuracy: 0.9999 - val_loss: 2.8748e-05 - val_accuracy: 1.0000\n",
      "Epoch 489/1000\n",
      "332/332 [==============================] - 17s 50ms/step - loss: 0.0073 - accuracy: 0.9981 - val_loss: 0.0146 - val_accuracy: 0.9963\n",
      "Epoch 490/1000\n",
      "332/332 [==============================] - 16s 47ms/step - loss: 0.0026 - accuracy: 0.9993 - val_loss: 0.0040 - val_accuracy: 0.9991\n",
      "Epoch 491/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 0.0026 - accuracy: 0.9994 - val_loss: 0.0245 - val_accuracy: 0.9948\n",
      "Epoch 492/1000\n",
      "332/332 [==============================] - 16s 47ms/step - loss: 9.9160e-04 - accuracy: 0.9996 - val_loss: 0.0652 - val_accuracy: 0.9910\n",
      "Epoch 493/1000\n",
      "332/332 [==============================] - 16s 47ms/step - loss: 0.0013 - accuracy: 0.9997 - val_loss: 0.0028 - val_accuracy: 0.9994\n",
      "Epoch 494/1000\n",
      "332/332 [==============================] - 16s 47ms/step - loss: 0.0052 - accuracy: 0.9988 - val_loss: 0.0567 - val_accuracy: 0.9890\n",
      "Epoch 495/1000\n",
      "332/332 [==============================] - 17s 50ms/step - loss: 0.0016 - accuracy: 0.9994 - val_loss: 0.0011 - val_accuracy: 0.9995\n",
      "Epoch 496/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 0.0030 - accuracy: 0.9993 - val_loss: 0.0132 - val_accuracy: 0.9968\n",
      "Epoch 497/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 0.0014 - accuracy: 0.9996 - val_loss: 0.0068 - val_accuracy: 0.9978\n",
      "Epoch 498/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 0.0013 - accuracy: 0.9996 - val_loss: 0.1255 - val_accuracy: 0.9826\n",
      "Epoch 499/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 0.0017 - accuracy: 0.9995 - val_loss: 9.2840e-04 - val_accuracy: 0.9996\n",
      "Epoch 500/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 3.3930e-04 - accuracy: 0.9999 - val_loss: 0.0011 - val_accuracy: 0.9999\n",
      "Epoch 501/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 5.4163e-04 - accuracy: 0.9999 - val_loss: 2.0832e-04 - val_accuracy: 0.9999\n",
      "Epoch 502/1000\n",
      "332/332 [==============================] - 17s 50ms/step - loss: 0.0023 - accuracy: 0.9993 - val_loss: 0.0879 - val_accuracy: 0.9868\n",
      "Epoch 503/1000\n",
      "332/332 [==============================] - 17s 50ms/step - loss: 0.0061 - accuracy: 0.9985 - val_loss: 0.0835 - val_accuracy: 0.9871\n",
      "Epoch 504/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 0.0018 - accuracy: 0.9994 - val_loss: 0.0151 - val_accuracy: 0.9979\n",
      "Epoch 505/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 0.0011 - accuracy: 0.9995 - val_loss: 0.0034 - val_accuracy: 0.9992\n",
      "Epoch 506/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 0.0024 - accuracy: 0.9993 - val_loss: 0.0172 - val_accuracy: 0.9983\n",
      "Epoch 507/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 0.0021 - accuracy: 0.9995 - val_loss: 0.0912 - val_accuracy: 0.9844\n",
      "Epoch 508/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 0.0026 - accuracy: 0.9993 - val_loss: 0.0045 - val_accuracy: 0.9984\n",
      "Epoch 509/1000\n",
      "332/332 [==============================] - 16s 47ms/step - loss: 0.0017 - accuracy: 0.9996 - val_loss: 0.0025 - val_accuracy: 0.9987\n",
      "Epoch 510/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 0.0015 - accuracy: 0.9996 - val_loss: 0.2859 - val_accuracy: 0.9627\n",
      "Epoch 511/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 0.0050 - accuracy: 0.9988 - val_loss: 0.0126 - val_accuracy: 0.9961\n",
      "Epoch 512/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 0.0020 - accuracy: 0.9995 - val_loss: 8.5560e-05 - val_accuracy: 1.0000\n",
      "Epoch 513/1000\n",
      "332/332 [==============================] - 16s 47ms/step - loss: 6.4883e-04 - accuracy: 0.9997 - val_loss: 0.0109 - val_accuracy: 0.9969\n",
      "Epoch 514/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 0.0030 - accuracy: 0.9994 - val_loss: 6.1332e-05 - val_accuracy: 1.0000\n",
      "Epoch 515/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 0.0027 - accuracy: 0.9992 - val_loss: 0.0133 - val_accuracy: 0.9961\n",
      "Epoch 516/1000\n",
      "332/332 [==============================] - 15s 46ms/step - loss: 0.0047 - accuracy: 0.9989 - val_loss: 0.0076 - val_accuracy: 0.9978\n",
      "Epoch 517/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 0.0024 - accuracy: 0.9996 - val_loss: 4.8875e-04 - val_accuracy: 0.9997\n",
      "Epoch 518/1000\n",
      "332/332 [==============================] - 15s 46ms/step - loss: 0.0013 - accuracy: 0.9996 - val_loss: 0.0012 - val_accuracy: 0.9996\n",
      "Epoch 519/1000\n",
      "332/332 [==============================] - 16s 47ms/step - loss: 0.0014 - accuracy: 0.9994 - val_loss: 5.1133e-04 - val_accuracy: 0.9998\n",
      "Epoch 520/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 0.0012 - accuracy: 0.9996 - val_loss: 2.8099e-04 - val_accuracy: 0.9999\n",
      "Epoch 521/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 0.0020 - accuracy: 0.9994 - val_loss: 0.0120 - val_accuracy: 0.9961\n",
      "Epoch 522/1000\n",
      "332/332 [==============================] - 16s 47ms/step - loss: 0.0027 - accuracy: 0.9993 - val_loss: 0.0020 - val_accuracy: 0.9997\n",
      "Epoch 523/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 0.0023 - accuracy: 0.9994 - val_loss: 0.1098 - val_accuracy: 0.9786\n",
      "Epoch 524/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 0.0022 - accuracy: 0.9991 - val_loss: 0.0015 - val_accuracy: 0.9997\n",
      "Epoch 525/1000\n",
      "332/332 [==============================] - 16s 50ms/step - loss: 0.0061 - accuracy: 0.9985 - val_loss: 0.0048 - val_accuracy: 0.9987\n",
      "Epoch 526/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 0.0015 - accuracy: 0.9995 - val_loss: 3.7785e-05 - val_accuracy: 1.0000\n",
      "Epoch 527/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 3.7103e-04 - accuracy: 0.9999 - val_loss: 3.2274e-06 - val_accuracy: 1.0000\n",
      "Epoch 528/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 0.0040 - accuracy: 0.9988 - val_loss: 0.0817 - val_accuracy: 0.9816\n",
      "Epoch 529/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 0.0033 - accuracy: 0.9991 - val_loss: 0.0020 - val_accuracy: 0.9996\n",
      "Epoch 530/1000\n",
      "332/332 [==============================] - 16s 47ms/step - loss: 0.0011 - accuracy: 0.9998 - val_loss: 0.0300 - val_accuracy: 0.9938\n",
      "Epoch 531/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 0.0024 - accuracy: 0.9992 - val_loss: 0.0992 - val_accuracy: 0.9844\n",
      "Epoch 532/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 0.0046 - accuracy: 0.9989 - val_loss: 0.0518 - val_accuracy: 0.9895\n",
      "Epoch 533/1000\n",
      "332/332 [==============================] - 17s 50ms/step - loss: 7.7966e-04 - accuracy: 0.9997 - val_loss: 2.1863e-05 - val_accuracy: 1.0000\n",
      "Epoch 534/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 0.0015 - accuracy: 0.9996 - val_loss: 0.0301 - val_accuracy: 0.9931\n",
      "Epoch 535/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 0.0015 - accuracy: 0.9994 - val_loss: 1.1783e-04 - val_accuracy: 0.9999\n",
      "Epoch 536/1000\n",
      "332/332 [==============================] - 16s 47ms/step - loss: 0.0038 - accuracy: 0.9992 - val_loss: 0.0074 - val_accuracy: 0.9980\n",
      "Epoch 537/1000\n",
      "332/332 [==============================] - 16s 47ms/step - loss: 0.0022 - accuracy: 0.9993 - val_loss: 8.4285e-04 - val_accuracy: 0.9997\n",
      "Epoch 538/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 9.3841e-04 - accuracy: 0.9997 - val_loss: 4.9689e-04 - val_accuracy: 0.9999\n",
      "Epoch 539/1000\n",
      "332/332 [==============================] - 15s 46ms/step - loss: 7.5381e-04 - accuracy: 0.9997 - val_loss: 8.8876e-04 - val_accuracy: 0.9994\n",
      "Epoch 540/1000\n",
      "332/332 [==============================] - 16s 50ms/step - loss: 0.0018 - accuracy: 0.9996 - val_loss: 0.0385 - val_accuracy: 0.9924\n",
      "Epoch 541/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 0.0041 - accuracy: 0.9989 - val_loss: 0.0012 - val_accuracy: 0.9995\n",
      "Epoch 542/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 5.2766e-04 - accuracy: 0.9998 - val_loss: 1.1373e-05 - val_accuracy: 1.0000\n",
      "Epoch 543/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 6.5114e-04 - accuracy: 0.9998 - val_loss: 4.2742e-04 - val_accuracy: 0.9998\n",
      "Epoch 544/1000\n",
      "332/332 [==============================] - 16s 47ms/step - loss: 1.5968e-04 - accuracy: 0.9999 - val_loss: 3.5180e-04 - val_accuracy: 0.9999\n",
      "Epoch 545/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 4.0193e-04 - accuracy: 0.9999 - val_loss: 7.6037e-04 - val_accuracy: 0.9999\n",
      "Epoch 546/1000\n",
      "332/332 [==============================] - 16s 47ms/step - loss: 1.4250e-04 - accuracy: 0.9999 - val_loss: 5.5485e-04 - val_accuracy: 0.9999\n",
      "Epoch 547/1000\n",
      "332/332 [==============================] - 16s 47ms/step - loss: 0.0043 - accuracy: 0.9989 - val_loss: 0.0924 - val_accuracy: 0.9833\n",
      "Epoch 548/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 0.0045 - accuracy: 0.9988 - val_loss: 0.0076 - val_accuracy: 0.9976\n",
      "Epoch 549/1000\n",
      "332/332 [==============================] - 16s 47ms/step - loss: 0.0067 - accuracy: 0.9987 - val_loss: 0.0557 - val_accuracy: 0.9892\n",
      "Epoch 550/1000\n",
      "332/332 [==============================] - 16s 47ms/step - loss: 9.2265e-04 - accuracy: 0.9997 - val_loss: 0.0024 - val_accuracy: 0.9994\n",
      "Epoch 551/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 0.0038 - accuracy: 0.9991 - val_loss: 0.0178 - val_accuracy: 0.9947\n",
      "Epoch 552/1000\n",
      "332/332 [==============================] - 17s 50ms/step - loss: 0.0018 - accuracy: 0.9996 - val_loss: 8.7149e-04 - val_accuracy: 0.9997\n",
      "Epoch 553/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 0.0022 - accuracy: 0.9995 - val_loss: 0.0256 - val_accuracy: 0.9948\n",
      "Epoch 554/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 0.0028 - accuracy: 0.9995 - val_loss: 0.0661 - val_accuracy: 0.9840\n",
      "Epoch 555/1000\n",
      "332/332 [==============================] - 15s 46ms/step - loss: 0.0021 - accuracy: 0.9994 - val_loss: 0.0021 - val_accuracy: 0.9992\n",
      "Epoch 556/1000\n",
      "332/332 [==============================] - 15s 46ms/step - loss: 3.4852e-04 - accuracy: 0.9998 - val_loss: 9.6204e-05 - val_accuracy: 1.0000\n",
      "Epoch 557/1000\n",
      "332/332 [==============================] - 15s 46ms/step - loss: 9.2992e-04 - accuracy: 0.9997 - val_loss: 4.8282e-04 - val_accuracy: 0.9998\n",
      "Epoch 558/1000\n",
      "332/332 [==============================] - 15s 46ms/step - loss: 0.0014 - accuracy: 0.9996 - val_loss: 3.2736e-05 - val_accuracy: 1.0000\n",
      "Epoch 559/1000\n",
      "332/332 [==============================] - 15s 46ms/step - loss: 0.0024 - accuracy: 0.9994 - val_loss: 0.0047 - val_accuracy: 0.9991\n",
      "Epoch 560/1000\n",
      "332/332 [==============================] - 15s 46ms/step - loss: 0.0033 - accuracy: 0.9991 - val_loss: 0.1918 - val_accuracy: 0.9744\n",
      "Epoch 561/1000\n",
      "332/332 [==============================] - 15s 46ms/step - loss: 0.0041 - accuracy: 0.9989 - val_loss: 0.1028 - val_accuracy: 0.9806\n",
      "Epoch 562/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 0.0017 - accuracy: 0.9995 - val_loss: 0.0011 - val_accuracy: 0.9997\n",
      "Epoch 563/1000\n",
      "332/332 [==============================] - 16s 47ms/step - loss: 0.0015 - accuracy: 0.9996 - val_loss: 9.5262e-06 - val_accuracy: 1.0000\n",
      "Epoch 564/1000\n",
      "332/332 [==============================] - 16s 47ms/step - loss: 1.5500e-04 - accuracy: 1.0000 - val_loss: 4.0195e-04 - val_accuracy: 0.9999\n",
      "Epoch 565/1000\n",
      "332/332 [==============================] - 15s 46ms/step - loss: 1.1826e-04 - accuracy: 0.9999 - val_loss: 3.2209e-06 - val_accuracy: 1.0000\n",
      "Epoch 566/1000\n",
      "332/332 [==============================] - 15s 46ms/step - loss: 2.2374e-05 - accuracy: 1.0000 - val_loss: 3.3559e-05 - val_accuracy: 1.0000\n",
      "Epoch 567/1000\n",
      "332/332 [==============================] - 15s 46ms/step - loss: 0.0011 - accuracy: 0.9997 - val_loss: 0.4565 - val_accuracy: 0.9493\n",
      "Epoch 568/1000\n",
      "332/332 [==============================] - 15s 46ms/step - loss: 0.0069 - accuracy: 0.9982 - val_loss: 8.7040e-05 - val_accuracy: 1.0000\n",
      "Epoch 569/1000\n",
      "332/332 [==============================] - 16s 50ms/step - loss: 0.0011 - accuracy: 0.9996 - val_loss: 0.0690 - val_accuracy: 0.9872\n",
      "Epoch 570/1000\n",
      "332/332 [==============================] - 15s 46ms/step - loss: 0.0036 - accuracy: 0.9991 - val_loss: 0.0018 - val_accuracy: 0.9991\n",
      "Epoch 571/1000\n",
      "332/332 [==============================] - 15s 46ms/step - loss: 0.0013 - accuracy: 0.9995 - val_loss: 0.0249 - val_accuracy: 0.9930\n",
      "Epoch 572/1000\n",
      "332/332 [==============================] - 15s 46ms/step - loss: 0.0013 - accuracy: 0.9996 - val_loss: 0.0023 - val_accuracy: 0.9994\n",
      "Epoch 573/1000\n",
      "332/332 [==============================] - 15s 46ms/step - loss: 2.1491e-04 - accuracy: 0.9999 - val_loss: 0.0013 - val_accuracy: 0.9998\n",
      "Epoch 574/1000\n",
      "332/332 [==============================] - 16s 47ms/step - loss: 4.2920e-04 - accuracy: 0.9999 - val_loss: 3.3497e-04 - val_accuracy: 0.9999\n",
      "Epoch 575/1000\n",
      "332/332 [==============================] - 16s 50ms/step - loss: 0.0037 - accuracy: 0.9989 - val_loss: 0.0042 - val_accuracy: 0.9988\n",
      "Epoch 576/1000\n",
      "332/332 [==============================] - 15s 46ms/step - loss: 0.0042 - accuracy: 0.9990 - val_loss: 6.1874e-04 - val_accuracy: 0.9997\n",
      "Epoch 577/1000\n",
      "332/332 [==============================] - 15s 46ms/step - loss: 0.0030 - accuracy: 0.9992 - val_loss: 0.0056 - val_accuracy: 0.9990\n",
      "Epoch 578/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 0.0033 - accuracy: 0.9991 - val_loss: 0.0010 - val_accuracy: 0.9997\n",
      "Epoch 579/1000\n",
      "332/332 [==============================] - 15s 46ms/step - loss: 0.0012 - accuracy: 0.9996 - val_loss: 0.0151 - val_accuracy: 0.9964\n",
      "Epoch 580/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 9.0204e-04 - accuracy: 0.9995 - val_loss: 4.4048e-04 - val_accuracy: 0.9999\n",
      "Epoch 581/1000\n",
      "332/332 [==============================] - 15s 46ms/step - loss: 8.9553e-04 - accuracy: 0.9998 - val_loss: 6.9965e-04 - val_accuracy: 0.9996\n",
      "Epoch 582/1000\n",
      "332/332 [==============================] - 15s 46ms/step - loss: 3.7755e-04 - accuracy: 0.9998 - val_loss: 2.7080e-04 - val_accuracy: 0.9999\n",
      "Epoch 583/1000\n",
      "332/332 [==============================] - 15s 46ms/step - loss: 0.0013 - accuracy: 0.9997 - val_loss: 0.0329 - val_accuracy: 0.9946\n",
      "Epoch 584/1000\n",
      "332/332 [==============================] - 16s 47ms/step - loss: 0.0019 - accuracy: 0.9994 - val_loss: 0.0218 - val_accuracy: 0.9946\n",
      "Epoch 585/1000\n",
      "332/332 [==============================] - 16s 47ms/step - loss: 0.0025 - accuracy: 0.9994 - val_loss: 2.5561e-04 - val_accuracy: 0.9999\n",
      "Epoch 586/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 5.4223e-04 - accuracy: 0.9998 - val_loss: 0.0210 - val_accuracy: 0.9963\n",
      "Epoch 587/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 0.0047 - accuracy: 0.9989 - val_loss: 0.0081 - val_accuracy: 0.9975\n",
      "Epoch 588/1000\n",
      "332/332 [==============================] - 15s 46ms/step - loss: 0.0023 - accuracy: 0.9994 - val_loss: 0.0483 - val_accuracy: 0.9913\n",
      "Epoch 589/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 0.0034 - accuracy: 0.9991 - val_loss: 0.0102 - val_accuracy: 0.9969\n",
      "Epoch 590/1000\n",
      "332/332 [==============================] - 15s 46ms/step - loss: 9.1536e-04 - accuracy: 0.9997 - val_loss: 0.0035 - val_accuracy: 0.9997\n",
      "Epoch 591/1000\n",
      "332/332 [==============================] - 15s 46ms/step - loss: 5.1677e-04 - accuracy: 0.9999 - val_loss: 0.0013 - val_accuracy: 0.9999\n",
      "Epoch 592/1000\n",
      "332/332 [==============================] - 16s 47ms/step - loss: 0.0012 - accuracy: 0.9997 - val_loss: 0.1499 - val_accuracy: 0.9831\n",
      "Epoch 593/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 0.0038 - accuracy: 0.9988 - val_loss: 0.0422 - val_accuracy: 0.9944\n",
      "Epoch 594/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 0.0023 - accuracy: 0.9995 - val_loss: 4.9326e-06 - val_accuracy: 1.0000\n",
      "Epoch 595/1000\n",
      "332/332 [==============================] - 15s 46ms/step - loss: 0.0023 - accuracy: 0.9994 - val_loss: 0.0023 - val_accuracy: 0.9992\n",
      "Epoch 596/1000\n",
      "332/332 [==============================] - 15s 46ms/step - loss: 0.0026 - accuracy: 0.9994 - val_loss: 0.0036 - val_accuracy: 0.9991\n",
      "Epoch 597/1000\n",
      "332/332 [==============================] - 15s 46ms/step - loss: 0.0015 - accuracy: 0.9995 - val_loss: 0.0182 - val_accuracy: 0.9948\n",
      "Epoch 598/1000\n",
      "332/332 [==============================] - 15s 46ms/step - loss: 0.0038 - accuracy: 0.9990 - val_loss: 7.0445e-04 - val_accuracy: 0.9996\n",
      "Epoch 599/1000\n",
      "332/332 [==============================] - 15s 46ms/step - loss: 0.0011 - accuracy: 0.9995 - val_loss: 8.7447e-04 - val_accuracy: 0.9997\n",
      "Epoch 600/1000\n",
      "332/332 [==============================] - 16s 47ms/step - loss: 6.8027e-04 - accuracy: 0.9997 - val_loss: 2.0226e-07 - val_accuracy: 1.0000\n",
      "Epoch 601/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 0.0010 - accuracy: 0.9997 - val_loss: 0.0027 - val_accuracy: 0.9993\n",
      "Epoch 602/1000\n",
      "332/332 [==============================] - 16s 47ms/step - loss: 7.7884e-04 - accuracy: 0.9997 - val_loss: 0.0015 - val_accuracy: 0.9994\n",
      "Epoch 603/1000\n",
      "332/332 [==============================] - 16s 47ms/step - loss: 4.8627e-04 - accuracy: 0.9999 - val_loss: 1.4388e-06 - val_accuracy: 1.0000\n",
      "Epoch 604/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 8.6048e-05 - accuracy: 1.0000 - val_loss: 1.3916e-06 - val_accuracy: 1.0000\n",
      "Epoch 605/1000\n",
      "332/332 [==============================] - 17s 50ms/step - loss: 1.6347e-04 - accuracy: 1.0000 - val_loss: 5.2101e-05 - val_accuracy: 1.0000\n",
      "Epoch 606/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 0.0089 - accuracy: 0.9980 - val_loss: 0.0117 - val_accuracy: 0.9970\n",
      "Epoch 607/1000\n",
      "332/332 [==============================] - 16s 47ms/step - loss: 0.0031 - accuracy: 0.9992 - val_loss: 0.0184 - val_accuracy: 0.9961\n",
      "Epoch 608/1000\n",
      "332/332 [==============================] - 16s 47ms/step - loss: 0.0023 - accuracy: 0.9993 - val_loss: 0.0118 - val_accuracy: 0.9970\n",
      "Epoch 609/1000\n",
      "332/332 [==============================] - 16s 47ms/step - loss: 0.0036 - accuracy: 0.9991 - val_loss: 0.1615 - val_accuracy: 0.9795\n",
      "Epoch 610/1000\n",
      "332/332 [==============================] - 16s 47ms/step - loss: 0.0011 - accuracy: 0.9997 - val_loss: 0.0080 - val_accuracy: 0.9977\n",
      "Epoch 611/1000\n",
      "332/332 [==============================] - 16s 47ms/step - loss: 8.2374e-04 - accuracy: 0.9997 - val_loss: 8.7894e-04 - val_accuracy: 0.9996\n",
      "Epoch 612/1000\n",
      "332/332 [==============================] - 16s 47ms/step - loss: 0.0017 - accuracy: 0.9997 - val_loss: 0.0150 - val_accuracy: 0.9957\n",
      "Epoch 613/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 0.0019 - accuracy: 0.9994 - val_loss: 0.0812 - val_accuracy: 0.9867\n",
      "Epoch 614/1000\n",
      "332/332 [==============================] - 16s 47ms/step - loss: 0.0029 - accuracy: 0.9992 - val_loss: 0.1298 - val_accuracy: 0.9805\n",
      "Epoch 615/1000\n",
      "332/332 [==============================] - 16s 47ms/step - loss: 0.0021 - accuracy: 0.9995 - val_loss: 0.0047 - val_accuracy: 0.9989\n",
      "Epoch 616/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 0.0012 - accuracy: 0.9996 - val_loss: 4.6920e-04 - val_accuracy: 0.9998\n",
      "Epoch 617/1000\n",
      "332/332 [==============================] - 16s 47ms/step - loss: 6.2966e-05 - accuracy: 1.0000 - val_loss: 1.1198e-07 - val_accuracy: 1.0000\n",
      "Epoch 618/1000\n",
      "332/332 [==============================] - 16s 47ms/step - loss: 6.4574e-04 - accuracy: 0.9999 - val_loss: 0.0018 - val_accuracy: 0.9999\n",
      "Epoch 619/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 0.0035 - accuracy: 0.9991 - val_loss: 0.0691 - val_accuracy: 0.9866\n",
      "Epoch 620/1000\n",
      "332/332 [==============================] - 16s 47ms/step - loss: 0.0054 - accuracy: 0.9988 - val_loss: 0.0027 - val_accuracy: 0.9992\n",
      "Epoch 621/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 2.6158e-04 - accuracy: 0.9999 - val_loss: 8.4713e-04 - val_accuracy: 0.9999\n",
      "Epoch 622/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 0.0018 - accuracy: 0.9996 - val_loss: 0.0048 - val_accuracy: 0.9988\n",
      "Epoch 623/1000\n",
      "332/332 [==============================] - 16s 47ms/step - loss: 0.0036 - accuracy: 0.9990 - val_loss: 2.1602e-04 - val_accuracy: 0.9999\n",
      "Epoch 624/1000\n",
      "332/332 [==============================] - 15s 46ms/step - loss: 0.0035 - accuracy: 0.9992 - val_loss: 0.1578 - val_accuracy: 0.9783\n",
      "Epoch 625/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 0.0033 - accuracy: 0.9990 - val_loss: 0.0095 - val_accuracy: 0.9974\n",
      "Epoch 626/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 0.0012 - accuracy: 0.9997 - val_loss: 8.0668e-04 - val_accuracy: 0.9999\n",
      "Epoch 627/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 9.1003e-05 - accuracy: 1.0000 - val_loss: 0.0012 - val_accuracy: 0.9998\n",
      "Epoch 628/1000\n",
      "332/332 [==============================] - 16s 47ms/step - loss: 0.0018 - accuracy: 0.9995 - val_loss: 0.0073 - val_accuracy: 0.9981\n",
      "Epoch 629/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 0.0026 - accuracy: 0.9994 - val_loss: 0.0131 - val_accuracy: 0.9956\n",
      "Epoch 630/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 0.0030 - accuracy: 0.9991 - val_loss: 0.0044 - val_accuracy: 0.9990\n",
      "Epoch 631/1000\n",
      "332/332 [==============================] - 15s 46ms/step - loss: 0.0020 - accuracy: 0.9994 - val_loss: 0.2402 - val_accuracy: 0.9671\n",
      "Epoch 632/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 0.0032 - accuracy: 0.9991 - val_loss: 0.0035 - val_accuracy: 0.9992\n",
      "Epoch 633/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 0.0014 - accuracy: 0.9996 - val_loss: 5.4596e-06 - val_accuracy: 1.0000\n",
      "Epoch 634/1000\n",
      "332/332 [==============================] - 17s 50ms/step - loss: 0.0013 - accuracy: 0.9996 - val_loss: 0.0011 - val_accuracy: 0.9995\n",
      "Epoch 635/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 0.0023 - accuracy: 0.9994 - val_loss: 0.0517 - val_accuracy: 0.9918\n",
      "Epoch 636/1000\n",
      "332/332 [==============================] - 16s 47ms/step - loss: 0.0033 - accuracy: 0.9990 - val_loss: 0.0731 - val_accuracy: 0.9848\n",
      "Epoch 637/1000\n",
      "332/332 [==============================] - 16s 47ms/step - loss: 0.0020 - accuracy: 0.9993 - val_loss: 0.0051 - val_accuracy: 0.9993\n",
      "Epoch 638/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 0.0014 - accuracy: 0.9996 - val_loss: 0.0025 - val_accuracy: 0.9994\n",
      "Epoch 639/1000\n",
      "332/332 [==============================] - 17s 50ms/step - loss: 0.0016 - accuracy: 0.9996 - val_loss: 5.2462e-04 - val_accuracy: 0.9999\n",
      "Epoch 640/1000\n",
      "332/332 [==============================] - 15s 46ms/step - loss: 0.0032 - accuracy: 0.9992 - val_loss: 0.0138 - val_accuracy: 0.9974\n",
      "Epoch 641/1000\n",
      "332/332 [==============================] - 16s 47ms/step - loss: 0.0013 - accuracy: 0.9997 - val_loss: 4.0315e-04 - val_accuracy: 0.9999\n",
      "Epoch 642/1000\n",
      "332/332 [==============================] - 17s 50ms/step - loss: 0.0053 - accuracy: 0.9989 - val_loss: 0.0025 - val_accuracy: 0.9993\n",
      "Epoch 643/1000\n",
      "332/332 [==============================] - 17s 50ms/step - loss: 0.0015 - accuracy: 0.9996 - val_loss: 0.0283 - val_accuracy: 0.9938\n",
      "Epoch 644/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 0.0036 - accuracy: 0.9992 - val_loss: 0.0067 - val_accuracy: 0.9984\n",
      "Epoch 645/1000\n",
      "332/332 [==============================] - 16s 47ms/step - loss: 7.6840e-04 - accuracy: 0.9997 - val_loss: 0.0026 - val_accuracy: 0.9991\n",
      "Epoch 646/1000\n",
      "332/332 [==============================] - 16s 47ms/step - loss: 7.3099e-04 - accuracy: 0.9997 - val_loss: 0.0087 - val_accuracy: 0.9980\n",
      "Epoch 647/1000\n",
      "332/332 [==============================] - 17s 50ms/step - loss: 0.0021 - accuracy: 0.9995 - val_loss: 0.0013 - val_accuracy: 0.9999\n",
      "Epoch 648/1000\n",
      "332/332 [==============================] - 16s 47ms/step - loss: 2.2500e-04 - accuracy: 0.9999 - val_loss: 7.7127e-04 - val_accuracy: 0.9999\n",
      "Epoch 649/1000\n",
      "332/332 [==============================] - 16s 47ms/step - loss: 2.7749e-04 - accuracy: 0.9999 - val_loss: 0.0014 - val_accuracy: 0.9994\n",
      "Epoch 650/1000\n",
      "332/332 [==============================] - 16s 47ms/step - loss: 0.0035 - accuracy: 0.9992 - val_loss: 0.0200 - val_accuracy: 0.9948\n",
      "Epoch 651/1000\n",
      "332/332 [==============================] - 16s 47ms/step - loss: 0.0094 - accuracy: 0.9980 - val_loss: 0.0113 - val_accuracy: 0.9985\n",
      "Epoch 652/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 0.0019 - accuracy: 0.9995 - val_loss: 0.0260 - val_accuracy: 0.9954\n",
      "Epoch 653/1000\n",
      "332/332 [==============================] - 16s 47ms/step - loss: 4.2640e-04 - accuracy: 0.9999 - val_loss: 4.3166e-04 - val_accuracy: 0.9998\n",
      "Epoch 654/1000\n",
      "332/332 [==============================] - 16s 47ms/step - loss: 7.9453e-05 - accuracy: 1.0000 - val_loss: 0.0011 - val_accuracy: 0.9999\n",
      "Epoch 655/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 0.0022 - accuracy: 0.9994 - val_loss: 0.0066 - val_accuracy: 0.9981\n",
      "Epoch 656/1000\n",
      "332/332 [==============================] - 16s 47ms/step - loss: 0.0029 - accuracy: 0.9994 - val_loss: 0.0026 - val_accuracy: 0.9992\n",
      "Epoch 657/1000\n",
      "332/332 [==============================] - 17s 50ms/step - loss: 0.0016 - accuracy: 0.9996 - val_loss: 4.6028e-04 - val_accuracy: 0.9998\n",
      "Epoch 658/1000\n",
      "332/332 [==============================] - 16s 47ms/step - loss: 0.0014 - accuracy: 0.9997 - val_loss: 0.0380 - val_accuracy: 0.9936\n",
      "Epoch 659/1000\n",
      "332/332 [==============================] - 16s 47ms/step - loss: 0.0036 - accuracy: 0.9993 - val_loss: 0.0355 - val_accuracy: 0.9930\n",
      "Epoch 660/1000\n",
      "332/332 [==============================] - 16s 47ms/step - loss: 0.0034 - accuracy: 0.9992 - val_loss: 0.0059 - val_accuracy: 0.9986\n",
      "Epoch 661/1000\n",
      "332/332 [==============================] - 17s 50ms/step - loss: 0.0020 - accuracy: 0.9996 - val_loss: 0.0018 - val_accuracy: 0.9998\n",
      "Epoch 662/1000\n",
      "332/332 [==============================] - 16s 47ms/step - loss: 4.2554e-04 - accuracy: 0.9998 - val_loss: 0.0011 - val_accuracy: 0.9998\n",
      "Epoch 663/1000\n",
      "332/332 [==============================] - 16s 47ms/step - loss: 0.0010 - accuracy: 0.9997 - val_loss: 0.0201 - val_accuracy: 0.9958\n",
      "Epoch 664/1000\n",
      "332/332 [==============================] - 16s 47ms/step - loss: 0.0032 - accuracy: 0.9992 - val_loss: 0.0020 - val_accuracy: 0.9996\n",
      "Epoch 665/1000\n",
      "332/332 [==============================] - 16s 47ms/step - loss: 4.8593e-04 - accuracy: 0.9998 - val_loss: 0.0599 - val_accuracy: 0.9886\n",
      "Epoch 666/1000\n",
      "332/332 [==============================] - 16s 47ms/step - loss: 0.0015 - accuracy: 0.9996 - val_loss: 0.0020 - val_accuracy: 0.9996\n",
      "Epoch 667/1000\n",
      "332/332 [==============================] - 16s 47ms/step - loss: 8.5841e-04 - accuracy: 0.9997 - val_loss: 0.0019 - val_accuracy: 0.9997\n",
      "Epoch 668/1000\n",
      "332/332 [==============================] - 16s 47ms/step - loss: 0.0037 - accuracy: 0.9989 - val_loss: 0.0092 - val_accuracy: 0.9975\n",
      "Epoch 669/1000\n",
      "332/332 [==============================] - 17s 50ms/step - loss: 0.0043 - accuracy: 0.9989 - val_loss: 0.0017 - val_accuracy: 0.9995\n",
      "Epoch 670/1000\n",
      "332/332 [==============================] - 16s 47ms/step - loss: 0.0023 - accuracy: 0.9993 - val_loss: 0.0039 - val_accuracy: 0.9992\n",
      "Epoch 671/1000\n",
      "332/332 [==============================] - 16s 47ms/step - loss: 0.0017 - accuracy: 0.9995 - val_loss: 0.0012 - val_accuracy: 0.9998\n",
      "Epoch 672/1000\n",
      "332/332 [==============================] - 17s 50ms/step - loss: 9.6479e-04 - accuracy: 0.9997 - val_loss: 0.0016 - val_accuracy: 0.9995\n",
      "Epoch 673/1000\n",
      "332/332 [==============================] - 16s 47ms/step - loss: 0.0020 - accuracy: 0.9995 - val_loss: 0.1255 - val_accuracy: 0.9799\n",
      "Epoch 674/1000\n",
      "332/332 [==============================] - 17s 50ms/step - loss: 0.0016 - accuracy: 0.9995 - val_loss: 0.0019 - val_accuracy: 0.9998\n",
      "Epoch 675/1000\n",
      "332/332 [==============================] - 16s 47ms/step - loss: 0.0035 - accuracy: 0.9991 - val_loss: 0.0811 - val_accuracy: 0.9862\n",
      "Epoch 676/1000\n",
      "332/332 [==============================] - 16s 47ms/step - loss: 0.0058 - accuracy: 0.9989 - val_loss: 0.0033 - val_accuracy: 0.9992\n",
      "Epoch 677/1000\n",
      "332/332 [==============================] - 16s 47ms/step - loss: 0.0014 - accuracy: 0.9996 - val_loss: 8.8692e-04 - val_accuracy: 0.9999\n",
      "Epoch 678/1000\n",
      "332/332 [==============================] - 16s 47ms/step - loss: 2.6413e-04 - accuracy: 0.9999 - val_loss: 1.3677e-05 - val_accuracy: 1.0000\n",
      "Epoch 679/1000\n",
      "332/332 [==============================] - 16s 47ms/step - loss: 0.0011 - accuracy: 0.9996 - val_loss: 0.0281 - val_accuracy: 0.9938\n",
      "Epoch 680/1000\n",
      "332/332 [==============================] - 16s 47ms/step - loss: 0.0041 - accuracy: 0.9990 - val_loss: 0.0012 - val_accuracy: 0.9995\n",
      "Epoch 681/1000\n",
      "332/332 [==============================] - 16s 47ms/step - loss: 0.0033 - accuracy: 0.9992 - val_loss: 0.0053 - val_accuracy: 0.9990\n",
      "Epoch 682/1000\n",
      "332/332 [==============================] - 16s 47ms/step - loss: 0.0024 - accuracy: 0.9994 - val_loss: 0.0397 - val_accuracy: 0.9939\n",
      "Epoch 683/1000\n",
      "332/332 [==============================] - 17s 50ms/step - loss: 0.0027 - accuracy: 0.9992 - val_loss: 7.9226e-04 - val_accuracy: 0.9997\n",
      "Epoch 684/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 9.3237e-04 - accuracy: 0.9997 - val_loss: 2.8448e-04 - val_accuracy: 0.9999\n",
      "Epoch 685/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 2.1442e-04 - accuracy: 1.0000 - val_loss: 5.9632e-06 - val_accuracy: 1.0000\n",
      "Epoch 686/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 0.0011 - accuracy: 0.9996 - val_loss: 0.0011 - val_accuracy: 0.9997\n",
      "Epoch 687/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 0.0039 - accuracy: 0.9992 - val_loss: 0.0024 - val_accuracy: 0.9992\n",
      "Epoch 688/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 0.0028 - accuracy: 0.9994 - val_loss: 3.1527e-04 - val_accuracy: 0.9998\n",
      "Epoch 689/1000\n",
      "332/332 [==============================] - 16s 47ms/step - loss: 6.9985e-04 - accuracy: 0.9999 - val_loss: 0.0174 - val_accuracy: 0.9958\n",
      "Epoch 690/1000\n",
      "332/332 [==============================] - 17s 50ms/step - loss: 0.0026 - accuracy: 0.9993 - val_loss: 0.0269 - val_accuracy: 0.9954\n",
      "Epoch 691/1000\n",
      "332/332 [==============================] - 16s 47ms/step - loss: 0.0041 - accuracy: 0.9991 - val_loss: 0.0073 - val_accuracy: 0.9981\n",
      "Epoch 692/1000\n",
      "332/332 [==============================] - 15s 46ms/step - loss: 0.0010 - accuracy: 0.9997 - val_loss: 0.0041 - val_accuracy: 0.9990\n",
      "Epoch 693/1000\n",
      "332/332 [==============================] - 16s 49ms/step - loss: 0.0025 - accuracy: 0.9996 - val_loss: 6.5279e-06 - val_accuracy: 1.0000\n",
      "Epoch 694/1000\n",
      "332/332 [==============================] - 17s 50ms/step - loss: 0.0010 - accuracy: 0.9997 - val_loss: 0.0013 - val_accuracy: 0.9995\n",
      "Epoch 695/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 2.0365e-04 - accuracy: 0.9999 - val_loss: 7.8687e-05 - val_accuracy: 1.0000\n",
      "Epoch 696/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 0.0016 - accuracy: 0.9995 - val_loss: 0.1385 - val_accuracy: 0.9752\n",
      "Epoch 697/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 0.0020 - accuracy: 0.9995 - val_loss: 0.0426 - val_accuracy: 0.9919\n",
      "Epoch 698/1000\n",
      "332/332 [==============================] - 16s 47ms/step - loss: 0.0026 - accuracy: 0.9994 - val_loss: 0.0218 - val_accuracy: 0.9956\n",
      "Epoch 699/1000\n",
      "332/332 [==============================] - 16s 47ms/step - loss: 0.0011 - accuracy: 0.9996 - val_loss: 0.1106 - val_accuracy: 0.9815\n",
      "Epoch 700/1000\n",
      "332/332 [==============================] - 17s 50ms/step - loss: 0.0052 - accuracy: 0.9986 - val_loss: 0.0047 - val_accuracy: 0.9985\n",
      "Epoch 701/1000\n",
      "332/332 [==============================] - 16s 47ms/step - loss: 0.0017 - accuracy: 0.9996 - val_loss: 0.0141 - val_accuracy: 0.9964\n",
      "Epoch 702/1000\n",
      "332/332 [==============================] - 16s 47ms/step - loss: 6.5114e-04 - accuracy: 0.9998 - val_loss: 0.0010 - val_accuracy: 0.9999\n",
      "Epoch 703/1000\n",
      "332/332 [==============================] - 16s 47ms/step - loss: 0.0022 - accuracy: 0.9995 - val_loss: 0.0033 - val_accuracy: 0.9996\n",
      "Epoch 704/1000\n",
      "332/332 [==============================] - 16s 47ms/step - loss: 0.0012 - accuracy: 0.9996 - val_loss: 0.0015 - val_accuracy: 0.9997\n",
      "Epoch 705/1000\n",
      "332/332 [==============================] - 16s 47ms/step - loss: 0.0012 - accuracy: 0.9996 - val_loss: 0.0047 - val_accuracy: 0.9990\n",
      "Epoch 706/1000\n",
      "332/332 [==============================] - 16s 47ms/step - loss: 0.0025 - accuracy: 0.9994 - val_loss: 0.0034 - val_accuracy: 0.9995\n",
      "Epoch 707/1000\n",
      "332/332 [==============================] - 16s 47ms/step - loss: 0.0011 - accuracy: 0.9996 - val_loss: 0.0083 - val_accuracy: 0.9975\n",
      "Epoch 708/1000\n",
      "332/332 [==============================] - 16s 47ms/step - loss: 9.0434e-04 - accuracy: 0.9997 - val_loss: 0.0895 - val_accuracy: 0.9875\n",
      "Epoch 709/1000\n",
      "332/332 [==============================] - 16s 47ms/step - loss: 8.6815e-04 - accuracy: 0.9997 - val_loss: 0.0032 - val_accuracy: 0.9993\n",
      "Epoch 710/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 0.0011 - accuracy: 0.9998 - val_loss: 4.7269e-04 - val_accuracy: 0.9999\n",
      "Epoch 711/1000\n",
      "332/332 [==============================] - 17s 50ms/step - loss: 2.0606e-04 - accuracy: 0.9999 - val_loss: 0.0045 - val_accuracy: 0.9992\n",
      "Epoch 712/1000\n",
      "332/332 [==============================] - 16s 47ms/step - loss: 2.4994e-04 - accuracy: 0.9999 - val_loss: 3.2660e-05 - val_accuracy: 1.0000\n",
      "Epoch 713/1000\n",
      "332/332 [==============================] - 16s 47ms/step - loss: 0.0080 - accuracy: 0.9983 - val_loss: 0.1850 - val_accuracy: 0.9751\n",
      "Epoch 714/1000\n",
      "332/332 [==============================] - 17s 50ms/step - loss: 0.0032 - accuracy: 0.9993 - val_loss: 0.0034 - val_accuracy: 0.9992\n",
      "Epoch 715/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 0.0016 - accuracy: 0.9997 - val_loss: 0.0408 - val_accuracy: 0.9935\n",
      "Epoch 716/1000\n",
      "332/332 [==============================] - 16s 47ms/step - loss: 0.0032 - accuracy: 0.9990 - val_loss: 3.8278e-04 - val_accuracy: 0.9999\n",
      "Epoch 717/1000\n",
      "332/332 [==============================] - 17s 50ms/step - loss: 0.0015 - accuracy: 0.9996 - val_loss: 3.7543e-04 - val_accuracy: 0.9999\n",
      "Epoch 718/1000\n",
      "332/332 [==============================] - 17s 50ms/step - loss: 0.0018 - accuracy: 0.9994 - val_loss: 0.0075 - val_accuracy: 0.9990\n",
      "Epoch 719/1000\n",
      "332/332 [==============================] - 16s 47ms/step - loss: 0.0085 - accuracy: 0.9982 - val_loss: 5.2560e-04 - val_accuracy: 0.9996\n",
      "Epoch 720/1000\n",
      "332/332 [==============================] - 16s 47ms/step - loss: 0.0019 - accuracy: 0.9996 - val_loss: 0.0052 - val_accuracy: 0.9983\n",
      "Epoch 721/1000\n",
      "332/332 [==============================] - 16s 47ms/step - loss: 0.0011 - accuracy: 0.9996 - val_loss: 0.0022 - val_accuracy: 0.9998\n",
      "Epoch 722/1000\n",
      "332/332 [==============================] - 16s 47ms/step - loss: 0.0013 - accuracy: 0.9996 - val_loss: 2.8449e-04 - val_accuracy: 0.9999\n",
      "Epoch 723/1000\n",
      "332/332 [==============================] - 17s 50ms/step - loss: 0.0027 - accuracy: 0.9993 - val_loss: 0.0011 - val_accuracy: 0.9997\n",
      "Epoch 724/1000\n",
      "332/332 [==============================] - 16s 47ms/step - loss: 0.0023 - accuracy: 0.9994 - val_loss: 6.4644e-04 - val_accuracy: 0.9999\n",
      "Epoch 725/1000\n",
      "332/332 [==============================] - 16s 47ms/step - loss: 9.7461e-04 - accuracy: 0.9997 - val_loss: 0.0131 - val_accuracy: 0.9968\n",
      "Epoch 726/1000\n",
      "332/332 [==============================] - 16s 47ms/step - loss: 0.0017 - accuracy: 0.9996 - val_loss: 2.9998e-04 - val_accuracy: 0.9999\n",
      "Epoch 727/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 0.0016 - accuracy: 0.9996 - val_loss: 3.2500e-04 - val_accuracy: 0.9999\n",
      "Epoch 728/1000\n",
      "332/332 [==============================] - 16s 47ms/step - loss: 0.0013 - accuracy: 0.9998 - val_loss: 4.8106e-04 - val_accuracy: 0.9998\n",
      "Epoch 729/1000\n",
      "332/332 [==============================] - 16s 47ms/step - loss: 0.0023 - accuracy: 0.9993 - val_loss: 0.2142 - val_accuracy: 0.9711\n",
      "Epoch 730/1000\n",
      "332/332 [==============================] - 16s 47ms/step - loss: 0.0023 - accuracy: 0.9995 - val_loss: 0.0171 - val_accuracy: 0.9970\n",
      "Epoch 731/1000\n",
      "332/332 [==============================] - 16s 47ms/step - loss: 0.0016 - accuracy: 0.9996 - val_loss: 0.0061 - val_accuracy: 0.9979\n",
      "Epoch 732/1000\n",
      "332/332 [==============================] - 16s 47ms/step - loss: 0.0016 - accuracy: 0.9996 - val_loss: 1.2915e-05 - val_accuracy: 1.0000\n",
      "Epoch 733/1000\n",
      "332/332 [==============================] - 16s 47ms/step - loss: 4.8351e-04 - accuracy: 0.9998 - val_loss: 0.0265 - val_accuracy: 0.9932\n",
      "Epoch 734/1000\n",
      "332/332 [==============================] - 17s 50ms/step - loss: 0.0023 - accuracy: 0.9995 - val_loss: 0.0244 - val_accuracy: 0.9955\n",
      "Epoch 735/1000\n",
      "332/332 [==============================] - 16s 47ms/step - loss: 0.0030 - accuracy: 0.9992 - val_loss: 0.0876 - val_accuracy: 0.9833\n",
      "Epoch 736/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 0.0044 - accuracy: 0.9990 - val_loss: 3.7449e-04 - val_accuracy: 0.9997\n",
      "Epoch 737/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 9.2190e-05 - accuracy: 1.0000 - val_loss: 5.1476e-07 - val_accuracy: 1.0000\n",
      "Epoch 738/1000\n",
      "332/332 [==============================] - 16s 47ms/step - loss: 2.5157e-04 - accuracy: 0.9999 - val_loss: 0.0013 - val_accuracy: 0.9996\n",
      "Epoch 739/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 0.0020 - accuracy: 0.9995 - val_loss: 0.0816 - val_accuracy: 0.9851\n",
      "Epoch 740/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 0.0043 - accuracy: 0.9990 - val_loss: 0.0543 - val_accuracy: 0.9909\n",
      "Epoch 741/1000\n",
      "332/332 [==============================] - 16s 47ms/step - loss: 0.0020 - accuracy: 0.9994 - val_loss: 4.3729e-04 - val_accuracy: 0.9997\n",
      "Epoch 742/1000\n",
      "332/332 [==============================] - 16s 47ms/step - loss: 7.8681e-04 - accuracy: 0.9997 - val_loss: 5.9245e-06 - val_accuracy: 1.0000\n",
      "Epoch 743/1000\n",
      "332/332 [==============================] - 16s 47ms/step - loss: 0.0023 - accuracy: 0.9996 - val_loss: 2.8317e-06 - val_accuracy: 1.0000\n",
      "Epoch 744/1000\n",
      "332/332 [==============================] - 16s 47ms/step - loss: 0.0037 - accuracy: 0.9993 - val_loss: 1.2262e-04 - val_accuracy: 0.9999\n",
      "Epoch 745/1000\n",
      "332/332 [==============================] - 16s 47ms/step - loss: 8.2889e-04 - accuracy: 0.9997 - val_loss: 0.0086 - val_accuracy: 0.9975\n",
      "Epoch 746/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 0.0012 - accuracy: 0.9997 - val_loss: 3.1607e-05 - val_accuracy: 1.0000\n",
      "Epoch 747/1000\n",
      "332/332 [==============================] - 16s 47ms/step - loss: 6.7748e-04 - accuracy: 0.9998 - val_loss: 7.2456e-05 - val_accuracy: 1.0000\n",
      "Epoch 748/1000\n",
      "332/332 [==============================] - 16s 47ms/step - loss: 0.0024 - accuracy: 0.9996 - val_loss: 0.0045 - val_accuracy: 0.9982\n",
      "Epoch 749/1000\n",
      "332/332 [==============================] - 17s 50ms/step - loss: 0.0034 - accuracy: 0.9992 - val_loss: 0.0223 - val_accuracy: 0.9958\n",
      "Epoch 750/1000\n",
      "332/332 [==============================] - 16s 47ms/step - loss: 0.0020 - accuracy: 0.9994 - val_loss: 0.0175 - val_accuracy: 0.9958\n",
      "Epoch 751/1000\n",
      "332/332 [==============================] - 16s 47ms/step - loss: 0.0012 - accuracy: 0.9997 - val_loss: 4.1402e-04 - val_accuracy: 0.9997\n",
      "Epoch 752/1000\n",
      "332/332 [==============================] - 16s 47ms/step - loss: 2.0873e-04 - accuracy: 0.9999 - val_loss: 0.0012 - val_accuracy: 0.9994\n",
      "Epoch 753/1000\n",
      "332/332 [==============================] - 16s 47ms/step - loss: 0.0017 - accuracy: 0.9996 - val_loss: 0.0027 - val_accuracy: 0.9991\n",
      "Epoch 754/1000\n",
      "332/332 [==============================] - 16s 47ms/step - loss: 6.5965e-04 - accuracy: 0.9998 - val_loss: 0.0020 - val_accuracy: 0.9995\n",
      "Epoch 755/1000\n",
      "332/332 [==============================] - 16s 47ms/step - loss: 0.0070 - accuracy: 0.9987 - val_loss: 0.0014 - val_accuracy: 0.9998\n",
      "Epoch 756/1000\n",
      "332/332 [==============================] - 16s 47ms/step - loss: 0.0011 - accuracy: 0.9997 - val_loss: 3.6346e-05 - val_accuracy: 1.0000\n",
      "Epoch 757/1000\n",
      "332/332 [==============================] - 16s 47ms/step - loss: 0.0013 - accuracy: 0.9997 - val_loss: 1.6987e-04 - val_accuracy: 1.0000\n",
      "Epoch 758/1000\n",
      "332/332 [==============================] - 16s 47ms/step - loss: 0.0012 - accuracy: 0.9997 - val_loss: 2.1317e-05 - val_accuracy: 1.0000\n",
      "Epoch 759/1000\n",
      "332/332 [==============================] - 16s 47ms/step - loss: 0.0041 - accuracy: 0.9989 - val_loss: 0.0230 - val_accuracy: 0.9936\n",
      "Epoch 760/1000\n",
      "332/332 [==============================] - 16s 47ms/step - loss: 0.0018 - accuracy: 0.9994 - val_loss: 9.9313e-04 - val_accuracy: 0.9996\n",
      "Epoch 761/1000\n",
      "332/332 [==============================] - 16s 47ms/step - loss: 0.0013 - accuracy: 0.9996 - val_loss: 0.0023 - val_accuracy: 0.9993\n",
      "Epoch 762/1000\n",
      "332/332 [==============================] - 16s 47ms/step - loss: 0.0020 - accuracy: 0.9995 - val_loss: 0.0051 - val_accuracy: 0.9987\n",
      "Epoch 763/1000\n",
      "332/332 [==============================] - 16s 47ms/step - loss: 0.0034 - accuracy: 0.9993 - val_loss: 0.0071 - val_accuracy: 0.9985\n",
      "Epoch 764/1000\n",
      "332/332 [==============================] - 16s 47ms/step - loss: 0.0041 - accuracy: 0.9992 - val_loss: 1.7629e-04 - val_accuracy: 0.9999\n",
      "Epoch 765/1000\n",
      "332/332 [==============================] - 16s 47ms/step - loss: 9.6051e-04 - accuracy: 0.9997 - val_loss: 0.0318 - val_accuracy: 0.9946\n",
      "Epoch 766/1000\n",
      "332/332 [==============================] - 16s 48ms/step - loss: 0.0023 - accuracy: 0.9993 - val_loss: 0.0224 - val_accuracy: 0.9950\n",
      "Epoch 767/1000\n",
      "332/332 [==============================] - 16s 47ms/step - loss: 0.0035 - accuracy: 0.9992 - val_loss: 3.9443e-04 - val_accuracy: 0.9999\n",
      "Epoch 768/1000\n",
      "332/332 [==============================] - 16s 47ms/step - loss: 4.9745e-04 - accuracy: 0.9998 - val_loss: 0.0034 - val_accuracy: 0.9998\n",
      "Epoch 769/1000\n",
      "332/332 [==============================] - 16s 48ms/step - loss: 0.0021 - accuracy: 0.9996 - val_loss: 0.0111 - val_accuracy: 0.9976\n",
      "Epoch 770/1000\n",
      "332/332 [==============================] - 16s 47ms/step - loss: 0.0016 - accuracy: 0.9996 - val_loss: 0.0061 - val_accuracy: 0.9985\n",
      "Epoch 771/1000\n",
      "332/332 [==============================] - 16s 47ms/step - loss: 0.0012 - accuracy: 0.9997 - val_loss: 0.0074 - val_accuracy: 0.9977\n",
      "Epoch 772/1000\n",
      "332/332 [==============================] - 16s 48ms/step - loss: 0.0012 - accuracy: 0.9996 - val_loss: 4.2332e-05 - val_accuracy: 1.0000\n",
      "Epoch 773/1000\n",
      "332/332 [==============================] - 16s 48ms/step - loss: 8.9913e-04 - accuracy: 0.9998 - val_loss: 0.0022 - val_accuracy: 0.9994\n",
      "Epoch 774/1000\n",
      "332/332 [==============================] - 16s 47ms/step - loss: 0.0027 - accuracy: 0.9993 - val_loss: 0.0039 - val_accuracy: 0.9992\n",
      "Epoch 775/1000\n",
      "332/332 [==============================] - 16s 47ms/step - loss: 0.0026 - accuracy: 0.9993 - val_loss: 0.0191 - val_accuracy: 0.9955\n",
      "Epoch 776/1000\n",
      "332/332 [==============================] - 16s 48ms/step - loss: 0.0044 - accuracy: 0.9990 - val_loss: 0.0012 - val_accuracy: 0.9997\n",
      "Epoch 777/1000\n",
      "332/332 [==============================] - 16s 47ms/step - loss: 0.0016 - accuracy: 0.9996 - val_loss: 0.0010 - val_accuracy: 0.9997\n",
      "Epoch 778/1000\n",
      "332/332 [==============================] - 16s 47ms/step - loss: 0.0023 - accuracy: 0.9995 - val_loss: 0.0666 - val_accuracy: 0.9898\n",
      "Epoch 779/1000\n",
      "332/332 [==============================] - 16s 47ms/step - loss: 0.0029 - accuracy: 0.9994 - val_loss: 0.0063 - val_accuracy: 0.9990\n",
      "Epoch 780/1000\n",
      "332/332 [==============================] - 16s 47ms/step - loss: 0.0035 - accuracy: 0.9991 - val_loss: 0.0159 - val_accuracy: 0.9961\n",
      "Epoch 781/1000\n",
      "332/332 [==============================] - 17s 50ms/step - loss: 0.0030 - accuracy: 0.9992 - val_loss: 0.0018 - val_accuracy: 0.9992\n",
      "Epoch 782/1000\n",
      "332/332 [==============================] - 16s 47ms/step - loss: 0.0039 - accuracy: 0.9992 - val_loss: 2.9030e-04 - val_accuracy: 0.9998\n",
      "Epoch 783/1000\n",
      "332/332 [==============================] - 16s 47ms/step - loss: 0.0010 - accuracy: 0.9997 - val_loss: 1.8750e-06 - val_accuracy: 1.0000\n",
      "Epoch 784/1000\n",
      "332/332 [==============================] - 17s 50ms/step - loss: 2.0403e-04 - accuracy: 0.9999 - val_loss: 3.4574e-07 - val_accuracy: 1.0000\n",
      "Epoch 785/1000\n",
      "332/332 [==============================] - 16s 47ms/step - loss: 2.6271e-04 - accuracy: 0.9999 - val_loss: 1.8727e-05 - val_accuracy: 1.0000\n",
      "Epoch 786/1000\n",
      "332/332 [==============================] - 16s 47ms/step - loss: 0.0022 - accuracy: 0.9995 - val_loss: 0.0060 - val_accuracy: 0.9976\n",
      "Epoch 787/1000\n",
      "332/332 [==============================] - 16s 47ms/step - loss: 0.0018 - accuracy: 0.9997 - val_loss: 0.0015 - val_accuracy: 0.9993\n",
      "Epoch 788/1000\n",
      "332/332 [==============================] - 17s 50ms/step - loss: 0.0042 - accuracy: 0.9990 - val_loss: 0.0085 - val_accuracy: 0.9973\n",
      "Epoch 789/1000\n",
      "332/332 [==============================] - 16s 47ms/step - loss: 0.0037 - accuracy: 0.9989 - val_loss: 1.1478e-04 - val_accuracy: 0.9999\n",
      "Epoch 790/1000\n",
      "332/332 [==============================] - 16s 47ms/step - loss: 0.0012 - accuracy: 0.9996 - val_loss: 5.9319e-04 - val_accuracy: 0.9998\n",
      "Epoch 791/1000\n",
      "332/332 [==============================] - 16s 47ms/step - loss: 0.0010 - accuracy: 0.9997 - val_loss: 0.0021 - val_accuracy: 0.9992\n",
      "Epoch 792/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 6.5764e-04 - accuracy: 0.9998 - val_loss: 6.8725e-04 - val_accuracy: 0.9998\n",
      "Epoch 793/1000\n",
      "332/332 [==============================] - 16s 47ms/step - loss: 0.0014 - accuracy: 0.9996 - val_loss: 0.0648 - val_accuracy: 0.9905\n",
      "Epoch 794/1000\n",
      "332/332 [==============================] - 16s 47ms/step - loss: 0.0061 - accuracy: 0.9989 - val_loss: 5.5422e-04 - val_accuracy: 0.9996\n",
      "Epoch 795/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 0.0036 - accuracy: 0.9992 - val_loss: 0.0082 - val_accuracy: 0.9981\n",
      "Epoch 796/1000\n",
      "332/332 [==============================] - 16s 47ms/step - loss: 0.0014 - accuracy: 0.9996 - val_loss: 6.2247e-05 - val_accuracy: 1.0000\n",
      "Epoch 797/1000\n",
      "332/332 [==============================] - 16s 47ms/step - loss: 8.4274e-04 - accuracy: 0.9998 - val_loss: 3.2070e-04 - val_accuracy: 0.9998\n",
      "Epoch 798/1000\n",
      "332/332 [==============================] - 17s 50ms/step - loss: 0.0033 - accuracy: 0.9993 - val_loss: 0.0302 - val_accuracy: 0.9948\n",
      "Epoch 799/1000\n",
      "332/332 [==============================] - 16s 47ms/step - loss: 0.0015 - accuracy: 0.9996 - val_loss: 0.0023 - val_accuracy: 0.9994\n",
      "Epoch 800/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 6.8370e-04 - accuracy: 0.9998 - val_loss: 4.1225e-04 - val_accuracy: 0.9998\n",
      "Epoch 801/1000\n",
      "332/332 [==============================] - 16s 47ms/step - loss: 5.8702e-04 - accuracy: 0.9997 - val_loss: 7.7613e-05 - val_accuracy: 1.0000\n",
      "Epoch 802/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 0.0035 - accuracy: 0.9992 - val_loss: 2.4505e-06 - val_accuracy: 1.0000\n",
      "Epoch 803/1000\n",
      "332/332 [==============================] - 17s 50ms/step - loss: 0.0017 - accuracy: 0.9996 - val_loss: 0.1050 - val_accuracy: 0.9835\n",
      "Epoch 804/1000\n",
      "332/332 [==============================] - 16s 47ms/step - loss: 0.0034 - accuracy: 0.9994 - val_loss: 2.0787e-04 - val_accuracy: 0.9999\n",
      "Epoch 805/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 0.0022 - accuracy: 0.9993 - val_loss: 4.4889e-04 - val_accuracy: 0.9997\n",
      "Epoch 806/1000\n",
      "332/332 [==============================] - 17s 50ms/step - loss: 9.7421e-04 - accuracy: 0.9997 - val_loss: 6.5024e-04 - val_accuracy: 0.9998\n",
      "Epoch 807/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 9.0787e-04 - accuracy: 0.9997 - val_loss: 0.0080 - val_accuracy: 0.9981\n",
      "Epoch 808/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 5.9963e-05 - accuracy: 1.0000 - val_loss: 1.7692e-07 - val_accuracy: 1.0000\n",
      "Epoch 809/1000\n",
      "332/332 [==============================] - 17s 50ms/step - loss: 0.0039 - accuracy: 0.9992 - val_loss: 0.0384 - val_accuracy: 0.9925\n",
      "Epoch 810/1000\n",
      "332/332 [==============================] - 16s 47ms/step - loss: 0.0022 - accuracy: 0.9994 - val_loss: 0.0016 - val_accuracy: 0.9994\n",
      "Epoch 811/1000\n",
      "332/332 [==============================] - 17s 50ms/step - loss: 0.0011 - accuracy: 0.9997 - val_loss: 1.2799e-04 - val_accuracy: 1.0000\n",
      "Epoch 812/1000\n",
      "332/332 [==============================] - 16s 47ms/step - loss: 3.9763e-04 - accuracy: 0.9999 - val_loss: 8.6903e-04 - val_accuracy: 0.9996\n",
      "Epoch 813/1000\n",
      "332/332 [==============================] - 16s 47ms/step - loss: 0.0016 - accuracy: 0.9997 - val_loss: 0.0062 - val_accuracy: 0.9979\n",
      "Epoch 814/1000\n",
      "332/332 [==============================] - 16s 47ms/step - loss: 8.4712e-04 - accuracy: 0.9996 - val_loss: 1.5952e-04 - val_accuracy: 0.9999\n",
      "Epoch 815/1000\n",
      "332/332 [==============================] - 16s 47ms/step - loss: 0.0036 - accuracy: 0.9992 - val_loss: 0.0186 - val_accuracy: 0.9969\n",
      "Epoch 816/1000\n",
      "332/332 [==============================] - 16s 47ms/step - loss: 0.0013 - accuracy: 0.9997 - val_loss: 0.0308 - val_accuracy: 0.9931\n",
      "Epoch 817/1000\n",
      "332/332 [==============================] - 17s 50ms/step - loss: 0.0014 - accuracy: 0.9997 - val_loss: 8.7341e-04 - val_accuracy: 0.9996\n",
      "Epoch 818/1000\n",
      "332/332 [==============================] - 16s 47ms/step - loss: 0.0028 - accuracy: 0.9993 - val_loss: 0.0203 - val_accuracy: 0.9954\n",
      "Epoch 819/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 0.0015 - accuracy: 0.9996 - val_loss: 0.0340 - val_accuracy: 0.9935\n",
      "Epoch 820/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 0.0017 - accuracy: 0.9996 - val_loss: 0.0024 - val_accuracy: 0.9994\n",
      "Epoch 821/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 0.0040 - accuracy: 0.9991 - val_loss: 0.0117 - val_accuracy: 0.9968\n",
      "Epoch 822/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 0.0014 - accuracy: 0.9996 - val_loss: 6.0833e-04 - val_accuracy: 0.9997\n",
      "Epoch 823/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 8.7575e-04 - accuracy: 0.9996 - val_loss: 0.0035 - val_accuracy: 0.9991\n",
      "Epoch 824/1000\n",
      "332/332 [==============================] - 17s 50ms/step - loss: 1.2202e-04 - accuracy: 1.0000 - val_loss: 3.4656e-06 - val_accuracy: 1.0000\n",
      "Epoch 825/1000\n",
      "332/332 [==============================] - 16s 47ms/step - loss: 5.9765e-04 - accuracy: 0.9999 - val_loss: 1.2843e-04 - val_accuracy: 0.9999\n",
      "Epoch 826/1000\n",
      "332/332 [==============================] - 16s 47ms/step - loss: 0.0052 - accuracy: 0.9989 - val_loss: 0.0036 - val_accuracy: 0.9985\n",
      "Epoch 827/1000\n",
      "332/332 [==============================] - 16s 47ms/step - loss: 0.0037 - accuracy: 0.9992 - val_loss: 0.0018 - val_accuracy: 0.9996\n",
      "Epoch 828/1000\n",
      "332/332 [==============================] - 16s 47ms/step - loss: 0.0016 - accuracy: 0.9996 - val_loss: 6.3242e-04 - val_accuracy: 0.9999\n",
      "Epoch 829/1000\n",
      "332/332 [==============================] - 16s 47ms/step - loss: 8.5388e-04 - accuracy: 0.9997 - val_loss: 7.5547e-06 - val_accuracy: 1.0000\n",
      "Epoch 830/1000\n",
      "332/332 [==============================] - 16s 47ms/step - loss: 6.8435e-04 - accuracy: 0.9999 - val_loss: 1.8737e-06 - val_accuracy: 1.0000\n",
      "Epoch 831/1000\n",
      "332/332 [==============================] - 16s 47ms/step - loss: 1.8001e-04 - accuracy: 1.0000 - val_loss: 1.0109e-05 - val_accuracy: 1.0000\n",
      "Epoch 832/1000\n",
      "332/332 [==============================] - 16s 47ms/step - loss: 5.9786e-05 - accuracy: 1.0000 - val_loss: 3.3762e-04 - val_accuracy: 0.9999\n",
      "Epoch 833/1000\n",
      "332/332 [==============================] - 17s 50ms/step - loss: 0.0027 - accuracy: 0.9991 - val_loss: 0.0290 - val_accuracy: 0.9962\n",
      "Epoch 834/1000\n",
      "332/332 [==============================] - 17s 50ms/step - loss: 0.0044 - accuracy: 0.9990 - val_loss: 0.0011 - val_accuracy: 0.9997\n",
      "Epoch 835/1000\n",
      "332/332 [==============================] - 16s 47ms/step - loss: 0.0029 - accuracy: 0.9994 - val_loss: 0.0012 - val_accuracy: 0.9995\n",
      "Epoch 836/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 0.0013 - accuracy: 0.9996 - val_loss: 0.0050 - val_accuracy: 0.9991\n",
      "Epoch 837/1000\n",
      "332/332 [==============================] - 16s 47ms/step - loss: 6.2270e-04 - accuracy: 0.9997 - val_loss: 1.3740e-06 - val_accuracy: 1.0000\n",
      "Epoch 838/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 9.8414e-04 - accuracy: 0.9998 - val_loss: 2.0164e-04 - val_accuracy: 0.9999\n",
      "Epoch 839/1000\n",
      "332/332 [==============================] - 17s 50ms/step - loss: 0.0025 - accuracy: 0.9992 - val_loss: 0.0075 - val_accuracy: 0.9988\n",
      "Epoch 840/1000\n",
      "332/332 [==============================] - 16s 47ms/step - loss: 0.0026 - accuracy: 0.9993 - val_loss: 0.0045 - val_accuracy: 0.9986\n",
      "Epoch 841/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 0.0011 - accuracy: 0.9997 - val_loss: 0.0013 - val_accuracy: 0.9997\n",
      "Epoch 842/1000\n",
      "332/332 [==============================] - 17s 50ms/step - loss: 0.0037 - accuracy: 0.9993 - val_loss: 0.0020 - val_accuracy: 0.9992\n",
      "Epoch 843/1000\n",
      "332/332 [==============================] - 16s 47ms/step - loss: 0.0058 - accuracy: 0.9987 - val_loss: 0.0176 - val_accuracy: 0.9961\n",
      "Epoch 844/1000\n",
      "332/332 [==============================] - 17s 50ms/step - loss: 8.1722e-04 - accuracy: 0.9998 - val_loss: 1.8668e-04 - val_accuracy: 0.9999\n",
      "Epoch 845/1000\n",
      "332/332 [==============================] - 16s 47ms/step - loss: 2.4925e-05 - accuracy: 1.0000 - val_loss: 6.3145e-08 - val_accuracy: 1.0000\n",
      "Epoch 846/1000\n",
      "332/332 [==============================] - 16s 47ms/step - loss: 8.0078e-04 - accuracy: 0.9997 - val_loss: 0.0011 - val_accuracy: 0.9995\n",
      "Epoch 847/1000\n",
      "332/332 [==============================] - 16s 47ms/step - loss: 0.0030 - accuracy: 0.9992 - val_loss: 0.0271 - val_accuracy: 0.9935\n",
      "Epoch 848/1000\n",
      "332/332 [==============================] - 17s 50ms/step - loss: 0.0025 - accuracy: 0.9994 - val_loss: 1.6699e-05 - val_accuracy: 1.0000\n",
      "Epoch 849/1000\n",
      "332/332 [==============================] - 16s 47ms/step - loss: 0.0025 - accuracy: 0.9994 - val_loss: 2.4479e-04 - val_accuracy: 0.9999\n",
      "Epoch 850/1000\n",
      "332/332 [==============================] - 16s 47ms/step - loss: 7.5675e-04 - accuracy: 0.9997 - val_loss: 2.1567e-04 - val_accuracy: 0.9999\n",
      "Epoch 851/1000\n",
      "332/332 [==============================] - 16s 47ms/step - loss: 0.0022 - accuracy: 0.9995 - val_loss: 0.0221 - val_accuracy: 0.9930\n",
      "Epoch 852/1000\n",
      "332/332 [==============================] - 16s 47ms/step - loss: 0.0023 - accuracy: 0.9995 - val_loss: 8.0814e-05 - val_accuracy: 1.0000\n",
      "Epoch 853/1000\n",
      "332/332 [==============================] - 17s 50ms/step - loss: 0.0018 - accuracy: 0.9996 - val_loss: 0.0017 - val_accuracy: 0.9994\n",
      "Epoch 854/1000\n",
      "332/332 [==============================] - 16s 47ms/step - loss: 0.0014 - accuracy: 0.9996 - val_loss: 1.7769e-07 - val_accuracy: 1.0000\n",
      "Epoch 855/1000\n",
      "332/332 [==============================] - 16s 47ms/step - loss: 8.9037e-04 - accuracy: 0.9997 - val_loss: 0.0026 - val_accuracy: 0.9992\n",
      "Epoch 856/1000\n",
      "332/332 [==============================] - 16s 47ms/step - loss: 4.0021e-04 - accuracy: 0.9999 - val_loss: 1.9885e-07 - val_accuracy: 1.0000\n",
      "Epoch 857/1000\n",
      "332/332 [==============================] - 16s 47ms/step - loss: 1.2681e-04 - accuracy: 0.9999 - val_loss: 7.7083e-07 - val_accuracy: 1.0000\n",
      "Epoch 858/1000\n",
      "332/332 [==============================] - 16s 47ms/step - loss: 0.0070 - accuracy: 0.9987 - val_loss: 0.0045 - val_accuracy: 0.9990\n",
      "Epoch 859/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 0.0014 - accuracy: 0.9996 - val_loss: 0.0032 - val_accuracy: 0.9992\n",
      "Epoch 860/1000\n",
      "332/332 [==============================] - 16s 47ms/step - loss: 0.0012 - accuracy: 0.9997 - val_loss: 0.0061 - val_accuracy: 0.9990\n",
      "Epoch 861/1000\n",
      "332/332 [==============================] - 17s 50ms/step - loss: 0.0043 - accuracy: 0.9994 - val_loss: 0.0063 - val_accuracy: 0.9983\n",
      "Epoch 862/1000\n",
      "332/332 [==============================] - 16s 47ms/step - loss: 0.0020 - accuracy: 0.9994 - val_loss: 9.0565e-04 - val_accuracy: 0.9996\n",
      "Epoch 863/1000\n",
      "332/332 [==============================] - 16s 47ms/step - loss: 5.9631e-04 - accuracy: 0.9998 - val_loss: 0.0014 - val_accuracy: 0.9995\n",
      "Epoch 864/1000\n",
      "332/332 [==============================] - 16s 47ms/step - loss: 0.0012 - accuracy: 0.9996 - val_loss: 0.0013 - val_accuracy: 0.9993\n",
      "Epoch 865/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 0.0035 - accuracy: 0.9991 - val_loss: 0.0064 - val_accuracy: 0.9990\n",
      "Epoch 866/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 0.0023 - accuracy: 0.9995 - val_loss: 0.0038 - val_accuracy: 0.9990\n",
      "Epoch 867/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 0.0010 - accuracy: 0.9997 - val_loss: 3.7233e-04 - val_accuracy: 0.9999\n",
      "Epoch 868/1000\n",
      "332/332 [==============================] - 17s 50ms/step - loss: 4.7605e-04 - accuracy: 0.9999 - val_loss: 2.6427e-05 - val_accuracy: 1.0000\n",
      "Epoch 869/1000\n",
      "332/332 [==============================] - 16s 47ms/step - loss: 0.0013 - accuracy: 0.9996 - val_loss: 9.7872e-05 - val_accuracy: 1.0000\n",
      "Epoch 870/1000\n",
      "332/332 [==============================] - 16s 47ms/step - loss: 0.0011 - accuracy: 0.9998 - val_loss: 0.0217 - val_accuracy: 0.9956\n",
      "Epoch 871/1000\n",
      "332/332 [==============================] - 16s 47ms/step - loss: 0.0013 - accuracy: 0.9997 - val_loss: 0.0028 - val_accuracy: 0.9991\n",
      "Epoch 872/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 0.0067 - accuracy: 0.9983 - val_loss: 0.0298 - val_accuracy: 0.9945\n",
      "Epoch 873/1000\n",
      "332/332 [==============================] - 17s 50ms/step - loss: 0.0020 - accuracy: 0.9993 - val_loss: 1.9271e-05 - val_accuracy: 1.0000\n",
      "Epoch 874/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 0.0030 - accuracy: 0.9993 - val_loss: 0.0385 - val_accuracy: 0.9892\n",
      "Epoch 875/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 9.0443e-04 - accuracy: 0.9997 - val_loss: 1.1231e-04 - val_accuracy: 1.0000\n",
      "Epoch 876/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 1.3197e-04 - accuracy: 1.0000 - val_loss: 4.1113e-04 - val_accuracy: 0.9998\n",
      "Epoch 877/1000\n",
      "332/332 [==============================] - 16s 47ms/step - loss: 5.1139e-04 - accuracy: 0.9998 - val_loss: 0.0020 - val_accuracy: 0.9994\n",
      "Epoch 878/1000\n",
      "332/332 [==============================] - 16s 47ms/step - loss: 0.0029 - accuracy: 0.9994 - val_loss: 1.9052e-04 - val_accuracy: 0.9999\n",
      "Epoch 879/1000\n",
      "332/332 [==============================] - 16s 47ms/step - loss: 0.0012 - accuracy: 0.9997 - val_loss: 0.0016 - val_accuracy: 0.9995\n",
      "Epoch 880/1000\n",
      "332/332 [==============================] - 16s 47ms/step - loss: 0.0017 - accuracy: 0.9996 - val_loss: 0.0024 - val_accuracy: 0.9995\n",
      "Epoch 881/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 0.0027 - accuracy: 0.9995 - val_loss: 0.0014 - val_accuracy: 0.9996\n",
      "Epoch 882/1000\n",
      "332/332 [==============================] - 17s 50ms/step - loss: 0.0015 - accuracy: 0.9997 - val_loss: 0.0091 - val_accuracy: 0.9980\n",
      "Epoch 883/1000\n",
      "332/332 [==============================] - 17s 50ms/step - loss: 0.0038 - accuracy: 0.9992 - val_loss: 0.0015 - val_accuracy: 0.9996\n",
      "Epoch 884/1000\n",
      "332/332 [==============================] - 16s 47ms/step - loss: 0.0018 - accuracy: 0.9995 - val_loss: 2.3000e-05 - val_accuracy: 1.0000\n",
      "Epoch 885/1000\n",
      "332/332 [==============================] - 16s 47ms/step - loss: 0.0023 - accuracy: 0.9996 - val_loss: 9.4984e-04 - val_accuracy: 0.9997\n",
      "Epoch 886/1000\n",
      "332/332 [==============================] - 17s 50ms/step - loss: 7.6652e-04 - accuracy: 0.9998 - val_loss: 3.4400e-04 - val_accuracy: 0.9997\n",
      "Epoch 887/1000\n",
      "332/332 [==============================] - 16s 47ms/step - loss: 0.0019 - accuracy: 0.9996 - val_loss: 0.0053 - val_accuracy: 0.9989\n",
      "Epoch 888/1000\n",
      "332/332 [==============================] - 16s 47ms/step - loss: 0.0046 - accuracy: 0.9992 - val_loss: 0.1316 - val_accuracy: 0.9813\n",
      "Epoch 889/1000\n",
      "332/332 [==============================] - 16s 47ms/step - loss: 0.0019 - accuracy: 0.9995 - val_loss: 0.0073 - val_accuracy: 0.9976\n",
      "Epoch 890/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 0.0020 - accuracy: 0.9994 - val_loss: 0.0510 - val_accuracy: 0.9942\n",
      "Epoch 891/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 0.0011 - accuracy: 0.9996 - val_loss: 0.0100 - val_accuracy: 0.9987\n",
      "Epoch 892/1000\n",
      "332/332 [==============================] - 16s 47ms/step - loss: 0.0045 - accuracy: 0.9991 - val_loss: 0.0020 - val_accuracy: 0.9992\n",
      "Epoch 893/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 0.0016 - accuracy: 0.9995 - val_loss: 0.0106 - val_accuracy: 0.9975\n",
      "Epoch 894/1000\n",
      "332/332 [==============================] - 16s 47ms/step - loss: 9.3938e-04 - accuracy: 0.9998 - val_loss: 0.0038 - val_accuracy: 0.9994\n",
      "Epoch 895/1000\n",
      "332/332 [==============================] - 16s 47ms/step - loss: 5.3752e-04 - accuracy: 0.9998 - val_loss: 9.3475e-04 - val_accuracy: 0.9996\n",
      "Epoch 896/1000\n",
      "332/332 [==============================] - 16s 47ms/step - loss: 7.4177e-04 - accuracy: 0.9997 - val_loss: 7.9033e-07 - val_accuracy: 1.0000\n",
      "Epoch 897/1000\n",
      "332/332 [==============================] - 16s 47ms/step - loss: 0.0039 - accuracy: 0.9991 - val_loss: 0.0109 - val_accuracy: 0.9976\n",
      "Epoch 898/1000\n",
      "332/332 [==============================] - 16s 47ms/step - loss: 0.0017 - accuracy: 0.9995 - val_loss: 0.0099 - val_accuracy: 0.9986\n",
      "Epoch 899/1000\n",
      "332/332 [==============================] - 16s 47ms/step - loss: 4.8788e-04 - accuracy: 0.9998 - val_loss: 4.3171e-04 - val_accuracy: 0.9999\n",
      "Epoch 900/1000\n",
      "332/332 [==============================] - 16s 47ms/step - loss: 4.6422e-04 - accuracy: 0.9999 - val_loss: 0.0029 - val_accuracy: 0.9992\n",
      "Epoch 901/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 3.7325e-04 - accuracy: 0.9999 - val_loss: 1.5215e-05 - val_accuracy: 1.0000\n",
      "Epoch 902/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 6.8333e-04 - accuracy: 0.9998 - val_loss: 0.0560 - val_accuracy: 0.9890\n",
      "Epoch 903/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 0.0090 - accuracy: 0.9987 - val_loss: 7.2990e-05 - val_accuracy: 1.0000\n",
      "Epoch 904/1000\n",
      "332/332 [==============================] - 16s 47ms/step - loss: 8.0756e-04 - accuracy: 0.9997 - val_loss: 1.1836e-05 - val_accuracy: 1.0000\n",
      "Epoch 905/1000\n",
      "332/332 [==============================] - 16s 47ms/step - loss: 0.0012 - accuracy: 0.9997 - val_loss: 2.7676e-06 - val_accuracy: 1.0000\n",
      "Epoch 906/1000\n",
      "332/332 [==============================] - 16s 47ms/step - loss: 1.6331e-04 - accuracy: 0.9999 - val_loss: 1.9087e-07 - val_accuracy: 1.0000\n",
      "Epoch 907/1000\n",
      "332/332 [==============================] - 16s 47ms/step - loss: 1.7160e-04 - accuracy: 1.0000 - val_loss: 2.2670e-07 - val_accuracy: 1.0000\n",
      "Epoch 908/1000\n",
      "332/332 [==============================] - 16s 47ms/step - loss: 1.7179e-04 - accuracy: 1.0000 - val_loss: 3.8772e-05 - val_accuracy: 1.0000\n",
      "Epoch 909/1000\n",
      "332/332 [==============================] - 16s 47ms/step - loss: 9.6620e-04 - accuracy: 0.9997 - val_loss: 0.0052 - val_accuracy: 0.9985\n",
      "Epoch 910/1000\n",
      "332/332 [==============================] - 16s 47ms/step - loss: 0.0094 - accuracy: 0.9982 - val_loss: 0.0020 - val_accuracy: 0.9994\n",
      "Epoch 911/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 0.0015 - accuracy: 0.9996 - val_loss: 5.5359e-04 - val_accuracy: 0.9999\n",
      "Epoch 912/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 0.0050 - accuracy: 0.9990 - val_loss: 2.2456e-04 - val_accuracy: 1.0000\n",
      "Epoch 913/1000\n",
      "332/332 [==============================] - 16s 47ms/step - loss: 2.1928e-04 - accuracy: 0.9999 - val_loss: 6.2541e-07 - val_accuracy: 1.0000\n",
      "Epoch 914/1000\n",
      "332/332 [==============================] - 16s 47ms/step - loss: 8.3321e-04 - accuracy: 0.9997 - val_loss: 1.5691e-04 - val_accuracy: 0.9999\n",
      "Epoch 915/1000\n",
      "332/332 [==============================] - 16s 47ms/step - loss: 0.0018 - accuracy: 0.9995 - val_loss: 2.6388e-05 - val_accuracy: 1.0000\n",
      "Epoch 916/1000\n",
      "332/332 [==============================] - 16s 47ms/step - loss: 0.0013 - accuracy: 0.9997 - val_loss: 0.0059 - val_accuracy: 0.9990\n",
      "Epoch 917/1000\n",
      "332/332 [==============================] - 16s 47ms/step - loss: 0.0029 - accuracy: 0.9993 - val_loss: 0.0100 - val_accuracy: 0.9983\n",
      "Epoch 918/1000\n",
      "332/332 [==============================] - 16s 47ms/step - loss: 3.1647e-04 - accuracy: 0.9999 - val_loss: 1.0570e-06 - val_accuracy: 1.0000\n",
      "Epoch 919/1000\n",
      "332/332 [==============================] - 16s 47ms/step - loss: 6.9983e-04 - accuracy: 0.9998 - val_loss: 0.0186 - val_accuracy: 0.9941\n",
      "Epoch 920/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 0.0022 - accuracy: 0.9994 - val_loss: 0.0215 - val_accuracy: 0.9950\n",
      "Epoch 921/1000\n",
      "332/332 [==============================] - 16s 47ms/step - loss: 0.0019 - accuracy: 0.9994 - val_loss: 1.9715e-04 - val_accuracy: 0.9999\n",
      "Epoch 922/1000\n",
      "332/332 [==============================] - 16s 47ms/step - loss: 0.0023 - accuracy: 0.9995 - val_loss: 0.0200 - val_accuracy: 0.9959\n",
      "Epoch 923/1000\n",
      "332/332 [==============================] - 16s 47ms/step - loss: 0.0029 - accuracy: 0.9993 - val_loss: 0.0311 - val_accuracy: 0.9917\n",
      "Epoch 924/1000\n",
      "332/332 [==============================] - 16s 47ms/step - loss: 0.0028 - accuracy: 0.9995 - val_loss: 2.8738e-06 - val_accuracy: 1.0000\n",
      "Epoch 925/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 0.0011 - accuracy: 0.9997 - val_loss: 1.7727e-04 - val_accuracy: 1.0000\n",
      "Epoch 926/1000\n",
      "332/332 [==============================] - 16s 47ms/step - loss: 4.8360e-04 - accuracy: 0.9999 - val_loss: 0.0071 - val_accuracy: 0.9990\n",
      "Epoch 927/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 8.0918e-04 - accuracy: 0.9997 - val_loss: 0.0516 - val_accuracy: 0.9881\n",
      "Epoch 928/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 4.4151e-04 - accuracy: 0.9999 - val_loss: 1.1366e-07 - val_accuracy: 1.0000\n",
      "Epoch 929/1000\n",
      "332/332 [==============================] - 16s 47ms/step - loss: 2.5124e-04 - accuracy: 0.9999 - val_loss: 1.6290e-05 - val_accuracy: 1.0000\n",
      "Epoch 930/1000\n",
      "332/332 [==============================] - 16s 47ms/step - loss: 0.0041 - accuracy: 0.9994 - val_loss: 0.6673 - val_accuracy: 0.9380\n",
      "Epoch 931/1000\n",
      "332/332 [==============================] - 16s 47ms/step - loss: 0.0061 - accuracy: 0.9985 - val_loss: 0.0090 - val_accuracy: 0.9977\n",
      "Epoch 932/1000\n",
      "332/332 [==============================] - 16s 47ms/step - loss: 7.9126e-04 - accuracy: 0.9997 - val_loss: 0.0379 - val_accuracy: 0.9936\n",
      "Epoch 933/1000\n",
      "332/332 [==============================] - 16s 47ms/step - loss: 3.9176e-04 - accuracy: 0.9998 - val_loss: 1.0840e-05 - val_accuracy: 1.0000\n",
      "Epoch 934/1000\n",
      "332/332 [==============================] - 16s 47ms/step - loss: 0.0011 - accuracy: 0.9998 - val_loss: 0.0091 - val_accuracy: 0.9981\n",
      "Epoch 935/1000\n",
      "332/332 [==============================] - 16s 50ms/step - loss: 0.0015 - accuracy: 0.9997 - val_loss: 1.1686e-04 - val_accuracy: 0.9999\n",
      "Epoch 936/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 0.0014 - accuracy: 0.9996 - val_loss: 0.0097 - val_accuracy: 0.9986\n",
      "Epoch 937/1000\n",
      "332/332 [==============================] - 16s 47ms/step - loss: 0.0012 - accuracy: 0.9997 - val_loss: 8.1935e-04 - val_accuracy: 0.9997\n",
      "Epoch 938/1000\n",
      "332/332 [==============================] - 17s 50ms/step - loss: 5.3161e-04 - accuracy: 0.9998 - val_loss: 0.0026 - val_accuracy: 0.9992\n",
      "Epoch 939/1000\n",
      "332/332 [==============================] - 17s 50ms/step - loss: 9.9790e-04 - accuracy: 0.9998 - val_loss: 5.3919e-07 - val_accuracy: 1.0000\n",
      "Epoch 940/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 0.0062 - accuracy: 0.9986 - val_loss: 0.2011 - val_accuracy: 0.9684\n",
      "Epoch 941/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 0.0021 - accuracy: 0.9996 - val_loss: 0.0027 - val_accuracy: 0.9992\n",
      "Epoch 942/1000\n",
      "332/332 [==============================] - 16s 47ms/step - loss: 7.9597e-04 - accuracy: 0.9998 - val_loss: 0.0013 - val_accuracy: 0.9996\n",
      "Epoch 943/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 1.5660e-04 - accuracy: 0.9999 - val_loss: 0.0012 - val_accuracy: 0.9995\n",
      "Epoch 944/1000\n",
      "332/332 [==============================] - 16s 47ms/step - loss: 0.0033 - accuracy: 0.9992 - val_loss: 0.0217 - val_accuracy: 0.9947\n",
      "Epoch 945/1000\n",
      "332/332 [==============================] - 16s 47ms/step - loss: 0.0015 - accuracy: 0.9996 - val_loss: 0.0032 - val_accuracy: 0.9988\n",
      "Epoch 946/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 0.0018 - accuracy: 0.9995 - val_loss: 0.0221 - val_accuracy: 0.9958\n",
      "Epoch 947/1000\n",
      "332/332 [==============================] - 16s 47ms/step - loss: 9.6224e-04 - accuracy: 0.9998 - val_loss: 0.0017 - val_accuracy: 0.9992\n",
      "Epoch 948/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 0.0047 - accuracy: 0.9992 - val_loss: 3.1701e-04 - val_accuracy: 0.9999\n",
      "Epoch 949/1000\n",
      "332/332 [==============================] - 16s 47ms/step - loss: 0.0011 - accuracy: 0.9997 - val_loss: 5.0175e-06 - val_accuracy: 1.0000\n",
      "Epoch 950/1000\n",
      "332/332 [==============================] - 16s 47ms/step - loss: 0.0011 - accuracy: 0.9997 - val_loss: 7.1332e-07 - val_accuracy: 1.0000\n",
      "Epoch 951/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 1.8381e-04 - accuracy: 0.9999 - val_loss: 5.1359e-06 - val_accuracy: 1.0000\n",
      "Epoch 952/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 0.0013 - accuracy: 0.9996 - val_loss: 5.0824e-06 - val_accuracy: 1.0000\n",
      "Epoch 953/1000\n",
      "332/332 [==============================] - 16s 47ms/step - loss: 0.0026 - accuracy: 0.9993 - val_loss: 0.0485 - val_accuracy: 0.9927\n",
      "Epoch 954/1000\n",
      "332/332 [==============================] - 16s 47ms/step - loss: 0.0014 - accuracy: 0.9996 - val_loss: 4.2378e-05 - val_accuracy: 1.0000\n",
      "Epoch 955/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 0.0013 - accuracy: 0.9996 - val_loss: 2.4252e-06 - val_accuracy: 1.0000\n",
      "Epoch 956/1000\n",
      "332/332 [==============================] - 16s 47ms/step - loss: 4.5075e-04 - accuracy: 0.9998 - val_loss: 5.4010e-04 - val_accuracy: 0.9997\n",
      "Epoch 957/1000\n",
      "332/332 [==============================] - 16s 47ms/step - loss: 0.0015 - accuracy: 0.9997 - val_loss: 4.4802e-06 - val_accuracy: 1.0000\n",
      "Epoch 958/1000\n",
      "332/332 [==============================] - 17s 50ms/step - loss: 9.5053e-04 - accuracy: 0.9998 - val_loss: 0.1900 - val_accuracy: 0.9768\n",
      "Epoch 959/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 0.0049 - accuracy: 0.9988 - val_loss: 8.8270e-04 - val_accuracy: 0.9996\n",
      "Epoch 960/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 0.0017 - accuracy: 0.9995 - val_loss: 8.0990e-05 - val_accuracy: 1.0000\n",
      "Epoch 961/1000\n",
      "332/332 [==============================] - 16s 47ms/step - loss: 0.0014 - accuracy: 0.9996 - val_loss: 0.0024 - val_accuracy: 0.9996\n",
      "Epoch 962/1000\n",
      "332/332 [==============================] - 16s 47ms/step - loss: 0.0023 - accuracy: 0.9995 - val_loss: 3.5588e-05 - val_accuracy: 1.0000\n",
      "Epoch 963/1000\n",
      "332/332 [==============================] - 16s 47ms/step - loss: 0.0012 - accuracy: 0.9997 - val_loss: 0.0365 - val_accuracy: 0.9945\n",
      "Epoch 964/1000\n",
      "332/332 [==============================] - 16s 47ms/step - loss: 0.0016 - accuracy: 0.9996 - val_loss: 0.0287 - val_accuracy: 0.9946\n",
      "Epoch 965/1000\n",
      "332/332 [==============================] - 16s 47ms/step - loss: 8.4089e-04 - accuracy: 0.9998 - val_loss: 2.9613e-05 - val_accuracy: 1.0000\n",
      "Epoch 966/1000\n",
      "332/332 [==============================] - 16s 47ms/step - loss: 1.9398e-04 - accuracy: 0.9999 - val_loss: 0.0143 - val_accuracy: 0.9962\n",
      "Epoch 967/1000\n",
      "332/332 [==============================] - 16s 47ms/step - loss: 0.0016 - accuracy: 0.9997 - val_loss: 0.0445 - val_accuracy: 0.9940\n",
      "Epoch 968/1000\n",
      "332/332 [==============================] - 16s 47ms/step - loss: 0.0032 - accuracy: 0.9993 - val_loss: 0.0023 - val_accuracy: 0.9994\n",
      "Epoch 969/1000\n",
      "332/332 [==============================] - 16s 47ms/step - loss: 0.0032 - accuracy: 0.9993 - val_loss: 1.1438e-04 - val_accuracy: 1.0000\n",
      "Epoch 970/1000\n",
      "332/332 [==============================] - 16s 47ms/step - loss: 0.0025 - accuracy: 0.9993 - val_loss: 0.0026 - val_accuracy: 0.9992\n",
      "Epoch 971/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 0.0014 - accuracy: 0.9996 - val_loss: 0.0250 - val_accuracy: 0.9963\n",
      "Epoch 972/1000\n",
      "332/332 [==============================] - 16s 47ms/step - loss: 0.0011 - accuracy: 0.9997 - val_loss: 3.9986e-05 - val_accuracy: 1.0000\n",
      "Epoch 973/1000\n",
      "332/332 [==============================] - 17s 50ms/step - loss: 0.0014 - accuracy: 0.9997 - val_loss: 0.0017 - val_accuracy: 0.9992\n",
      "Epoch 974/1000\n",
      "332/332 [==============================] - 17s 50ms/step - loss: 2.4736e-04 - accuracy: 0.9999 - val_loss: 8.4740e-05 - val_accuracy: 0.9999\n",
      "Epoch 975/1000\n",
      "332/332 [==============================] - 16s 47ms/step - loss: 4.6217e-04 - accuracy: 0.9999 - val_loss: 0.0056 - val_accuracy: 0.9985\n",
      "Epoch 976/1000\n",
      "332/332 [==============================] - 16s 47ms/step - loss: 0.0079 - accuracy: 0.9987 - val_loss: 0.0041 - val_accuracy: 0.9986\n",
      "Epoch 977/1000\n",
      "332/332 [==============================] - 16s 47ms/step - loss: 0.0023 - accuracy: 0.9996 - val_loss: 0.0117 - val_accuracy: 0.9966\n",
      "Epoch 978/1000\n",
      "332/332 [==============================] - 16s 47ms/step - loss: 7.3418e-04 - accuracy: 0.9998 - val_loss: 0.0046 - val_accuracy: 0.9988\n",
      "Epoch 979/1000\n",
      "332/332 [==============================] - 16s 47ms/step - loss: 0.0021 - accuracy: 0.9995 - val_loss: 0.0440 - val_accuracy: 0.9913\n",
      "Epoch 980/1000\n",
      "332/332 [==============================] - 16s 47ms/step - loss: 0.0016 - accuracy: 0.9996 - val_loss: 3.2154e-04 - val_accuracy: 0.9999\n",
      "Epoch 981/1000\n",
      "332/332 [==============================] - 17s 50ms/step - loss: 0.0023 - accuracy: 0.9994 - val_loss: 4.3187e-04 - val_accuracy: 0.9998\n",
      "Epoch 982/1000\n",
      "332/332 [==============================] - 16s 47ms/step - loss: 0.0033 - accuracy: 0.9993 - val_loss: 7.4621e-07 - val_accuracy: 1.0000\n",
      "Epoch 983/1000\n",
      "332/332 [==============================] - 16s 47ms/step - loss: 5.8733e-04 - accuracy: 0.9998 - val_loss: 3.4587e-06 - val_accuracy: 1.0000\n",
      "Epoch 984/1000\n",
      "332/332 [==============================] - 16s 47ms/step - loss: 3.6059e-04 - accuracy: 0.9999 - val_loss: 4.9458e-07 - val_accuracy: 1.0000\n",
      "Epoch 985/1000\n",
      "332/332 [==============================] - 17s 50ms/step - loss: 6.3547e-04 - accuracy: 0.9998 - val_loss: 0.0116 - val_accuracy: 0.9970\n",
      "Epoch 986/1000\n",
      "332/332 [==============================] - 16s 47ms/step - loss: 0.0026 - accuracy: 0.9994 - val_loss: 0.0399 - val_accuracy: 0.9926\n",
      "Epoch 987/1000\n",
      "332/332 [==============================] - 16s 47ms/step - loss: 0.0024 - accuracy: 0.9994 - val_loss: 0.0111 - val_accuracy: 0.9988\n",
      "Epoch 988/1000\n",
      "332/332 [==============================] - 15s 47ms/step - loss: 0.0038 - accuracy: 0.9993 - val_loss: 0.0023 - val_accuracy: 0.9993\n",
      "Epoch 989/1000\n",
      "332/332 [==============================] - 16s 47ms/step - loss: 0.0015 - accuracy: 0.9996 - val_loss: 0.0030 - val_accuracy: 0.9992\n",
      "Epoch 990/1000\n",
      "332/332 [==============================] - 17s 50ms/step - loss: 0.0018 - accuracy: 0.9994 - val_loss: 0.0027 - val_accuracy: 0.9987\n",
      "Epoch 991/1000\n",
      "332/332 [==============================] - 16s 47ms/step - loss: 0.0011 - accuracy: 0.9996 - val_loss: 0.0022 - val_accuracy: 0.9995\n",
      "Epoch 992/1000\n",
      "332/332 [==============================] - 16s 47ms/step - loss: 9.0636e-04 - accuracy: 0.9998 - val_loss: 7.5520e-06 - val_accuracy: 1.0000\n",
      "Epoch 993/1000\n",
      "332/332 [==============================] - 16s 47ms/step - loss: 7.2639e-04 - accuracy: 0.9999 - val_loss: 8.5017e-04 - val_accuracy: 0.9997\n",
      "Epoch 994/1000\n",
      "332/332 [==============================] - 16s 47ms/step - loss: 0.0015 - accuracy: 0.9997 - val_loss: 0.0038 - val_accuracy: 0.9992\n",
      "Epoch 995/1000\n",
      "332/332 [==============================] - 16s 47ms/step - loss: 0.0036 - accuracy: 0.9992 - val_loss: 0.0630 - val_accuracy: 0.9880\n",
      "Epoch 996/1000\n",
      "332/332 [==============================] - 16s 47ms/step - loss: 0.0031 - accuracy: 0.9991 - val_loss: 2.2848e-05 - val_accuracy: 1.0000\n",
      "Epoch 997/1000\n",
      "332/332 [==============================] - 16s 47ms/step - loss: 5.2796e-04 - accuracy: 0.9998 - val_loss: 6.1140e-04 - val_accuracy: 0.9997\n",
      "Epoch 998/1000\n",
      "332/332 [==============================] - 16s 47ms/step - loss: 0.0025 - accuracy: 0.9995 - val_loss: 0.0354 - val_accuracy: 0.9915\n",
      "Epoch 999/1000\n",
      "332/332 [==============================] - 16s 47ms/step - loss: 0.0012 - accuracy: 0.9997 - val_loss: 1.9993e-04 - val_accuracy: 0.9999\n",
      "Epoch 1000/1000\n",
      "332/332 [==============================] - 16s 47ms/step - loss: 9.6211e-04 - accuracy: 0.9998 - val_loss: 0.0066 - val_accuracy: 0.9983\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f81c0340610>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# NN LSTM\n",
    "\n",
    "input = keras.layers.Input(shape=[48,48])\n",
    "bi1 = keras.layers.Bidirectional(LSTM(800))(input)\n",
    "flat = keras.layers.Flatten(input_shape=[48,48])(bi1)\n",
    "batch1=keras.layers.BatchNormalization()(flat)\n",
    "hidden1 = keras.layers.Dense(400, activation=\"tanh\")(batch1)\n",
    "drop1 = keras.layers.Dropout(0.1)(hidden1)\n",
    "hidden2 = keras.layers.Dense(100, activation=\"LeakyReLU\")(drop1)\n",
    "concat = keras.layers.Concatenate()([flat, hidden2])\n",
    "output = keras.layers.Dense(7, activation=\"softmax\")(concat)\n",
    "model = keras.Model(inputs=[input], outputs=[output])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "#with tf.device(\"/device:GPU:1\"):\n",
    "history = model.fit(trainData, trainTarget, epochs=1000, batch_size=128, validation_data=(testData, testTarget))\n",
    "\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['validation', 'train'], loc='lower right')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
